{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c6e6b5",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2893c4",
   "metadata": {},
   "source": [
    "## TRAC-2 Data Augmentation- Back Translation\n",
    "\n",
    "In this notebook we use back traslation techniques to augment the TRAC-2 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17dffa5",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a62f049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.1.1 in /opt/conda/lib/python3.7/site-packages (4.1.1)\n",
      "Requirement already satisfied: sentencepiece==0.1.94 in /opt/conda/lib/python3.7/site-packages (0.1.94)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (2021.8.28)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (0.0.45)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (4.62.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (1.19.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (2.25.1)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (0.9.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.1.1) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.1.1) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.1.1) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.1.1) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.1.1) (4.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.1.1) (8.0.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.1.1) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.1.1) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses->transformers==4.1.1) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==4.1.1) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==4.1.1) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.1.1 sentencepiece==0.1.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd2bc39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mosestokenizer==1.1.0 in /opt/conda/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: toolwrapper in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0) (2.1.0)\n",
      "Requirement already satisfied: openfile in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0) (0.0.7)\n",
      "Requirement already satisfied: uctools in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0) (1.3.0)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install mosestokenizer==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39eddc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the MarianMT model and tokenizer.\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# import pandas and numpys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587701a",
   "metadata": {},
   "source": [
    "## Models from english to Romance languages and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef50a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MarianMTModel were not initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ROMANCE and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model that can translate from English to Romance languages\n",
    "# this is a single model that can translate to any of the romance languages\n",
    "\n",
    "target_tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-ROMANCE')\n",
    "target_model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-ROMANCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6909b82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MarianMTModel were not initialized from the model checkpoint at Helsinki-NLP/opus-mt-ROMANCE-en and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# initialize models that can translate Romance languages to English.\n",
    "\n",
    "en_tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ROMANCE-en')\n",
    "en_model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ROMANCE-en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e438d",
   "metadata": {},
   "source": [
    "## Available languages\n",
    "\n",
    "Below is a full list of available languages. The most relevant are: \n",
    "\n",
    "French(fr), Spanish(es), Italian(it), Portuguese(pt), Romanian(ro), Galician(gl), Sardinian(sn), Corsican(co), and many others including spanish from Spain and Latin America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa681791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>>fr<<',\n",
       " '>>es<<',\n",
       " '>>it<<',\n",
       " '>>pt<<',\n",
       " '>>pt_br<<',\n",
       " '>>ro<<',\n",
       " '>>ca<<',\n",
       " '>>gl<<',\n",
       " '>>pt_BR<<',\n",
       " '>>la<<',\n",
       " '>>wa<<',\n",
       " '>>fur<<',\n",
       " '>>oc<<',\n",
       " '>>fr_CA<<',\n",
       " '>>sc<<',\n",
       " '>>es_ES<<',\n",
       " '>>es_MX<<',\n",
       " '>>es_AR<<',\n",
       " '>>es_PR<<',\n",
       " '>>es_UY<<',\n",
       " '>>es_CL<<',\n",
       " '>>es_CO<<',\n",
       " '>>es_CR<<',\n",
       " '>>es_GT<<',\n",
       " '>>es_HN<<',\n",
       " '>>es_NI<<',\n",
       " '>>es_PA<<',\n",
       " '>>es_PE<<',\n",
       " '>>es_VE<<',\n",
       " '>>es_DO<<',\n",
       " '>>es_EC<<',\n",
       " '>>es_SV<<',\n",
       " '>>an<<',\n",
       " '>>pt_PT<<',\n",
       " '>>frp<<',\n",
       " '>>lad<<',\n",
       " '>>vec<<',\n",
       " '>>fr_FR<<',\n",
       " '>>co<<',\n",
       " '>>it_IT<<',\n",
       " '>>lld<<',\n",
       " '>>lij<<',\n",
       " '>>lmo<<',\n",
       " '>>nap<<',\n",
       " '>>rm<<',\n",
       " '>>scn<<',\n",
       " '>>mwl<<']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available languages\n",
    "target_tokenizer.supported_language_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c25fde5",
   "metadata": {},
   "source": [
    "## Helper functions to translate in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "275b677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(texts, model, tokenizer, language=\"fr\"):\n",
    "    # Prepare the text data into appropriate format for the model\n",
    "    template = lambda text: f\"{text}\" if language == \"en\" else f\">>{language}<< {text}\"\n",
    "    src_texts = [template(i) for i in texts]\n",
    "\n",
    "    # Tokenize the texts\n",
    "    encoded = tokenizer.prepare_seq2seq_batch(src_texts,return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate translation using model\n",
    "    translated = model.generate(**encoded)\n",
    "\n",
    "    # Convert the generated tokens indices back into text\n",
    "    translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    \n",
    "    return translated_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e95d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translate(texts, source_lang=\"en\", target_lang=\"fr\"):\n",
    "    # Translate from source to target language\n",
    "    fr_texts = translate(texts, target_model, target_tokenizer, \n",
    "                         language=target_lang)\n",
    "\n",
    "    # Translate from target language back to source language\n",
    "    back_translated_texts = translate(fr_texts, en_model, en_tokenizer, \n",
    "                                      language=source_lang)\n",
    "    \n",
    "    return back_translated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "512d82d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'd like a cup of coffee.\"]\n"
     ]
    }
   ],
   "source": [
    "# note that even a single text needs to be inside a list\n",
    "single_sentence = ['I would like to have a cup of coffee']\n",
    "\n",
    "aug_texts = back_translate(single_sentence, source_lang=\"en\", target_lang=\"es\")\n",
    "print(aug_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8967a1",
   "metadata": {},
   "source": [
    "## Play a little..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8138dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I really like this assignment.', \"It's not a great performance.\"]\n"
     ]
    }
   ],
   "source": [
    "# example using back translation to spanish\n",
    "\n",
    "example_texts = ['I like this homework so much', 'this is not a great performance']\n",
    "\n",
    "aug_texts = back_translate(example_texts, source_lang=\"en\", target_lang=\"es\")\n",
    "print(aug_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c65e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love homework so much.', \"It's not a great performance.\"]\n"
     ]
    }
   ],
   "source": [
    "# example using back translation to french\n",
    "\n",
    "aug_texts = back_translate(example_texts, source_lang=\"en\", target_lang=\"fr\")\n",
    "\n",
    "print(aug_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "567b344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I really like homework.', \"This isn't a great performance.\"]\n"
     ]
    }
   ],
   "source": [
    "# example using back translation to italian\n",
    "\n",
    "aug_texts = back_translate(example_texts, source_lang=\"en\", target_lang=\"it\")\n",
    "\n",
    "print(aug_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c1ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I really like this housework.', \"This isn't a great performance.\"]\n"
     ]
    }
   ],
   "source": [
    "# example using back translation to portuguese\n",
    "\n",
    "aug_texts = back_translate(example_texts, source_lang=\"en\", target_lang=\"pt\")\n",
    "\n",
    "print(aug_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36657907",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7265afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all training data\n",
    "train_data_a = pd.read_csv('../../../data/release-files/eng/trac2_eng_train_oversampled_task_A.csv')\n",
    "train_data_b = pd.read_csv('../../../data/release-files/eng/trac2_eng_train_oversampled_task_B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8a1626a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C45.451</td>\n",
       "      <td>Next part</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C47.11</td>\n",
       "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C33.79</td>\n",
       "      <td>🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.1961</td>\n",
       "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C10.153</td>\n",
       "      <td>Concerned authorities should bring arundathi R...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text Sub-task A  \\\n",
       "0  C45.451                                          Next part        NAG   \n",
       "1   C47.11                 Iii8mllllllm\\nMdxfvb8o90lplppi0005        NAG   \n",
       "2   C33.79  🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...        NAG   \n",
       "3  C4.1961  What the fuck was this? I respect shwetabh and...        NAG   \n",
       "4  C10.153  Concerned authorities should bring arundathi R...        NAG   \n",
       "\n",
       "  Sub-task B  \n",
       "0       NGEN  \n",
       "1       NGEN  \n",
       "2       NGEN  \n",
       "3       NGEN  \n",
       "4       NGEN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6be051b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C45.451</td>\n",
       "      <td>Next part</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C47.11</td>\n",
       "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C33.79</td>\n",
       "      <td>🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.1961</td>\n",
       "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C10.153</td>\n",
       "      <td>Concerned authorities should bring arundathi R...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text Sub-task A  \\\n",
       "0  C45.451                                          Next part        NAG   \n",
       "1   C47.11                 Iii8mllllllm\\nMdxfvb8o90lplppi0005        NAG   \n",
       "2   C33.79  🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...        NAG   \n",
       "3  C4.1961  What the fuck was this? I respect shwetabh and...        NAG   \n",
       "4  C10.153  Concerned authorities should bring arundathi R...        NAG   \n",
       "\n",
       "  Sub-task B  \n",
       "0       NGEN  \n",
       "1       NGEN  \n",
       "2       NGEN  \n",
       "3       NGEN  \n",
       "4       NGEN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "991a590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for each class\n",
    "# translation takes a lot of time. This allows to create partial results in case the kernel dies\n",
    "train_data_a_NAG = train_data_a[train_data_a['Sub-task A'] == 'NAG']\n",
    "train_data_a_CAG = train_data_a[train_data_a['Sub-task A'] == 'CAG']\n",
    "train_data_a_OAG = train_data_a[train_data_a['Sub-task A'] == 'OAG']\n",
    "\n",
    "train_data_b_NGEN = train_data_b[train_data_b['Sub-task B'] == 'NGEN']\n",
    "train_data_b_GEN = train_data_b[train_data_b['Sub-task B'] == 'GEN']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aa8607",
   "metadata": {},
   "source": [
    "## Data augmentation for task-A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1005974",
   "metadata": {},
   "source": [
    "### Class NAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e561ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to spanish and back to english\n",
    "train_data_a_NAG['es_trans'] = train_data_a_NAG['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='es')[0])\n",
    "train_data_a_NAG.to_csv('../../../data/augm/taskA-NAG-es.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to french and back to english\n",
    "train_data_a_NAG['fr_trans'] = train_data_a_NAG['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='fr')[0])\n",
    "train_data_a_NAG.to_csv('../../../data/augm/taskA-NAG-fr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8acf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to italian and back to english\n",
    "train_data_a_NAG['it_trans'] = train_data_a_NAG['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='it')[0])\n",
    "train_data_a_NAG.to_csv('../../../data/augm/taskA-NAG-it.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795af35",
   "metadata": {},
   "source": [
    "### Class CAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c9d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to spanish and back to english\n",
    "train_data_a_CAG['es_trans'] = train_data_a_CAG['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='es')[0])\n",
    "train_data_a_CAG.to_csv('../../../data/augm/taskA-CAG-es.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to french and back to english\n",
    "train_data_a_CAG['fr_trans'] = train_data_a_CAG['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='fr')[0])\n",
    "train_data_a_CAG.to_csv('../../../data/augm/taskA-CAG-fr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to italian and back to english\n",
    "train_data_a_CAG['it_trans'] = train_data_a_CAG['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='it')[0])\n",
    "train_data_a_CAG.to_csv('../../../data/augm/taskA-CAG-it.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c0f3a6",
   "metadata": {},
   "source": [
    "### Class OAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80cf9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to spanish and back to english\n",
    "train_data_a_OAG['es_trans'] = train_data_a_OAG['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='es')[0])\n",
    "train_data_a_OAG.to_csv('../../../data/augm/taskA-OAG-es.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to french and back to english\n",
    "train_data_a_OAG['fr_trans'] = train_data_a_OAG['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='fr')[0])\n",
    "train_data_a_OAG.to_csv('../../../data/augm/taskA-OAG-fr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to italian and back to english\n",
    "train_data_a_OAG['it_trans'] = train_data_a_OAG['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='it')[0])\n",
    "train_data_a_OAG.to_csv('../../../data/augm/taskA-OAG-it.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b63bf7",
   "metadata": {},
   "source": [
    "## Data augmentation for task-B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671c35b",
   "metadata": {},
   "source": [
    "### Class NGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to spanish and back to english\n",
    "train_data_b_NGEN['es_trans'] = train_data_b_NGEN['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='es')[0])\n",
    "train_data_b_NGEN.to_csv('../../../data/augm/taskB-NGEN-es.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to french and back to english\n",
    "train_data_b_NGEN['fr_trans'] = train_data_b_NGEN['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='fr')[0])\n",
    "train_data_b_NGEN.to_csv('../../../data/augm/taskB-NGEN-fr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb95d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to italian and back to english\n",
    "train_data_b_NGEN['it_trans'] = train_data_b_NGEN['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='it')[0])\n",
    "train_data_b_NGEN.to_csv('../../../data/augm/taskB-NGEN-it.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b9a84",
   "metadata": {},
   "source": [
    "### Class GEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7770b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to spanish and back to english\n",
    "train_data_b_GEN['es_trans'] = train_data_b_GEN['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='es')[0])\n",
    "train_data_b_GEN.to_csv('../../../data/augm/taskB-GEN-es.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b18c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to french and back to english\n",
    "train_data_b_GEN['fr_trans'] = train_data_b_GEN['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='fr')[0])\n",
    "train_data_b_GEN.to_csv('../../../data/augm/taskB-GEN-fr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranlation to italian and back to english\n",
    "train_data_b_GEN['it_trans'] = train_data_b_GEN['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='it')[0])\n",
    "train_data_b_GEN.to_csv('../../../data/augm/taskB-GEN-it.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce9a4fc",
   "metadata": {},
   "source": [
    "## Import data back to generate the augmented dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1097103",
   "metadata": {},
   "source": [
    "### Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43cb9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../../../data/files_back_translation/taskA-NAG-es.csv')[['Text', 'Sub-task A']]\n",
    "df1 = pd.read_csv('../../../data/files_back_translation/taskA-NAG-es.csv')[['es_trans', 'Sub-task A']]\n",
    "df2 = pd.read_csv('../../../data/files_back_translation/taskA-NAG-it.csv')[['it_trans', 'Sub-task A']]\n",
    "df3 = pd.read_csv('../../../data/files_back_translation/taskA-NAG-fr.csv')[['fr_trans', 'Sub-task A']]\n",
    "\n",
    "df4 = pd.read_csv('../../../data/files_back_translation/taskA-CAG-es.csv')[['Text', 'Sub-task A']]\n",
    "df5 = pd.read_csv('../../../data/files_back_translation/taskA-CAG-es.csv')[['es_trans', 'Sub-task A']]\n",
    "df6 = pd.read_csv('../../../data/files_back_translation/taskA-CAG-it.csv')[['it_trans', 'Sub-task A']]\n",
    "df7 = pd.read_csv('../../../data/files_back_translation/taskA-CAG-fr.csv')[['fr_trans', 'Sub-task A']]\n",
    "\n",
    "df8 = pd.read_csv('../../../data/files_back_translation/taskA-OAG-es.csv')[['Text', 'Sub-task A']]\n",
    "df9 = pd.read_csv('../../../data/files_back_translation/taskA-OAG-es.csv')[['es_trans', 'Sub-task A']]\n",
    "df10 = pd.read_csv('../../../data/files_back_translation/taskA-OAG-it.csv')[['it_trans', 'Sub-task A']]\n",
    "df11 = pd.read_csv('../../../data/files_back_translation/taskA-OAG-fr.csv')[['fr_trans', 'Sub-task A']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71cb83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "\n",
    "df1 = df1.rename(columns={'es_trans':'Text'})\n",
    "df2 = df2.rename(columns={'it_trans':'Text'})\n",
    "df3 = df3.rename(columns={'fr_trans':'Text'})\n",
    "\n",
    "df5 = df5.rename(columns={'es_trans':'Text'})\n",
    "df6 = df6.rename(columns={'it_trans':'Text'})\n",
    "df7 = df7.rename(columns={'fr_trans':'Text'})\n",
    "\n",
    "df9 = df9.rename(columns={'es_trans':'Text'})\n",
    "df10 = df10.rename(columns={'it_trans':'Text'})\n",
    "df11 = df11.rename(columns={'fr_trans':'Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bd3adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes\n",
    "final_a = pd.concat([df0,df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11], ignore_index=True)\n",
    "\n",
    "# shuffle \n",
    "final_a = final_a.sample(frac=1)\n",
    "\n",
    "# save\n",
    "final_a.to_csv('../../../data/release-files/eng/trac2_eng_train_BT_task_A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eb3074d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OAG    13500\n",
       "NAG    13500\n",
       "CAG    13500\n",
       "Name: Sub-task A, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_a['Sub-task A'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e34d52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40500, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a8107",
   "metadata": {},
   "source": [
    "### Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eadb2c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../../../data/files_back_translation/taskB-NGEN-es.csv')[['Text', 'Sub-task B']]\n",
    "df1 = pd.read_csv('../../../data/files_back_translation/taskB-NGEN-es.csv')[['es_trans', 'Sub-task B']]\n",
    "df2 = pd.read_csv('../../../data/files_back_translation/taskB-NGEN-it.csv')[['it_trans', 'Sub-task B']]\n",
    "df3 = pd.read_csv('../../../data/files_back_translation/taskB-NGEN-fr.csv')[['fr_trans', 'Sub-task B']]\n",
    "\n",
    "df4 = pd.read_csv('../../../data/files_back_translation/taskB-GEN-es.csv')[['Text', 'Sub-task B']]\n",
    "df5 = pd.read_csv('../../../data/files_back_translation/taskB-GEN-es.csv')[['es_trans', 'Sub-task B']]\n",
    "df6 = pd.read_csv('../../../data/files_back_translation/taskB-GEN-it.csv')[['it_trans', 'Sub-task B']]\n",
    "df7 = pd.read_csv('../../../data/files_back_translation/taskB-GEN-fr.csv')[['fr_trans', 'Sub-task B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f212d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "\n",
    "df1 = df1.rename(columns={'es_trans':'Text'})\n",
    "df2 = df2.rename(columns={'it_trans':'Text'})\n",
    "df3 = df3.rename(columns={'fr_trans':'Text'})\n",
    "\n",
    "df5 = df5.rename(columns={'es_trans':'Text'})\n",
    "df6 = df6.rename(columns={'it_trans':'Text'})\n",
    "df7 = df7.rename(columns={'fr_trans':'Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be5e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes\n",
    "final_b = pd.concat([df0,df1,df2,df3,df4,df5,df6,df7], ignore_index=True)\n",
    "\n",
    "# shuffle \n",
    "final_b = final_b.sample(frac=1)\n",
    "\n",
    "# save\n",
    "final_b.to_csv('../../../data/release-files/eng/trac2_eng_train_BT_task_B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ddb8fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NGEN    15816\n",
       "GEN     15816\n",
       "Name: Sub-task B, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_b['Sub-task B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "408906cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31632, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_b.shape"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m79"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
