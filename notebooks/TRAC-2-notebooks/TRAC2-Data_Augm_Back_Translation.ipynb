{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ae47a1",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977beff0",
   "metadata": {},
   "source": [
    "## TRAC-2 Data Augmentation- Back Translation\n",
    "\n",
    "In this notebook we use back traslation techniques to augment our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11227e67",
   "metadata": {},
   "source": [
    "## Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99acad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.1.1 in /opt/conda/lib/python3.7/site-packages (4.1.1)\n",
      "Requirement already satisfied: sentencepiece==0.1.94 in /opt/conda/lib/python3.7/site-packages (0.1.94)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (2021.8.28)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (21.0)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (0.9.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (2.25.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (3.0.12)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (4.62.2)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.1.1) (0.0.45)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.1.1) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.1.1) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.1.1) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.1.1) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.1.1) (2021.5.30)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.1.1) (8.0.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.1.1) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.1.1) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses->transformers==4.1.1) (4.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==4.1.1) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==4.1.1) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.1.1 sentencepiece==0.1.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5369c54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mosestokenizer==1.1.0 in /opt/conda/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0) (0.6.2)\n",
      "Requirement already satisfied: uctools in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0) (1.3.0)\n",
      "Requirement already satisfied: toolwrapper in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0) (2.1.0)\n",
      "Requirement already satisfied: openfile in /opt/conda/lib/python3.7/site-packages (from mosestokenizer==1.1.0) (0.0.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install mosestokenizer==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052702f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the MarianMT model and tokenizer.\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# import pandas and numpys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7152f120",
   "metadata": {},
   "source": [
    "## Models from english to Romance languages and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580df6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MarianMTModel were not initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-ROMANCE and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model that can translate from English to Romance languages\n",
    "# this is a single model that can translate to any of the romance languages\n",
    "\n",
    "target_tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-ROMANCE')\n",
    "target_model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-ROMANCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee742022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MarianMTModel were not initialized from the model checkpoint at Helsinki-NLP/opus-mt-ROMANCE-en and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# initialize models that can translate Romance languages to English.\n",
    "\n",
    "en_tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ROMANCE-en')\n",
    "en_model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ROMANCE-en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eefc48",
   "metadata": {},
   "source": [
    "## Available languages\n",
    "\n",
    "Below is a full list of available languages. The most relevant are: \n",
    "\n",
    "French(fr), Spanish(es), Italian(it), Portuguese(pt), Romanian(ro), Galician(gl), Sardinian(sn), Corsican(co), and many others including spanish from Spain and Latin America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c0f370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>>fr<<',\n",
       " '>>es<<',\n",
       " '>>it<<',\n",
       " '>>pt<<',\n",
       " '>>pt_br<<',\n",
       " '>>ro<<',\n",
       " '>>ca<<',\n",
       " '>>gl<<',\n",
       " '>>pt_BR<<',\n",
       " '>>la<<',\n",
       " '>>wa<<',\n",
       " '>>fur<<',\n",
       " '>>oc<<',\n",
       " '>>fr_CA<<',\n",
       " '>>sc<<',\n",
       " '>>es_ES<<',\n",
       " '>>es_MX<<',\n",
       " '>>es_AR<<',\n",
       " '>>es_PR<<',\n",
       " '>>es_UY<<',\n",
       " '>>es_CL<<',\n",
       " '>>es_CO<<',\n",
       " '>>es_CR<<',\n",
       " '>>es_GT<<',\n",
       " '>>es_HN<<',\n",
       " '>>es_NI<<',\n",
       " '>>es_PA<<',\n",
       " '>>es_PE<<',\n",
       " '>>es_VE<<',\n",
       " '>>es_DO<<',\n",
       " '>>es_EC<<',\n",
       " '>>es_SV<<',\n",
       " '>>an<<',\n",
       " '>>pt_PT<<',\n",
       " '>>frp<<',\n",
       " '>>lad<<',\n",
       " '>>vec<<',\n",
       " '>>fr_FR<<',\n",
       " '>>co<<',\n",
       " '>>it_IT<<',\n",
       " '>>lld<<',\n",
       " '>>lij<<',\n",
       " '>>lmo<<',\n",
       " '>>nap<<',\n",
       " '>>rm<<',\n",
       " '>>scn<<',\n",
       " '>>mwl<<']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available languages\n",
    "target_tokenizer.supported_language_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dada07e7",
   "metadata": {},
   "source": [
    "## Helper functions to translate in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb8cfdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(texts, model, tokenizer, language=\"fr\"):\n",
    "    # Prepare the text data into appropriate format for the model\n",
    "    template = lambda text: f\"{text}\" if language == \"en\" else f\">>{language}<< {text}\"\n",
    "    src_texts = [template(i) for i in texts]\n",
    "\n",
    "    # Tokenize the texts\n",
    "    encoded = tokenizer.prepare_seq2seq_batch(src_texts,return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate translation using model\n",
    "    translated = model.generate(**encoded)\n",
    "\n",
    "    # Convert the generated tokens indices back into text\n",
    "    translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    \n",
    "    return translated_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d27e38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translate(texts, source_lang=\"en\", target_lang=\"fr\"):\n",
    "    # Translate from source to target language\n",
    "    fr_texts = translate(texts, target_model, target_tokenizer, \n",
    "                         language=target_lang)\n",
    "\n",
    "    # Translate from target language back to source language\n",
    "    back_translated_texts = translate(fr_texts, en_model, en_tokenizer, \n",
    "                                      language=source_lang)\n",
    "    \n",
    "    return back_translated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12beef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'd like a cup of coffee.\"]\n"
     ]
    }
   ],
   "source": [
    "# note that even a single text needs to be inside a list\n",
    "single_sentence = ['I would like to have a cup of coffee']\n",
    "\n",
    "aug_texts = back_translate(single_sentence, source_lang=\"en\", target_lang=\"es\")\n",
    "print(aug_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e34fd",
   "metadata": {},
   "source": [
    "## Play a little..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603e2a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I really like this assignment.', \"It's not a great performance.\"]\n"
     ]
    }
   ],
   "source": [
    "# example using back translation to spanish\n",
    "\n",
    "example_texts = ['I like this homework so much', 'this is not a great performance']\n",
    "\n",
    "aug_texts = back_translate(example_texts, source_lang=\"en\", target_lang=\"es\")\n",
    "print(aug_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23c0176a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love homework so much.', \"It's not a great performance.\"]\n"
     ]
    }
   ],
   "source": [
    "# example using back translation to french\n",
    "\n",
    "aug_texts = back_translate(example_texts, source_lang=\"en\", target_lang=\"fr\")\n",
    "\n",
    "print(aug_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a786b978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I really like homework.', \"This isn't a great performance.\"]\n"
     ]
    }
   ],
   "source": [
    "# example using back translation to italian\n",
    "\n",
    "aug_texts = back_translate(example_texts, source_lang=\"en\", target_lang=\"it\")\n",
    "\n",
    "print(aug_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61d9a013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I really like this housework.', \"This isn't a great performance.\"]\n"
     ]
    }
   ],
   "source": [
    "# example using back translation to portuguese\n",
    "\n",
    "aug_texts = back_translate(example_texts, source_lang=\"en\", target_lang=\"pt\")\n",
    "\n",
    "print(aug_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac46ee6",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9893ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all training data\n",
    "train_data = pd.read_csv('../../../data/release-files/eng/trac2_eng_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d539576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C45.451</td>\n",
       "      <td>Next part</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C47.11</td>\n",
       "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C33.79</td>\n",
       "      <td>🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.1961</td>\n",
       "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C10.153</td>\n",
       "      <td>Concerned authorities should bring arundathi R...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text Sub-task A  \\\n",
       "0  C45.451                                          Next part        NAG   \n",
       "1   C47.11                 Iii8mllllllm\\nMdxfvb8o90lplppi0005        NAG   \n",
       "2   C33.79  🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...        NAG   \n",
       "3  C4.1961  What the fuck was this? I respect shwetabh and...        NAG   \n",
       "4  C10.153  Concerned authorities should bring arundathi R...        NAG   \n",
       "\n",
       "  Sub-task B  \n",
       "0       NGEN  \n",
       "1       NGEN  \n",
       "2       NGEN  \n",
       "3       NGEN  \n",
       "4       NGEN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b296baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a column that considers all the possible combination of classes for task A and task B\n",
    "## NAG-NGEN, NAG-GEN, CAG-NGEN, CAG-GEN, OAG-NGEN, OAG-GEN\n",
    "\n",
    "# create a list of conditions\n",
    "conditions = [(train_data['Sub-task A'] == 'NAG') & (train_data['Sub-task B'] == 'NGEN'),\n",
    "              (train_data['Sub-task A'] == 'NAG') & (train_data['Sub-task B'] == 'GEN'), \n",
    "              (train_data['Sub-task A'] == 'CAG') & (train_data['Sub-task B'] == 'NGEN'),\n",
    "              (train_data['Sub-task A'] == 'CAG') & (train_data['Sub-task B'] == 'GEN'),\n",
    "              (train_data['Sub-task A'] == 'OAG') & (train_data['Sub-task B'] == 'NGEN'),\n",
    "              (train_data['Sub-task A'] == 'OAG') & (train_data['Sub-task B'] == 'GEN')\n",
    "             ]\n",
    "           \n",
    "# values for each condition\n",
    "values = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "# create a new column \n",
    "train_data['combined'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ced2482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C45.451</td>\n",
       "      <td>Next part</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C47.11</td>\n",
       "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C33.79</td>\n",
       "      <td>🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.1961</td>\n",
       "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C10.153</td>\n",
       "      <td>Concerned authorities should bring arundathi R...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text Sub-task A  \\\n",
       "0  C45.451                                          Next part        NAG   \n",
       "1   C47.11                 Iii8mllllllm\\nMdxfvb8o90lplppi0005        NAG   \n",
       "2   C33.79  🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...        NAG   \n",
       "3  C4.1961  What the fuck was this? I respect shwetabh and...        NAG   \n",
       "4  C10.153  Concerned authorities should bring arundathi R...        NAG   \n",
       "\n",
       "  Sub-task B  combined  \n",
       "0       NGEN         0  \n",
       "1       NGEN         0  \n",
       "2       NGEN         0  \n",
       "3       NGEN         0  \n",
       "4       NGEN         0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af942a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3241\n",
       "2     418\n",
       "4     295\n",
       "5     140\n",
       "1     134\n",
       "3      35\n",
       "Name: combined, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['combined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e67738ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for each class\n",
    "train_0 = train_data[train_data['combined'] == 0]\n",
    "train_1 = train_data[train_data['combined'] == 1]\n",
    "train_2 = train_data[train_data['combined'] == 2]\n",
    "train_3 = train_data[train_data['combined'] == 3]\n",
    "train_4 = train_data[train_data['combined'] == 4]\n",
    "train_5 = train_data[train_data['combined'] == 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af2ff5",
   "metadata": {},
   "source": [
    "### Data augmentation for combined class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "105afb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# make translations to 5 languages and back to english\n",
    "train_1['es_trans'] = train_1['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='es')[0])\n",
    "train_1['fr_trans'] = train_1['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='fr')[0])\n",
    "train_1['it_trans'] = train_1['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='it')[0])\n",
    "train_1['pt_trans'] = train_1['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='pt')[0])\n",
    "train_1['ro_trans'] = train_1['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='ro')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "065430a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "train_1.to_csv('../../../data/augm/train_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313aef5e",
   "metadata": {},
   "source": [
    "### Data augmentation for combined class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56191e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# make translations to 5 languages and back to english\n",
    "train_2['es_trans'] = train_2['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='es')[0])\n",
    "train_2['fr_trans'] = train_2['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='fr')[0])\n",
    "train_2['it_trans'] = train_2['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='it')[0])\n",
    "train_2['pt_trans'] = train_2['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='pt')[0])\n",
    "train_2['ro_trans'] = train_2['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='ro')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ade4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "train_2.to_csv('../../../data/augm/train_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c493abb",
   "metadata": {},
   "source": [
    "### Data augmentation for combined class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9831873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make translations to 5 languages and back to english\n",
    "train_3['es_trans'] = train_3['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='es')[0])\n",
    "train_3['fr_trans'] = train_3['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='fr')[0])\n",
    "train_3['it_trans'] = train_3['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='it')[0])\n",
    "train_3['pt_trans'] = train_3['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='pt')[0])\n",
    "train_3['ro_trans'] = train_3['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='ro')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "438104fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "train_3.to_csv('../../../data/augm/train_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace2938",
   "metadata": {},
   "source": [
    "### Data augmentation for combined class 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef48af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# make translations to 5 languages and back to english\n",
    "train_4['es_trans'] = train_4['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='es')[0])\n",
    "train_4['fr_trans'] = train_4['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='fr')[0])\n",
    "train_4['it_trans'] = train_4['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='it')[0])\n",
    "train_4['pt_trans'] = train_4['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='pt')[0])\n",
    "train_4['ro_trans'] = train_4['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='ro')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f15a7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "train_4.to_csv('../../../data/augm/train_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1798c",
   "metadata": {},
   "source": [
    "### Data augmentation for combined class 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b15773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# make translations to 5 languages and back to english\n",
    "train_5['es_trans'] = train_5['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='es')[0])\n",
    "train_5['fr_trans'] = train_5['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='fr')[0])\n",
    "train_5['it_trans'] = train_5['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='it')[0])\n",
    "train_5['pt_trans'] = train_5['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='pt')[0])\n",
    "train_5['ro_trans'] = train_5['Text'].apply(lambda x: back_translate([x], source_lang='en', target_lang='ro')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41fa309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "train_5.to_csv('../../../data/augm/train_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40afaad7",
   "metadata": {},
   "source": [
    "## Load all data back and create the new training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c710fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4417ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined class 0 is not backtranslated (majority class)\n",
    "train_0 = pd.read_csv('../../../data/release-files/eng/trac2_eng_train.csv')\n",
    "train_0 = train_0[(train_0['Sub-task A'] == 'NAG') & (train_0['Sub-task B'] == 'NGEN')]\n",
    "# Load all the other combined classes\n",
    "train_1 = pd.read_csv('../../../data/augm/train_1.csv')\n",
    "train_2 = pd.read_csv('../../../data/augm/train_2.csv')\n",
    "train_3 = pd.read_csv('../../../data/augm/train_3.csv')\n",
    "train_4 = pd.read_csv('../../../data/augm/train_4.csv')\n",
    "train_5 = pd.read_csv('../../../data/augm/train_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d00d31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C45.451</td>\n",
       "      <td>Next part</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C47.11</td>\n",
       "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C33.79</td>\n",
       "      <td>🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.1961</td>\n",
       "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C10.153</td>\n",
       "      <td>Concerned authorities should bring arundathi R...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text Sub-task A  \\\n",
       "0  C45.451                                          Next part        NAG   \n",
       "1   C47.11                 Iii8mllllllm\\nMdxfvb8o90lplppi0005        NAG   \n",
       "2   C33.79  🤣🤣😂😂🤣🤣🤣😂osm vedio ....keep it up...make more v...        NAG   \n",
       "3  C4.1961  What the fuck was this? I respect shwetabh and...        NAG   \n",
       "4  C10.153  Concerned authorities should bring arundathi R...        NAG   \n",
       "\n",
       "  Sub-task B  \n",
       "0       NGEN  \n",
       "1       NGEN  \n",
       "2       NGEN  \n",
       "3       NGEN  \n",
       "4       NGEN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4da70fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "      <th>combined</th>\n",
       "      <th>es_trans</th>\n",
       "      <th>fr_trans</th>\n",
       "      <th>it_trans</th>\n",
       "      <th>pt_trans</th>\n",
       "      <th>ro_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C10.967.5</td>\n",
       "      <td>Ram Raja - she is a female dog - who can’t eve...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>GEN</td>\n",
       "      <td>5</td>\n",
       "      <td>Ram Raja - she's a bitch - who can't even keep...</td>\n",
       "      <td>Ram Raja - she's a bitch - who can't even keep...</td>\n",
       "      <td>Ram Raja - she's a bitch - who can't even hold...</td>\n",
       "      <td>Ram Raja - she's a dog - who can't even keep a...</td>\n",
       "      <td>Ram Raja - she's a female dog - who can't even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C20.110</td>\n",
       "      <td>One word for u bhaad me jaa chudail</td>\n",
       "      <td>OAG</td>\n",
       "      <td>GEN</td>\n",
       "      <td>5</td>\n",
       "      <td>A word for or bhaad me jaa chudail</td>\n",
       "      <td>A word for u bhaad me jaa chudail</td>\n",
       "      <td>A word for bhaad me jaa chudail</td>\n",
       "      <td>A word for the bhaad me jaa chudail</td>\n",
       "      <td>A word for me jaa chudail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C9.58</td>\n",
       "      <td>This whore is a member of psuedo intellectual ...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>GEN</td>\n",
       "      <td>5</td>\n",
       "      <td>This whore is a member of a centuries-old inte...</td>\n",
       "      <td>This whore is a member of a psuedo secular int...</td>\n",
       "      <td>This whore is a member of the secular intellec...</td>\n",
       "      <td>This prostitute is a member of the pseudo secu...</td>\n",
       "      <td>This whore is a member of the centuries-old ps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4.1652</td>\n",
       "      <td>Fuck feminism !</td>\n",
       "      <td>OAG</td>\n",
       "      <td>GEN</td>\n",
       "      <td>5</td>\n",
       "      <td>Fuck feminism!</td>\n",
       "      <td>Damn feminism!</td>\n",
       "      <td>Fuck feminism!</td>\n",
       "      <td>Fuck feminism!</td>\n",
       "      <td>Fuck feminism!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C26.171</td>\n",
       "      <td>He should have also killed that bitch</td>\n",
       "      <td>OAG</td>\n",
       "      <td>GEN</td>\n",
       "      <td>5</td>\n",
       "      <td>I should have killed that bitch, too.</td>\n",
       "      <td>He should have killed that bitch, too.</td>\n",
       "      <td>You should have killed that bitch, too.</td>\n",
       "      <td>He should have killed that bitch, too.</td>\n",
       "      <td>He should have killed that bitch, too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>C20.265</td>\n",
       "      <td>You,re a bitch</td>\n",
       "      <td>OAG</td>\n",
       "      <td>GEN</td>\n",
       "      <td>5</td>\n",
       "      <td>You're a bitch.</td>\n",
       "      <td>You're a bitch.</td>\n",
       "      <td>You're a bitch.</td>\n",
       "      <td>You, you're a bitch.</td>\n",
       "      <td>You're a bitch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>C43.167.1</td>\n",
       "      <td>@Baraqua Amina Levy-Khan So is prests raping c...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>GEN</td>\n",
       "      <td>5</td>\n",
       "      <td>@Baraqua Amina Levy-Khan So presidents rape ch...</td>\n",
       "      <td>@Baraqua Amina Levy-Khan So, violent loan chil...</td>\n",
       "      <td>@Baraqua Amina Levy-Khan So it's Prest raping ...</td>\n",
       "      <td>@Baraqua Amina Levy-Khan So Prestes raping chi...</td>\n",
       "      <td>@Baraqua Amina Levy-Khan Asa is ready to rape ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>C20.62</td>\n",
       "      <td>Fuck u and your reviews.....</td>\n",
       "      <td>OAG</td>\n",
       "      <td>GEN</td>\n",
       "      <td>5</td>\n",
       "      <td>Fuck you and your criticisms..</td>\n",
       "      <td>Fuck you and your comments..</td>\n",
       "      <td>Fuck you and your reviews..</td>\n",
       "      <td>Fuck you and your criticisms.</td>\n",
       "      <td>Fuck your reviews.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>C38.448</td>\n",
       "      <td>Open bob and vagane</td>\n",
       "      <td>OAG</td>\n",
       "      <td>GEN</td>\n",
       "      <td>5</td>\n",
       "      <td>Open bob and vag</td>\n",
       "      <td>Open Bob and Vagina</td>\n",
       "      <td>Open the bob and the vag</td>\n",
       "      <td>Open Bob and Vagane</td>\n",
       "      <td>Open Bob and Vagina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>C10.123</td>\n",
       "      <td>Abey loudey Arnab... Did u ever see the vedios...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>GEN</td>\n",
       "      <td>5</td>\n",
       "      <td>Abey lovey Arnab... Have you ever seen the hij...</td>\n",
       "      <td>Abey Sweoley Arnab... Have you ever seen the h...</td>\n",
       "      <td>Abey lovey Arnab... you've never seen the sees...</td>\n",
       "      <td>Abey sweoley Arnab... you've seen the hijdi fe...</td>\n",
       "      <td>Abey Sweoley Arnab... have you ever seen the h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text Sub-task A  \\\n",
       "0    C10.967.5  Ram Raja - she is a female dog - who can’t eve...        OAG   \n",
       "1      C20.110                One word for u bhaad me jaa chudail        OAG   \n",
       "2        C9.58  This whore is a member of psuedo intellectual ...        OAG   \n",
       "3      C4.1652                                    Fuck feminism !        OAG   \n",
       "4      C26.171              He should have also killed that bitch        OAG   \n",
       "..         ...                                                ...        ...   \n",
       "135    C20.265                                     You,re a bitch        OAG   \n",
       "136  C43.167.1  @Baraqua Amina Levy-Khan So is prests raping c...        OAG   \n",
       "137     C20.62                       Fuck u and your reviews.....        OAG   \n",
       "138    C38.448                                Open bob and vagane        OAG   \n",
       "139    C10.123  Abey loudey Arnab... Did u ever see the vedios...        OAG   \n",
       "\n",
       "    Sub-task B  combined                                           es_trans  \\\n",
       "0          GEN         5  Ram Raja - she's a bitch - who can't even keep...   \n",
       "1          GEN         5                 A word for or bhaad me jaa chudail   \n",
       "2          GEN         5  This whore is a member of a centuries-old inte...   \n",
       "3          GEN         5                                     Fuck feminism!   \n",
       "4          GEN         5              I should have killed that bitch, too.   \n",
       "..         ...       ...                                                ...   \n",
       "135        GEN         5                                    You're a bitch.   \n",
       "136        GEN         5  @Baraqua Amina Levy-Khan So presidents rape ch...   \n",
       "137        GEN         5                     Fuck you and your criticisms..   \n",
       "138        GEN         5                                   Open bob and vag   \n",
       "139        GEN         5  Abey lovey Arnab... Have you ever seen the hij...   \n",
       "\n",
       "                                              fr_trans  \\\n",
       "0    Ram Raja - she's a bitch - who can't even keep...   \n",
       "1                    A word for u bhaad me jaa chudail   \n",
       "2    This whore is a member of a psuedo secular int...   \n",
       "3                                       Damn feminism!   \n",
       "4               He should have killed that bitch, too.   \n",
       "..                                                 ...   \n",
       "135                                    You're a bitch.   \n",
       "136  @Baraqua Amina Levy-Khan So, violent loan chil...   \n",
       "137                       Fuck you and your comments..   \n",
       "138                                Open Bob and Vagina   \n",
       "139  Abey Sweoley Arnab... Have you ever seen the h...   \n",
       "\n",
       "                                              it_trans  \\\n",
       "0    Ram Raja - she's a bitch - who can't even hold...   \n",
       "1                      A word for bhaad me jaa chudail   \n",
       "2    This whore is a member of the secular intellec...   \n",
       "3                                       Fuck feminism!   \n",
       "4              You should have killed that bitch, too.   \n",
       "..                                                 ...   \n",
       "135                                    You're a bitch.   \n",
       "136  @Baraqua Amina Levy-Khan So it's Prest raping ...   \n",
       "137                        Fuck you and your reviews..   \n",
       "138                           Open the bob and the vag   \n",
       "139  Abey lovey Arnab... you've never seen the sees...   \n",
       "\n",
       "                                              pt_trans  \\\n",
       "0    Ram Raja - she's a dog - who can't even keep a...   \n",
       "1                  A word for the bhaad me jaa chudail   \n",
       "2    This prostitute is a member of the pseudo secu...   \n",
       "3                                       Fuck feminism!   \n",
       "4               He should have killed that bitch, too.   \n",
       "..                                                 ...   \n",
       "135                               You, you're a bitch.   \n",
       "136  @Baraqua Amina Levy-Khan So Prestes raping chi...   \n",
       "137                      Fuck you and your criticisms.   \n",
       "138                                Open Bob and Vagane   \n",
       "139  Abey sweoley Arnab... you've seen the hijdi fe...   \n",
       "\n",
       "                                              ro_trans  \n",
       "0    Ram Raja - she's a female dog - who can't even...  \n",
       "1                            A word for me jaa chudail  \n",
       "2    This whore is a member of the centuries-old ps...  \n",
       "3                                       Fuck feminism!  \n",
       "4               He should have killed that bitch, too.  \n",
       "..                                                 ...  \n",
       "135                                    You're a bitch.  \n",
       "136  @Baraqua Amina Levy-Khan Asa is ready to rape ...  \n",
       "137                                 Fuck your reviews.  \n",
       "138                                Open Bob and Vagina  \n",
       "139  Abey Sweoley Arnab... have you ever seen the h...  \n",
       "\n",
       "[140 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f37e683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(df):\n",
    "    '''\n",
    "    Returns a dataframe with all translations as rows and not columns.\n",
    "    '''\n",
    "    df0 = df[['ID','Text', 'Sub-task A', 'Sub-task B']]\n",
    "    df1 = df[['ID','es_trans', 'Sub-task A', 'Sub-task B']].rename(columns={'es_trans':'Text'})\n",
    "    df2 = df[['ID','fr_trans', 'Sub-task A', 'Sub-task B']].rename(columns={'fr_trans':'Text'})\n",
    "    df3 = df[['ID','it_trans', 'Sub-task A', 'Sub-task B']].rename(columns={'it_trans':'Text'})\n",
    "    df4 = df[['ID','pt_trans', 'Sub-task A', 'Sub-task B']].rename(columns={'pt_trans':'Text'})\n",
    "    df5 = df[['ID','ro_trans', 'Sub-task A', 'Sub-task B']].rename(columns={'ro_trans':'Text'})\n",
    "    \n",
    "    # concatenate dataframes\n",
    "    result = pd.concat([df0,df1,df2,df3,df4,df5])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aae61ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "train_1_reshaped = reshape_data(train_1)\n",
    "train_2_reshaped = reshape_data(train_2)\n",
    "train_3_reshaped = reshape_data(train_3)\n",
    "train_4_reshaped = reshape_data(train_4)\n",
    "train_5_reshaped = reshape_data(train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae537fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate final dataframe with back-translations\n",
    "final_df = pd.concat([train_0, train_1_reshaped, train_2_reshaped, \n",
    "                      train_3_reshaped, train_4_reshaped, train_5_reshaped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df03c33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9373, 4)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce30db08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAG    0.431559\n",
       "CAG    0.289982\n",
       "OAG    0.278459\n",
       "Name: Sub-task A, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review new distribution of classes for Task-A\n",
    "final_df['Sub-task A'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f229dfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NGEN    0.802198\n",
       "GEN     0.197802\n",
       "Name: Sub-task B, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review new distribution of classes for Task-B\n",
    "final_df['Sub-task B'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b15bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../../../data/release-files/eng/trac2_eng_train_augm_backt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a15ba6",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febfd086",
   "metadata": {},
   "source": [
    "- Text data augmentation: https://amitness.com/back-translation/"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m79"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
