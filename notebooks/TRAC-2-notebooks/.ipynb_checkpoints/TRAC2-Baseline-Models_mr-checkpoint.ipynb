{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3722dc",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bac5fd",
   "metadata": {},
   "source": [
    "## TRAC2- Baseline Models\n",
    "\n",
    "In this notebook we build the baseline models for the TRAC-2 dataset. \n",
    "\n",
    "Characteristics of the models:\n",
    "- Neural Bag of Words architecture\n",
    "- A single dense layer with dropout\n",
    "- Use Glove embeddings (dim=300) without fine tuning them\n",
    "- Maximum sequence length is 150\n",
    "- Use keras tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d694f4e",
   "metadata": {},
   "source": [
    "## Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52044815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda, Dropout\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import tensorflow.keras.backend as K\n",
    "# for hyperparameter tunning\n",
    "# from keras_tuner import HyperModel\n",
    "# import keras_tuner as kt\n",
    "# import sklearn to calculate the metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69ddf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3a748",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Load training, development and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1cd31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aggressiveness dataset\n",
    "train_data = pd.read_csv('../../../data/release-files/eng/trac2_eng_train.csv')\n",
    "dev_data = pd.read_csv('../../../data/release-files/eng/trac2_eng_dev.csv')\n",
    "\n",
    "# test data data and labels is in separate files\n",
    "test_data = pd.read_csv('../../../data/release-files/test/trac2_eng_test.csv')\n",
    "test_labels_a = pd.read_csv('../../../data/release-files/gold/trac2_eng_gold_a.csv')\n",
    "test_labels_b = pd.read_csv('../../../data/release-files/gold/trac2_eng_gold_b.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d553f77d",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c3eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_prob_to_labels(model, x, task):\n",
    "    '''\n",
    "    Returns labels based on predicted probability on labels [CAG,NAG,OAG] for task A. Task B is binary, and 'GEN' represents \n",
    "    the positive class.\n",
    "    Parameters:\n",
    "    model: trained model\n",
    "    x: input data\n",
    "    task: either 'A' or 'B'\n",
    "    '''\n",
    "    pred = model.predict(x)\n",
    "    \n",
    "    index_a = {0:'CAG', 1:'NAG', 2:'OAG'}\n",
    "    \n",
    "    if task == 'A':\n",
    "        highest_prob_class = np.argmax(pred, axis=1)\n",
    "        labels = np.vectorize(index_a.get)(highest_prob_class.astype(int))\n",
    "        \n",
    "    elif task == 'B':\n",
    "        labels = np.where(pred <0.5, 'NGEN', 'GEN')\n",
    "    else:\n",
    "        labels = []\n",
    "        \n",
    "    return labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f8cd562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary_labels(string_labels, classes_list):\n",
    "    '''\n",
    "    Returns an array with 0 and 1 for a binary classification problem.\n",
    "    Parameters:\n",
    "    string_labels: array with 2 categories defined as strings e.g. ['cat', 'dog', 'dog', ...] \n",
    "    classes_list: array with the two classes. The order of the array defines which gets 0 and which gets 1. The first\n",
    "                  gets 0.\n",
    "    '''\n",
    "\n",
    "    labels = label_binarize(string_labels, classes = classes_list).flatten()\n",
    "    \n",
    "    return labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176911c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot_labels(string_labels):\n",
    "    '''\n",
    "    Returns one-hot encoded labels from a multi-class label vector e.g. ['cat', 'dog', 'dog', 'lion', 'cat', ...] \n",
    "    Parameters:\n",
    "    string_labels: \n",
    "    '''\n",
    "    labels = pd.get_dummies(string_labels)\n",
    "    labels = labels.to_numpy()\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97840fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(model, input_data, true_labels, task, normalize=None):\n",
    "    '''\n",
    "    Returns a confusion matrix with a nice format.\n",
    "    Parameters:\n",
    "    model: trained model\n",
    "    input data: data we want to use to evaluate the model\n",
    "    true_labels: true labels \n",
    "    task: 'A' or 'B'\n",
    "    normalize: if want to normalize the confusion matrix normalize='true'\n",
    "    '''\n",
    "    \n",
    "    # get predicted labels\n",
    "    pred_labels = from_prob_to_labels(model, input_data, task)\n",
    "    \n",
    "    # Create a confusion matrix\n",
    "    cm = metrics.confusion_matrix(true_labels, pred_labels, normalize=normalize)\n",
    "    cm = np.around(cm, 2)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    if task == 'A':\n",
    "        axis_labels = ['CAG', 'NAG', 'OAG']\n",
    "    elif task == 'B':\n",
    "        axis_labels = ['GEN', 'NGEN']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    im = ax.imshow(cm, cmap=\"Blues\")\n",
    "\n",
    "    # Create the ticks and labels\n",
    "    ax.set_xticks(np.arange(len(axis_labels)))\n",
    "    ax.set_yticks(np.arange(len(axis_labels)))\n",
    "    ax.set_xticklabels(axis_labels)\n",
    "    ax.set_yticklabels(axis_labels)\n",
    "\n",
    "    # Axis titles\n",
    "    plt.ylabel('True label', size=12)\n",
    "    plt.xlabel('Predicted label', size=12)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(axis_labels)):\n",
    "        for j in range(len(axis_labels)):\n",
    "            text = ax.text(j, i, cm[i, j],ha=\"center\", va=\"center\", color=\"dimgrey\", size=12)\n",
    "    \n",
    "    ax.set_title(\"Confusion Matrix\", size=16, weight=\"bold\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3879a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_accuracy_plots(training_history, xrange, task):\n",
    "    '''\n",
    "    Returns plots for loss and accuracy during the training process of a NN.\n",
    "    Parameters:\n",
    "    training_history: object that stores the training history of the NN (from model.fit(...))\n",
    "    xrange: range in x axis\n",
    "    task: string used for the title in the plot\n",
    "    '''\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n",
    "    \n",
    "    # loss plot\n",
    "    ax1.plot(training_history.history['loss'], color='black')\n",
    "    ax1.plot(training_history.history['val_loss'], color='blue')\n",
    "    ax1.set_title('Training and validation loss Sub-Task ' + task)\n",
    "    ax1.legend(['training', 'development'])\n",
    "    ax1.grid(which='both')\n",
    "    ax1.set_xticks(np.arange(0, xrange, 2))\n",
    "    \n",
    "    # accuracy plot\n",
    "    if task == 'A':\n",
    "        ax2.plot(training_history.history['categorical_accuracy'], color='black')\n",
    "        ax2.plot(training_history.history['val_categorical_accuracy'], color='blue')\n",
    "        ax2.set_title('Training and validation acccuracy Sub_Task ' + task)\n",
    "        ax2.legend(['training', 'development'])\n",
    "        ax2.grid(which='both')\n",
    "        ax2.set_xticks(np.arange(0, xrange, 2))\n",
    "    elif task == 'B':\n",
    "        ax2.plot(training_history.history['binary_accuracy'], color='black')\n",
    "        ax2.plot(training_history.history['val_binary_accuracy'], color='blue')\n",
    "        ax2.set_title('Training and validation acccuracy Sub_Task ' + task)\n",
    "        ax2.legend(['training', 'development'])\n",
    "        ax2.grid(which='both')\n",
    "        ax2.set_xticks(np.arange(0, xrange, 2))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4013e70",
   "metadata": {},
   "source": [
    "## Prepare the data for modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44eb4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arrays of text examples for train, development and test data\n",
    "train_text = np.array(train_data['Text'])\n",
    "dev_text = np.array(dev_data['Text'])\n",
    "test_text = np.array(test_data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61965304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arrays of labels for train, development and test data\n",
    "\n",
    "# Sub-Task A\n",
    "train_labels_a = np.array(train_data['Sub-task A'])\n",
    "dev_labels_a = np.array(dev_data['Sub-task A'])\n",
    "test_labels_a = np.array(test_labels_a['Sub-task A'])\n",
    "\n",
    "# Sub-Task B\n",
    "# create arrays of labels for train, development and test data\n",
    "train_labels_b = np.array(train_data['Sub-task B'])\n",
    "dev_labels_b = np.array(dev_data['Sub-task B'])\n",
    "test_labels_b = np.array(test_labels_b['Sub-task B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f08770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels\n",
    "\n",
    "# Sub-Task A - [CAG,NAG,OAG]\n",
    "train_labels_a_enc = to_one_hot_labels(train_labels_a)\n",
    "dev_labels_a_enc = to_one_hot_labels(dev_labels_a)\n",
    "test_labels_a_enc = to_one_hot_labels(test_labels_a)\n",
    "\n",
    "# Sub-Task B\n",
    "# encode the labels. As this is a binary classification we use binary labels 0:NGEN, 1:GEN\n",
    "train_labels_b_enc = to_binary_labels(train_labels_b, classes_list=['NGEN', 'GEN'])\n",
    "dev_labels_b_enc = to_binary_labels(dev_labels_b, classes_list=['NGEN', 'GEN'])\n",
    "test_labels_b_enc = to_binary_labels(test_labels_b, classes_list=['NGEN', 'GEN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4e7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings. In this case Glove\n",
    "# This is commented out to avoid downloading it again\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip -P ~/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a8914d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the file\n",
    "# commented out for the same reason above\n",
    "# !unzip ~/data/glove.6B.zip -d ~/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda7f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to glove file- will use the embeddings with dimension = 300\n",
    "glove_file =\"../../../data/glove6B/glove.6B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55ea1aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 07:12:31.221072: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-10-20 07:12:31.221156: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# create a vocabulary index \n",
    "# consider this maximum number of words- Played with larger vocab sizes, but 10,000 is enough.\n",
    "max_tokens = 10000\n",
    "# truncate or pad sequences to be this long\n",
    "max_sequence_lenght = 150\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=max_tokens, output_sequence_length=max_sequence_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc29007a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 07:12:31.248825: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-20 07:12:31.249023: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-10-20 07:12:31.276697: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# train vocabulary\n",
    "vectorizer.adapt(train_text)\n",
    "\n",
    "# save vocabulary in a variable\n",
    "vocab = vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ef53f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has 10000 words.\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocabulary has {len(vocab)} words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23dea0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index for each word {word: index}\n",
    "word_idx = dict(zip(vocab, range(len(vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23f4d785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings available: 400000\n"
     ]
    }
   ],
   "source": [
    "# Map words with their vector representation (embeddings)\n",
    "embeddings_glove = {}\n",
    "with open(glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_glove[word] = coefs\n",
    "\n",
    "print(f'Number of embeddings available: {len(embeddings_glove)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08570e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to check let's get the dimensions of one of the embeddings\n",
    "embeddings_glove['home'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a46f124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words with embeddings found: 6928\n",
      "Number of words with embeddings NOT found: 3072\n"
     ]
    }
   ],
   "source": [
    "# build embedding matrix to use it in the model\n",
    "dimensions_emb = 300\n",
    "# the plus two is for padding and unknown tokens\n",
    "total_tokens = len(vocab) + 2\n",
    "with_embedding = []\n",
    "without_embedding = []\n",
    "\n",
    "# initialize embedding matrix with zeroes\n",
    "embedding_matrix = np.zeros((total_tokens, dimensions_emb))\n",
    "\n",
    "for word, index in word_idx.items():\n",
    "    emb_vector = embeddings_glove.get(word)\n",
    "    # add to matrix\n",
    "    # count converted and not converted words\n",
    "    if emb_vector is not None:\n",
    "        embedding_matrix[index] = emb_vector\n",
    "        with_embedding.append(word)\n",
    "    else:\n",
    "        without_embedding.append(word)\n",
    "\n",
    "print(f'Number of words with embeddings found: {len(with_embedding)}')\n",
    "print(f'Number of words with embeddings NOT found: {len(without_embedding)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a6a9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data for the model\n",
    "# convert the train sentences to sequences of ids\n",
    "train_input = vectorizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ff99674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4263, 150])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dimensions\n",
    "# looks good: number examples and 150 max lenght\n",
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5b2705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for development and test data\n",
    "dev_input = vectorizer(dev_text)\n",
    "test_input = vectorizer(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0cf348",
   "metadata": {},
   "source": [
    "## Model Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e618941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 07:12:44.848006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:12:46.062266: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:13:30.271749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:13:30.520189: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:13:31.341624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:14:16.906523: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:14:17.172589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:14:17.973739: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:15:02.652906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:15:02.915199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:15:03.743196: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:15:48.165157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:15:48.598397: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:15:49.448786: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class NAG\n",
      "Mean f1-score = 0.806\n",
      "Standard deviation f1-score = 0.017\n",
      "\n",
      "Class CAG\n",
      "Mean f1-score = 0.128\n",
      "Standard deviation f1-score = 0.106\n",
      "\n",
      "Class OAG\n",
      "Mean f1-score = 0.58\n",
      "Standard deviation f1-score = 0.049\n",
      "\n",
      "Class Macro\n",
      "Mean f1-score = 0.505\n",
      "Standard deviation f1-score = 0.056\n",
      "\n",
      "Class Weighted\n",
      "Mean f1-score = 0.626\n",
      "Standard deviation f1-score = 0.04\n",
      "\n",
      "Accuracy\n",
      "Mean = 0.693\n",
      "Standard deviation = 0.024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 07:16:34.384884: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to keep statistics of all runs\n",
    "f1_NAG = []\n",
    "f1_CAG = []\n",
    "f1_OAG = []\n",
    "f1_macro = []\n",
    "f1_weighted = []\n",
    "accuracy = []\n",
    "\n",
    "for i in range(5):\n",
    "    # delete model if exists\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # sequential model\n",
    "    model = tf.keras.Sequential()\n",
    "        \n",
    "    # embedding layer\n",
    "    model.add(Embedding(embedding_matrix.shape[0],\n",
    "                        embedding_matrix.shape[1],\n",
    "                        embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                        input_length=max_sequence_lenght,\n",
    "                        trainable=False))\n",
    "        \n",
    "    # average embedding vectors\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1))) \n",
    "        \n",
    "    # hidden layer\n",
    "    model.add(Dense(units=10, activation='relu'))\n",
    "\n",
    "    # dropout layer \n",
    "    model.add(Dropout(0.3))\n",
    "        \n",
    "    # output layer \n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                  metrics=[tf.keras.metrics.categorical_accuracy, 'categorical_crossentropy'])\n",
    "    \n",
    "    # train model\n",
    "    training_history = model.fit(train_input, train_labels_a_enc, \n",
    "                                 validation_data=(dev_input, dev_labels_a_enc), \n",
    "                                 epochs=50, verbose=0)\n",
    "    \n",
    "    # evaluate model\n",
    "    pred_labels_test_a = from_prob_to_labels(model, test_input, 'A')\n",
    "    \n",
    "    x = metrics.classification_report(test_labels_a, pred_labels_test_a, digits=3, output_dict=True)\n",
    "\n",
    "    # append values to keep scores\n",
    "    f1_NAG.append(x['NAG']['f1-score'])\n",
    "    f1_CAG.append(x['CAG']['f1-score'])\n",
    "    f1_OAG.append(x['OAG']['f1-score'])\n",
    "    f1_macro.append(x['macro avg']['f1-score'])\n",
    "    f1_weighted.append(x['weighted avg']['f1-score'])\n",
    "    accuracy.append(x['accuracy'])\n",
    "\n",
    "# calculate mean\n",
    "f1_NAG_mean = round(statistics.mean(f1_NAG), 3)\n",
    "f1_CAG_mean = round(statistics.mean(f1_CAG), 3)\n",
    "f1_OAG_mean = round(statistics.mean(f1_OAG), 3)\n",
    "f1_macro_mean = round(statistics.mean(f1_macro), 3)\n",
    "f1_weighted_mean = round(statistics.mean(f1_weighted), 3)\n",
    "accuracy_mean = round(statistics.mean(accuracy), 3)\n",
    "\n",
    "# calculate standard deviation\n",
    "f1_NAG_std = round(statistics.stdev(f1_NAG), 3)\n",
    "f1_CAG_std = round(statistics.stdev(f1_CAG), 3)\n",
    "f1_OAG_std = round(statistics.stdev(f1_OAG), 3)\n",
    "f1_macro_std = round(statistics.stdev(f1_macro), 3)\n",
    "f1_weighted_std = round(statistics.stdev(f1_weighted), 3)\n",
    "accuracy_std = round(statistics.stdev(accuracy), 3)\n",
    "\n",
    "print('Class NAG')\n",
    "print(f'Mean f1-score = {f1_NAG_mean}')\n",
    "print(f'Standard deviation f1-score = {f1_NAG_std}\\n')\n",
    "\n",
    "print('Class CAG')\n",
    "print(f'Mean f1-score = {f1_CAG_mean}')\n",
    "print(f'Standard deviation f1-score = {f1_CAG_std}\\n')\n",
    "\n",
    "print('Class OAG')\n",
    "print(f'Mean f1-score = {f1_OAG_mean}')\n",
    "print(f'Standard deviation f1-score = {f1_OAG_std}\\n')\n",
    "\n",
    "print('Class Macro')\n",
    "print(f'Mean f1-score = {f1_macro_mean}')\n",
    "print(f'Standard deviation f1-score = {f1_macro_std}\\n')\n",
    "\n",
    "print('Class Weighted')\n",
    "print(f'Mean f1-score = {f1_weighted_mean}')\n",
    "print(f'Standard deviation f1-score = {f1_weighted_std}\\n')\n",
    "\n",
    "print('Accuracy')\n",
    "print(f'Mean = {accuracy_mean}')\n",
    "print(f'Standard deviation = {accuracy_std}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfae34",
   "metadata": {},
   "source": [
    "## Model Task B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a44e17ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 07:16:34.732539: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:16:36.493436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:17:14.391872: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:17:14.664874: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:17:15.448488: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:17:53.561038: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:17:53.819636: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:17:54.628705: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:18:32.618030: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/isabel/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/isabel/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/isabel/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-10-20 07:18:32.871749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:18:33.691044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:19:11.738044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:19:11.999268: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-10-20 07:19:12.805763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class NGEN\n",
      "Mean f1-score = 0.924\n",
      "Standard deviation f1-score = 0.004\n",
      "\n",
      "Class GEN\n",
      "Mean f1-score = 0.279\n",
      "Standard deviation f1-score = 0.256\n",
      "\n",
      "Macro\n",
      "Mean f1-score = 0.602\n",
      "Standard deviation f1-score = 0.129\n",
      "\n",
      "Weighted\n",
      "Mean f1-score = 0.83\n",
      "Standard deviation f1-score = 0.04\n",
      "\n",
      "Accuracy\n",
      "Mean = 0.864\n",
      "Standard deviation = 0.01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 07:19:50.628329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/isabel/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/isabel/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/isabel/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to keep statistics of all runs\n",
    "f1_NGEN = []\n",
    "f1_GEN = []\n",
    "f1_macro_b = []\n",
    "f1_weighted_b = []\n",
    "accuracy_b = []\n",
    "\n",
    "for i in range(5):\n",
    "    # delete model if exists\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # sequential model\n",
    "    model = tf.keras.Sequential()\n",
    "        \n",
    "    # embedding layer\n",
    "    model.add(Embedding(embedding_matrix.shape[0],\n",
    "                        embedding_matrix.shape[1],\n",
    "                        embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                        input_length=max_sequence_lenght,\n",
    "                        trainable=False))\n",
    "        \n",
    "    # average embedding vectors\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1))) \n",
    "        \n",
    "    # hidden layer\n",
    "    model.add(Dense(units=9, activation='relu'))\n",
    "\n",
    "    # dropout layer \n",
    "    model.add(Dropout(0.2))\n",
    "        \n",
    "    # output layer \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy', 'binary_crossentropy'])\n",
    "    \n",
    "    # train the model and store the training history\n",
    "    training_history = model.fit(train_input, train_labels_b_enc, \n",
    "                                 validation_data=(dev_input, dev_labels_b_enc), \n",
    "                                 epochs=50, verbose=0)\n",
    "    \n",
    "    # evaluate model\n",
    "    pred_labels_test_b = from_prob_to_labels(model, test_input, 'B')\n",
    "    \n",
    "    x = metrics.classification_report(test_labels_b, pred_labels_test_b, digits=3, output_dict=True)\n",
    "    \n",
    "    # append values to keep scores\n",
    "    f1_NGEN.append(x['NGEN']['f1-score'])\n",
    "    f1_GEN.append(x['GEN']['f1-score'])\n",
    "    f1_macro_b.append(x['macro avg']['f1-score'])\n",
    "    f1_weighted_b.append(x['weighted avg']['f1-score'])\n",
    "    accuracy_b.append(x['accuracy'])\n",
    "\n",
    "# calculate mean\n",
    "f1_NGEN_mean = round(statistics.mean(f1_NGEN), 3)\n",
    "f1_GEN_mean = round(statistics.mean(f1_GEN), 3)\n",
    "f1_macro_b_mean = round(statistics.mean(f1_macro_b), 3)\n",
    "f1_weighted_b_mean = round(statistics.mean(f1_weighted_b), 3)\n",
    "accuracy_b_mean = round(statistics.mean(accuracy_b), 3)\n",
    "\n",
    "# calculate standard deviation\n",
    "f1_NGEN_std = round(statistics.stdev(f1_NGEN), 3)\n",
    "f1_GEN_std = round(statistics.stdev(f1_GEN), 3)\n",
    "f1_macro_b_std = round(statistics.stdev(f1_macro_b), 3)\n",
    "f1_weighted_b_std = round(statistics.stdev(f1_weighted_b), 3)\n",
    "accuracy_b_std = round(statistics.stdev(accuracy_b), 3)\n",
    "\n",
    "print('Class NGEN')\n",
    "print(f'Mean f1-score = {f1_NGEN_mean}')\n",
    "print(f'Standard deviation f1-score = {f1_NGEN_std}\\n')\n",
    "\n",
    "print('Class GEN')\n",
    "print(f'Mean f1-score = {f1_GEN_mean}')\n",
    "print(f'Standard deviation f1-score = {f1_GEN_std}\\n')\n",
    "\n",
    "print('Macro')\n",
    "print(f'Mean f1-score = {f1_macro_b_mean}')\n",
    "print(f'Standard deviation f1-score = {f1_macro_b_std}\\n')\n",
    "\n",
    "print('Weighted')\n",
    "print(f'Mean f1-score = {f1_weighted_b_mean}')\n",
    "print(f'Standard deviation f1-score = {f1_weighted_b_std}\\n')\n",
    "\n",
    "print('Accuracy')\n",
    "print(f'Mean = {accuracy_b_mean}')\n",
    "print(f'Standard deviation = {accuracy_b_std}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m79"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
