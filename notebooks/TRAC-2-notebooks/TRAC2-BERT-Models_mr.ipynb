{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "environment": {
      "name": "tf2-gpu.2-6.m79",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m79"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "TRAC2-BERT-Models_mr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d54dfc8671c74e458be9e42a388634f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_455f6c3d13654e0ab8a7cd8cd8dd0e07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a58ce6c92a042b0a8f3902e9a24c2c0",
              "IPY_MODEL_b21eb029c73c48e9bf9c03a3c331bd9c",
              "IPY_MODEL_86f7f519ebcf4bb8a791fb184a020a56"
            ]
          }
        },
        "455f6c3d13654e0ab8a7cd8cd8dd0e07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a58ce6c92a042b0a8f3902e9a24c2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_466081e9b5e4456db0350cacada17322",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c832db76e0d4a88aa530b21d8a0ccca"
          }
        },
        "b21eb029c73c48e9bf9c03a3c331bd9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5f2c5c0cb9c4023b3a0f64b01ec39a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_261efc20e9d34d83809326ec607c502f"
          }
        },
        "86f7f519ebcf4bb8a791fb184a020a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2da7abc7a5474a2f9a204cbe0bcef8b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00, 28.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c83f4e4561c8419c9c09294c9f2f47a6"
          }
        },
        "466081e9b5e4456db0350cacada17322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c832db76e0d4a88aa530b21d8a0ccca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5f2c5c0cb9c4023b3a0f64b01ec39a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "261efc20e9d34d83809326ec607c502f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2da7abc7a5474a2f9a204cbe0bcef8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c83f4e4561c8419c9c09294c9f2f47a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdd03d651416431faabd1da474f8bccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_76939b3c4f434555ab46af25316bed8e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3643b041e9e4d45b74194abfab300f1",
              "IPY_MODEL_0e91ae56252c459ea5496678c997746e",
              "IPY_MODEL_d4f3d8e2131d4689a716c41e71074b39"
            ]
          }
        },
        "76939b3c4f434555ab46af25316bed8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3643b041e9e4d45b74194abfab300f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3188bfeb846d47dfae31b851bfac0eb3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_867b0bf89f9c4013a3c84dd66ef2739a"
          }
        },
        "0e91ae56252c459ea5496678c997746e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_234ce353644e4dedbc7854b0fc3920f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba43404e9e0e4e7092f77e43f9f4859e"
          }
        },
        "d4f3d8e2131d4689a716c41e71074b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1bddb26d38d6408b9dcda02fa9565f97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00, 15.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10d6dc33cd1b4c3993ca6a4d4824c156"
          }
        },
        "3188bfeb846d47dfae31b851bfac0eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "867b0bf89f9c4013a3c84dd66ef2739a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "234ce353644e4dedbc7854b0fc3920f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba43404e9e0e4e7092f77e43f9f4859e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bddb26d38d6408b9dcda02fa9565f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10d6dc33cd1b4c3993ca6a4d4824c156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41601ab8acb440788e6411201da24297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_180d5d988b4e4ff3a0f95daecb8b5591",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b69b8d4d5d2a4ad09b2c70d5511e1293",
              "IPY_MODEL_bee5853c4a3146be8419e6ee128ebf21",
              "IPY_MODEL_830c51980ded4efcbfe872669baa8ba8"
            ]
          }
        },
        "180d5d988b4e4ff3a0f95daecb8b5591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b69b8d4d5d2a4ad09b2c70d5511e1293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8706b588408b47e4bd531afc0816ad52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdb997ec41aa41d9bef72b5455bfca75"
          }
        },
        "bee5853c4a3146be8419e6ee128ebf21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_15f4299801bf42a89667c8f862d5bddc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5a1c4ccca424ffbb7f07b89f1bf6c34"
          }
        },
        "830c51980ded4efcbfe872669baa8ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4908d0508e5c49e1abd0eda2db337c50",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 11.89ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d067d742127e4e1fa9cb641dabb0b90e"
          }
        },
        "8706b588408b47e4bd531afc0816ad52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdb997ec41aa41d9bef72b5455bfca75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15f4299801bf42a89667c8f862d5bddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5a1c4ccca424ffbb7f07b89f1bf6c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4908d0508e5c49e1abd0eda2db337c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d067d742127e4e1fa9cb641dabb0b90e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f01d8e3"
      },
      "source": [
        "# Final Project"
      ],
      "id": "8f01d8e3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67b65eac"
      },
      "source": [
        "## TRAC2- Transformer Models (BERT) - base uncased - Evaluate variance\n",
        "\n",
        "The purpose of this notebook is to evaluate the variance in the results (f1-score) of the models for classification task-A and task-B.\n",
        "\n",
        "These models use the original training data. No oversampling or data augmentation."
      ],
      "id": "67b65eac"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0HMV_5JH3iL",
        "outputId": "62e1f812-bcba-43dd-b574-1f878be4fcda"
      },
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "H0HMV_5JH3iL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc82e530"
      },
      "source": [
        "## Package imports"
      ],
      "id": "fc82e530"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss6OEdHqIWyt",
        "outputId": "29607894-9aba-4c07-9db1-39bac44d543b"
      },
      "source": [
        "!pip install transformers"
      ],
      "id": "ss6OEdHqIWyt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 6.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__N7lLxVIYs0",
        "outputId": "61ab43da-6f9b-40fc-da5c-61e0d1d64f19"
      },
      "source": [
        "!pip install datasets"
      ],
      "id": "__N7lLxVIYs0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 133 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 153 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 163 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 174 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 184 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 194 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 266 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 270 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.19)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.10.0-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 68.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 73.7 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 68.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 datasets-1.12.1 fsspec-2021.10.0 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0ad9cf3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# This tells matplotlib not to try opening a new window for each plot.\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn import metrics\n",
        "\n",
        "import statistics"
      ],
      "id": "c0ad9cf3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b0b9771"
      },
      "source": [
        "## Helper functions"
      ],
      "id": "1b0b9771"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a8eaacb"
      },
      "source": [
        "def from_logits_to_labels(pred, task):\n",
        "    '''\n",
        "    Returns labels based on predicted logits on labels [CAG,NAG,OAG] for task A. Task B is binary, and 'GEN' represents \n",
        "    the positive class.\n",
        "    Parameters:\n",
        "    pred: array with model prediction\n",
        "    task: either 'A' or 'B'\n",
        "    '''\n",
        "    index_a = {0:'CAG', 1:'NAG', 2:'OAG'}\n",
        "    index_b = {0:'GEN', 1:'NGEN'}\n",
        "    \n",
        "    if task == 'A':\n",
        "        highest_prob_class = np.argmax(pred, axis=1)\n",
        "        labels = np.vectorize(index_a.get)(highest_prob_class.astype(int))\n",
        "        \n",
        "    elif task == 'B':\n",
        "        highest_prob_class = np.argmax(pred, axis=1)\n",
        "        labels = np.vectorize(index_b.get)(highest_prob_class.astype(int))\n",
        "    else:\n",
        "        labels = []\n",
        "        \n",
        "    return labels  "
      ],
      "id": "4a8eaacb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "505b0828"
      },
      "source": [
        "def to_one_hot_labels(string_labels):\n",
        "    '''\n",
        "    Returns one-hot encoded labels from a multi-class label vector e.g. ['cat', 'dog', 'dog', 'lion', 'cat', ...] \n",
        "    Parameters:\n",
        "    string_labels: \n",
        "    '''\n",
        "    labels = pd.get_dummies(string_labels)\n",
        "    labels = labels.to_numpy()\n",
        "    \n",
        "    return labels"
      ],
      "id": "505b0828",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf367348"
      },
      "source": [
        "# this is modified to get the prediction as parameter\n",
        "# to avoid predicting again since inference takes time\n",
        "def confusion_matrix_plot(pred_labels, true_labels, task, normalize=None):\n",
        "    '''\n",
        "    Returns a confusion matrix with a nice format.\n",
        "    Parameters:\n",
        "    pred_labels: predicted labels\n",
        "    true_labels: true labels \n",
        "    task: 'A' or 'B'\n",
        "    normalize: if want to normalize the confusion matrix normalize='true'\n",
        "    '''\n",
        "    \n",
        "    # Create a confusion matrix\n",
        "    cm = metrics.confusion_matrix(true_labels, pred_labels, normalize=normalize)\n",
        "    cm = np.around(cm, 2)\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    if task == 'A':\n",
        "        axis_labels = ['CAG', 'NAG', 'OAG']\n",
        "    elif task == 'B':\n",
        "        axis_labels = ['GEN', 'NGEN']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(4,4))\n",
        "    im = ax.imshow(cm, cmap=\"Blues\")\n",
        "\n",
        "    # Create the ticks and labels\n",
        "    ax.set_xticks(np.arange(len(axis_labels)))\n",
        "    ax.set_yticks(np.arange(len(axis_labels)))\n",
        "    ax.set_xticklabels(axis_labels)\n",
        "    ax.set_yticklabels(axis_labels)\n",
        "\n",
        "    # Axis titles\n",
        "    plt.ylabel('True label', size=12)\n",
        "    plt.xlabel('Predicted label', size=12)\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    for i in range(len(axis_labels)):\n",
        "        for j in range(len(axis_labels)):\n",
        "            text = ax.text(j, i, cm[i, j],ha=\"center\", va=\"center\", color=\"dimgrey\", size=12)\n",
        "    \n",
        "    ax.set_title(\"Confusion Matrix\", size=16, weight=\"bold\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n"
      ],
      "id": "cf367348",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17c5651f"
      },
      "source": [
        "def loss_accuracy_plots(training_history, xrange, task):\n",
        "    '''\n",
        "    Returns plots for loss and accuracy during the training process of a NN.\n",
        "    Parameters:\n",
        "    training_history: object that stores the training history of the NN (from model.fit(...))\n",
        "    xrange: range in x axis\n",
        "    task: string used for the title in the plot\n",
        "    '''\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n",
        "    \n",
        "    # loss plot\n",
        "    ax1.plot(training_history.history['loss'], color='black')\n",
        "    ax1.plot(training_history.history['val_loss'], color='blue')\n",
        "    ax1.set_title('Training and validation loss Sub-Task ' + task)\n",
        "    ax1.legend(['training', 'development'])\n",
        "    ax1.grid(which='both')\n",
        "    ax1.set_xticks(np.arange(0, xrange, 2))\n",
        "    \n",
        "    # accuracy plot\n",
        "    ax2.plot(training_history.history['categorical_accuracy'], color='black')\n",
        "    ax2.plot(training_history.history['val_categorical_accuracy'], color='blue')\n",
        "    ax2.set_title('Training and validation acccuracy Sub_Task ' + task)\n",
        "    ax2.legend(['training', 'development'])\n",
        "    ax2.grid(which='both')\n",
        "    ax2.set_xticks(np.arange(0, xrange, 2))\n",
        "    plt.show()\n",
        "    "
      ],
      "id": "17c5651f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "544f08b5"
      },
      "source": [
        "## Load data\n",
        "Load training, development and test datasets."
      ],
      "id": "544f08b5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7a92330"
      },
      "source": [
        "# Load labels using pandas dataframes\n",
        "\n",
        "train_labels_a = pd.read_csv('drive/MyDrive/w266/release-files/eng/trac2_eng_train.csv')['Sub-task A']\n",
        "train_labels_b = pd.read_csv('drive/MyDrive/w266/release-files/eng/trac2_eng_train.csv')['Sub-task B']\n",
        "dev_labels_a = pd.read_csv('drive/MyDrive/w266/release-files/eng/trac2_eng_dev.csv')['Sub-task A']\n",
        "dev_labels_b = pd.read_csv('drive/MyDrive/w266/release-files/eng/trac2_eng_dev.csv')['Sub-task B']\n",
        "test_labels_a = pd.read_csv('drive/MyDrive/w266/release-files/gold/trac2_eng_gold_a.csv')['Sub-task A']\n",
        "test_labels_b = pd.read_csv('drive/MyDrive/w266/release-files/gold/trac2_eng_gold_b.csv')['Sub-task B']"
      ],
      "id": "c7a92330",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382,
          "referenced_widgets": [
            "d54dfc8671c74e458be9e42a388634f5",
            "455f6c3d13654e0ab8a7cd8cd8dd0e07",
            "8a58ce6c92a042b0a8f3902e9a24c2c0",
            "b21eb029c73c48e9bf9c03a3c331bd9c",
            "86f7f519ebcf4bb8a791fb184a020a56",
            "466081e9b5e4456db0350cacada17322",
            "9c832db76e0d4a88aa530b21d8a0ccca",
            "b5f2c5c0cb9c4023b3a0f64b01ec39a3",
            "261efc20e9d34d83809326ec607c502f",
            "2da7abc7a5474a2f9a204cbe0bcef8b8",
            "c83f4e4561c8419c9c09294c9f2f47a6",
            "fdd03d651416431faabd1da474f8bccc",
            "76939b3c4f434555ab46af25316bed8e",
            "d3643b041e9e4d45b74194abfab300f1",
            "0e91ae56252c459ea5496678c997746e",
            "d4f3d8e2131d4689a716c41e71074b39",
            "3188bfeb846d47dfae31b851bfac0eb3",
            "867b0bf89f9c4013a3c84dd66ef2739a",
            "234ce353644e4dedbc7854b0fc3920f9",
            "ba43404e9e0e4e7092f77e43f9f4859e",
            "1bddb26d38d6408b9dcda02fa9565f97",
            "10d6dc33cd1b4c3993ca6a4d4824c156",
            "c8c07c3a8e7a4297b9f7a9e35bc5bc8d",
            "e3f6c29b0fda4ded84bdc4a0419f412f",
            "4fb52f5799164d0297f6f935773a73fe",
            "2d7b53c9176a4127afd4323911faafda",
            "eb10d23cd2f9406da1bf5b111066f7a7",
            "99bdd1121c1948d58d90ff67c6e3a505",
            "73898b7bf22a4300abf710bd5ef72989"
          ]
        },
        "id": "e837f450",
        "outputId": "107e3f64-e654-480c-8a1f-5bfab44cb354"
      },
      "source": [
        "# Load text data using Hugging Face datasets\n",
        "# need to use the split argument even though we are not splitting. If not, data is loaded as DatasetDict\n",
        "# to load as dataset need to include the split parameter\n",
        "train_dataset = load_dataset('csv', data_files='drive/MyDrive/w266/release-files/eng/trac2_eng_train.csv', split = 'train[:4263]')\n",
        "dev_dataset = load_dataset('csv', data_files='drive/MyDrive/w266/release-files/eng/trac2_eng_dev.csv', split = 'train[:1066]')\n",
        "test_dataset = load_dataset('csv', data_files='drive/MyDrive/w266/release-files/test/trac2_eng_test.csv', split = 'train[:1200]')"
      ],
      "id": "e837f450",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-208f2d914f0f5280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-208f2d914f0f5280/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d54dfc8671c74e458be9e42a388634f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdd03d651416431faabd1da474f8bccc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8c07c3a8e7a4297b9f7a9e35bc5bc8d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 tables [00:00, ? tables/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-208f2d914f0f5280/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-8fe574042ae65a17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-8fe574042ae65a17/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3f6c29b0fda4ded84bdc4a0419f412f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fb52f5799164d0297f6f935773a73fe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d7b53c9176a4127afd4323911faafda",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 tables [00:00, ? tables/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-8fe574042ae65a17/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-f4f28cfddb9ffd8b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-f4f28cfddb9ffd8b/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb10d23cd2f9406da1bf5b111066f7a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99bdd1121c1948d58d90ff67c6e3a505",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73898b7bf22a4300abf710bd5ef72989",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 tables [00:00, ? tables/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-f4f28cfddb9ffd8b/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86e2c1cf"
      },
      "source": [
        "## Encode labels"
      ],
      "id": "86e2c1cf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bc320b3"
      },
      "source": [
        "# encode labels Task A- [CAG,NAG,OAG]\n",
        "train_labels_a_enc = to_one_hot_labels(train_labels_a)\n",
        "dev_labels_a_enc = to_one_hot_labels(dev_labels_a)\n",
        "test_labels_a_enc = to_one_hot_labels(test_labels_a)\n"
      ],
      "id": "2bc320b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCpGlFvZZ1ua"
      },
      "source": [
        "# encode labels Task B- [GEN, NGEN]\n",
        "train_labels_b_enc = to_one_hot_labels(train_labels_b)\n",
        "dev_labels_b_enc = to_one_hot_labels(dev_labels_b)\n",
        "test_labels_b_enc = to_one_hot_labels(test_labels_b)"
      ],
      "id": "jCpGlFvZZ1ua",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5db58504"
      },
      "source": [
        "## Prepare TensorFlow datasets for BERT"
      ],
      "id": "5db58504"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "415583c1"
      },
      "source": [
        "# remove columns to leave only the column with the posts. Column 'Text'\n",
        "train_dataset = train_dataset.remove_columns(['ID', 'Sub-task B', 'Sub-task A'])\n",
        "dev_dataset = dev_dataset.remove_columns(['ID', 'Sub-task A', 'Sub-task B'])\n",
        "test_dataset = test_dataset.remove_columns('ID')"
      ],
      "id": "415583c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ead92c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "2f35395ec68443e39c1a158332e1d526",
            "38711623cbc646adacebc1557bf10a04",
            "8ec879384afc47b98e94506c2c9b564c",
            "8593a124f3e1479d98f43799138b408d"
          ]
        },
        "outputId": "c5e06a66-caa8-4887-ff23-078acaef06e1"
      },
      "source": [
        "# define a BERT tokenizer\n",
        "# use the bert-based-uncased tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "id": "5ead92c9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f35395ec68443e39c1a158332e1d526",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38711623cbc646adacebc1557bf10a04",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ec879384afc47b98e94506c2c9b564c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8593a124f3e1479d98f43799138b408d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "41601ab8acb440788e6411201da24297",
            "180d5d988b4e4ff3a0f95daecb8b5591",
            "b69b8d4d5d2a4ad09b2c70d5511e1293",
            "bee5853c4a3146be8419e6ee128ebf21",
            "830c51980ded4efcbfe872669baa8ba8",
            "8706b588408b47e4bd531afc0816ad52",
            "bdb997ec41aa41d9bef72b5455bfca75",
            "15f4299801bf42a89667c8f862d5bddc",
            "f5a1c4ccca424ffbb7f07b89f1bf6c34",
            "4908d0508e5c49e1abd0eda2db337c50",
            "d067d742127e4e1fa9cb641dabb0b90e",
            "9acf034376a54e0dabdd20b9990a7222",
            "c6124d4c311f49c58f69d9124134f8a1"
          ]
        },
        "id": "cd498279",
        "outputId": "b6e4d3c1-38fa-4659-8c99-5f2f668e9990"
      },
      "source": [
        "# tokenize the train, development and test data\n",
        "# Use a max sequence of 150 tokens. Based on EDA this is enough for majority of posts\n",
        "\n",
        "train_dataset_tok = train_dataset.map(lambda x: tokenizer(x['Text'], truncation=True, padding=True, max_length=150), batched=True)\n",
        "dev_dataset_tok = dev_dataset.map(lambda x: tokenizer(x['Text'], truncation=True, padding=True, max_length=150), batched=True)\n",
        "test_dataset_tok = test_dataset.map(lambda x: tokenizer(x['Text'], truncation=True, padding=True, max_length=150), batched=True)"
      ],
      "id": "cd498279",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41601ab8acb440788e6411201da24297",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9acf034376a54e0dabdd20b9990a7222",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6124d4c311f49c58f69d9124134f8a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0526c186"
      },
      "source": [
        "# now we can remove the column with the original post from the dataset. We are going to use the result of tokenization for modeling\n",
        "train_dataset_tok = train_dataset_tok.remove_columns(['Text']).with_format('tensorflow')\n",
        "dev_dataset_tok = dev_dataset_tok.remove_columns(['Text']).with_format('tensorflow')\n",
        "test_dataset_tok = test_dataset_tok.remove_columns(['Text']).with_format('tensorflow')"
      ],
      "id": "0526c186",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "778a3871"
      },
      "source": [
        "# extract features from tokenizer output: 'input_ids', 'token_type_ids', 'attention_mask'\n",
        "train_features = {x: train_dataset_tok[x].to_tensor() for x in tokenizer.model_input_names}\n",
        "dev_features = {x: dev_dataset_tok[x].to_tensor() for x in tokenizer.model_input_names}\n",
        "test_features = {x: test_dataset_tok[x].to_tensor() for x in tokenizer.model_input_names}"
      ],
      "id": "778a3871",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c9445e5"
      },
      "source": [
        "# batch data\n",
        "\n",
        "batch_size = 16\n",
        "buffer = len(train_dataset_tok)\n",
        "\n",
        "# Task A\n",
        "train_tf_dataset_a = tf.data.Dataset.from_tensor_slices((train_features, train_labels_a_enc)).shuffle(buffer).batch(batch_size)\n",
        "dev_tf_dataset_a = tf.data.Dataset.from_tensor_slices((dev_features, dev_labels_a_enc)).batch(batch_size)\n",
        "test_tf_dataset_a = tf.data.Dataset.from_tensor_slices((test_features, test_labels_a_enc)).batch(batch_size)\n",
        "\n",
        "# Task B\n",
        "train_tf_dataset_b = tf.data.Dataset.from_tensor_slices((train_features, train_labels_b_enc)).shuffle(buffer).batch(batch_size)\n",
        "dev_tf_dataset_b = tf.data.Dataset.from_tensor_slices((dev_features, dev_labels_b_enc)).batch(batch_size)\n",
        "test_tf_dataset_b = tf.data.Dataset.from_tensor_slices((test_features, test_labels_b_enc)).batch(batch_size)"
      ],
      "id": "2c9445e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b59c68de"
      },
      "source": [
        "## Model Task A"
      ],
      "id": "b59c68de"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "492338d5b147466caf687c7e2473f5e9"
          ]
        },
        "id": "nc1v9RnfLBNg",
        "outputId": "0bcc4da6-7833-4e13-f62b-16515be5c08e"
      },
      "source": [
        "# initialize lists to keep statistics of all runs\n",
        "f1_NAG = []\n",
        "f1_CAG = []\n",
        "f1_OAG = []\n",
        "f1_macro = []\n",
        "f1_weighted = []\n",
        "\n",
        "# run 15 times the model to get an idea of variability\n",
        "for i in range(15):\n",
        "\n",
        "  # delete model if exists\n",
        "  try:\n",
        "    del BERT_model_A\n",
        "  except:\n",
        "    pass\n",
        "  \n",
        "  # define the model. Task A is a classification task with 3 labels\n",
        "  BERT_model_A = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "\n",
        "  # compile model\n",
        "  BERT_model_A.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "                       loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                       metrics=tf.metrics.CategoricalAccuracy()\n",
        "                       )\n",
        "  # fit model\n",
        "  training_history = BERT_model_A.fit(train_tf_dataset_a, validation_data=dev_tf_dataset_a, epochs=2)\n",
        "\n",
        "  print(f'---------------------------Iteration {i} ---------------------------\\n')\n",
        "  # Evaluate model on TEST data\n",
        "  # predict using model. Returns logits\n",
        "  pred_labels_test = BERT_model_A.predict(test_features)[0]\n",
        "  # convert logits lo labels\n",
        "  pred_labels_test = from_logits_to_labels(pred_labels_test, 'A')\n",
        "\n",
        "  # get f1-score for all classes, macro and weighted\n",
        "  x = metrics.classification_report(test_labels_a, pred_labels_test, digits=3, output_dict=True)\n",
        "  # append values to keep scores\n",
        "  f1_NAG.append(x['NAG']['f1-score'])\n",
        "  f1_CAG.append(x['CAG']['f1-score'])\n",
        "  f1_OAG.append(x['OAG']['f1-score'])\n",
        "  f1_macro.append(x['macro avg']['f1-score'])\n",
        "  f1_weighted.append(x['weighted avg']['f1-score'])\n",
        "\n",
        "# calculate mean\n",
        "f1_NAG_mean = round(statistics.mean(f1_NAG), 3)\n",
        "f1_CAG_mean = round(statistics.mean(f1_CAG), 3)\n",
        "f1_OAG_mean = round(statistics.mean(f1_OAG), 3)\n",
        "f1_macro_mean = round(statistics.mean(f1_macro), 3)\n",
        "f1_weighted_mean = round(statistics.mean(f1_weighted), 3)\n",
        "\n",
        "# calculate standard deviation\n",
        "f1_NAG_std = round(statistics.stdev(f1_NAG), 3)\n",
        "f1_CAG_std = round(statistics.stdev(f1_CAG), 3)\n",
        "f1_OAG_std = round(statistics.stdev(f1_OAG), 3)\n",
        "f1_macro_std = round(statistics.stdev(f1_macro), 3)\n",
        "f1_weighted_std = round(statistics.stdev(f1_weighted), 3)\n",
        "\n",
        "print('Class NAG')\n",
        "print(f'Mean f1-score = {f1_NAG_mean}')\n",
        "print(f'Standard deviation f1-score = {f1_NAG_std}\\n')\n",
        "\n",
        "print('Class CAG')\n",
        "print(f'Mean f1-score = {f1_CAG_mean}')\n",
        "print(f'Standard deviation f1-score = {f1_CAG_std}\\n')\n",
        "\n",
        "print('Class OAG')\n",
        "print(f'Mean f1-score = {f1_OAG_mean}')\n",
        "print(f'Standard deviation f1-score = {f1_OAG_std}\\n')\n",
        "\n",
        "print('Class Macro')\n",
        "print(f'Mean f1-score = {f1_macro_mean}')\n",
        "print(f'Standard deviation f1-score = {f1_macro_std}\\n')\n",
        "\n",
        "print('Class Weighted')\n",
        "print(f'Mean f1-score = {f1_weighted_mean}')\n",
        "print(f'Standard deviation f1-score = {f1_weighted_std}\\n')"
      ],
      "id": "nc1v9RnfLBNg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "492338d5b147466caf687c7e2473f5e9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 116s 375ms/step - loss: 0.5509 - categorical_accuracy: 0.7931 - val_loss: 0.4771 - val_categorical_accuracy: 0.8105\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 365ms/step - loss: 0.4133 - categorical_accuracy: 0.8271 - val_loss: 0.4850 - val_categorical_accuracy: 0.8096\n",
            "---------------------------Iteration 0 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 113s 374ms/step - loss: 0.5417 - categorical_accuracy: 0.7912 - val_loss: 0.4720 - val_categorical_accuracy: 0.7852\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 365ms/step - loss: 0.3861 - categorical_accuracy: 0.8370 - val_loss: 0.5076 - val_categorical_accuracy: 0.7964\n",
            "---------------------------Iteration 1 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 374ms/step - loss: 0.5398 - categorical_accuracy: 0.7931 - val_loss: 0.4918 - val_categorical_accuracy: 0.8077\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.3933 - categorical_accuracy: 0.8381 - val_loss: 0.4827 - val_categorical_accuracy: 0.8058\n",
            "---------------------------Iteration 2 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 375ms/step - loss: 0.5565 - categorical_accuracy: 0.7910 - val_loss: 0.4987 - val_categorical_accuracy: 0.7955\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.4404 - categorical_accuracy: 0.8215 - val_loss: 0.5332 - val_categorical_accuracy: 0.8011\n",
            "---------------------------Iteration 3 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 374ms/step - loss: 0.5624 - categorical_accuracy: 0.7947 - val_loss: 0.4985 - val_categorical_accuracy: 0.8068\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.4068 - categorical_accuracy: 0.8302 - val_loss: 0.4613 - val_categorical_accuracy: 0.8171\n",
            "---------------------------Iteration 4 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 113s 374ms/step - loss: 0.5747 - categorical_accuracy: 0.7875 - val_loss: 0.4964 - val_categorical_accuracy: 0.7983\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.4111 - categorical_accuracy: 0.8337 - val_loss: 0.4849 - val_categorical_accuracy: 0.8058\n",
            "---------------------------Iteration 5 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 375ms/step - loss: 0.5458 - categorical_accuracy: 0.7910 - val_loss: 0.4879 - val_categorical_accuracy: 0.8096\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.3976 - categorical_accuracy: 0.8370 - val_loss: 0.4935 - val_categorical_accuracy: 0.8096\n",
            "---------------------------Iteration 6 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 376ms/step - loss: 0.5455 - categorical_accuracy: 0.7875 - val_loss: 0.5143 - val_categorical_accuracy: 0.8105\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.4110 - categorical_accuracy: 0.8306 - val_loss: 0.4994 - val_categorical_accuracy: 0.8058\n",
            "---------------------------Iteration 7 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 375ms/step - loss: 0.5326 - categorical_accuracy: 0.8004 - val_loss: 0.4688 - val_categorical_accuracy: 0.7983\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.3884 - categorical_accuracy: 0.8360 - val_loss: 0.4914 - val_categorical_accuracy: 0.7936\n",
            "---------------------------Iteration 8 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 374ms/step - loss: 0.5355 - categorical_accuracy: 0.8015 - val_loss: 0.5145 - val_categorical_accuracy: 0.7805\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 365ms/step - loss: 0.3911 - categorical_accuracy: 0.8414 - val_loss: 0.4813 - val_categorical_accuracy: 0.7955\n",
            "---------------------------Iteration 9 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 115s 376ms/step - loss: 0.5505 - categorical_accuracy: 0.7962 - val_loss: 0.4685 - val_categorical_accuracy: 0.8068\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.3970 - categorical_accuracy: 0.8363 - val_loss: 0.4730 - val_categorical_accuracy: 0.8105\n",
            "---------------------------Iteration 10 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 375ms/step - loss: 0.5438 - categorical_accuracy: 0.7896 - val_loss: 0.5104 - val_categorical_accuracy: 0.7871\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.4120 - categorical_accuracy: 0.8290 - val_loss: 0.4574 - val_categorical_accuracy: 0.8068\n",
            "---------------------------Iteration 11 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 375ms/step - loss: 0.5529 - categorical_accuracy: 0.7910 - val_loss: 0.4693 - val_categorical_accuracy: 0.8077\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.3956 - categorical_accuracy: 0.8358 - val_loss: 0.4912 - val_categorical_accuracy: 0.7974\n",
            "---------------------------Iteration 12 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 376ms/step - loss: 0.5391 - categorical_accuracy: 0.7980 - val_loss: 0.4838 - val_categorical_accuracy: 0.7974\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.4112 - categorical_accuracy: 0.8344 - val_loss: 0.4841 - val_categorical_accuracy: 0.8143\n",
            "---------------------------Iteration 13 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "267/267 [==============================] - 114s 375ms/step - loss: 0.5719 - categorical_accuracy: 0.7854 - val_loss: 0.4884 - val_categorical_accuracy: 0.7899\n",
            "Epoch 2/2\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.4380 - categorical_accuracy: 0.8217 - val_loss: 0.5602 - val_categorical_accuracy: 0.7645\n",
            "---------------------------Iteration 14 ---------------------------\n",
            "\n",
            "Class NAG\n",
            "Mean f1-score = 0.843\n",
            "Standard deviation f1-score = 0.036\n",
            "\n",
            "Class CAG\n",
            "Mean f1-score = 0.311\n",
            "Standard deviation f1-score = 0.185\n",
            "\n",
            "Class OAG\n",
            "Mean f1-score = 0.631\n",
            "Standard deviation f1-score = 0.071\n",
            "\n",
            "Class Macro\n",
            "Mean f1-score = 0.595\n",
            "Standard deviation f1-score = 0.072\n",
            "\n",
            "Class Weighted\n",
            "Mean f1-score = 0.693\n",
            "Standard deviation f1-score = 0.054\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9142a3df"
      },
      "source": [
        "## Model Task B"
      ],
      "id": "9142a3df"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdvEEPmqN5E-",
        "outputId": "35ef1fb6-6c14-4860-eeb6-bad767246747"
      },
      "source": [
        "# initialize lists to keep statistics of all runs\n",
        "f1_NGEN = []\n",
        "f1_GEN = []\n",
        "f1_macro_b = []\n",
        "f1_weighted_b = []\n",
        "\n",
        "for i in range(15):\n",
        "\n",
        "  # delete model if exists\n",
        "  try:\n",
        "    del BERT_model_B\n",
        "  except:\n",
        "    pass\n",
        "  \n",
        "  # define the model. Task B is a classification task with 2 labels\n",
        "  BERT_model_B = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "  # compile model\n",
        "  BERT_model_B.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "                       loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                       metrics=tf.metrics.CategoricalAccuracy()\n",
        "                       )\n",
        "  \n",
        "  # fit model\n",
        "  training_history = BERT_model_B.fit(train_tf_dataset_b, validation_data=dev_tf_dataset_b, epochs=3)\n",
        "\n",
        "  print(f'---------------------------Iteration {i} ---------------------------\\n')\n",
        "  # Evaluate model on TEST data\n",
        "  # predict using model. Returns logits\n",
        "  pred_labels_test = BERT_model_B.predict(test_features)[0]\n",
        "\n",
        "  # convert logits lo labels\n",
        "  pred_labels_test = from_logits_to_labels(pred_labels_test, 'B')\n",
        "\n",
        "  # get f1-score for all classes, macro and weighted\n",
        "  x = metrics.classification_report(test_labels_b, pred_labels_test, digits=3, output_dict=True)\n",
        "  # append values to keep scores\n",
        "  f1_NGEN.append(x['NGEN']['f1-score'])\n",
        "  f1_GEN.append(x['GEN']['f1-score'])\n",
        "  f1_macro_b.append(x['macro avg']['f1-score'])\n",
        "  f1_weighted_b.append(x['weighted avg']['f1-score'])\n",
        "\n",
        "# calculate mean\n",
        "f1_NGEN_mean = round(statistics.mean(f1_NGEN), 3)\n",
        "f1_GEN_mean = round(statistics.mean(f1_GEN), 3)\n",
        "f1_macro_b_mean = round(statistics.mean(f1_macro_b), 3)\n",
        "f1_weighted_b_mean = round(statistics.mean(f1_weighted_b), 3)\n",
        "\n",
        "# calculate standard deviation\n",
        "f1_NGEN_std = round(statistics.stdev(f1_NGEN), 3)\n",
        "f1_GEN_std = round(statistics.stdev(f1_GEN), 3)\n",
        "f1_macro_b_std = round(statistics.stdev(f1_macro_b), 3)\n",
        "f1_weighted_b_std = round(statistics.stdev(f1_weighted_b), 3)\n",
        "\n",
        "print('Class NGEN')\n",
        "print(f'Mean f1-score = {f1_NGEN_mean}')\n",
        "print(f'Standard deviation f1-score = {f1_NGEN_std}\\n')\n",
        "\n",
        "print('Class GEN')\n",
        "print(f'Mean f1-score = {f1_GEN_mean}')\n",
        "print(f'Standard deviation f1-score = {f1_GEN_std}\\n')\n",
        "\n",
        "print('Macro')\n",
        "print(f'Mean f1-score = {f1_macro_b_mean}')\n",
        "print(f'Standard deviation f1-score = {f1_macro_b_std}\\n')\n",
        "\n",
        "print('Weighted')\n",
        "print(f'Mean f1-score = {f1_weighted_b_mean}')\n",
        "print(f'Standard deviation f1-score = {f1_weighted_b_std}\\n')\n"
      ],
      "id": "qdvEEPmqN5E-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 115s 375ms/step - loss: 0.2329 - categorical_accuracy: 0.9249 - val_loss: 0.2448 - val_categorical_accuracy: 0.9315\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.2639 - categorical_accuracy: 0.9275 - val_loss: 0.2492 - val_categorical_accuracy: 0.9315\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.2612 - categorical_accuracy: 0.9273 - val_loss: 0.2495 - val_categorical_accuracy: 0.9315\n",
            "---------------------------Iteration 0 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 113s 375ms/step - loss: 0.2628 - categorical_accuracy: 0.9207 - val_loss: 0.2614 - val_categorical_accuracy: 0.9315\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1915 - categorical_accuracy: 0.9381 - val_loss: 0.2279 - val_categorical_accuracy: 0.9334\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1305 - categorical_accuracy: 0.9573 - val_loss: 0.1843 - val_categorical_accuracy: 0.9447\n",
            "---------------------------Iteration 1 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 114s 375ms/step - loss: 0.2318 - categorical_accuracy: 0.9301 - val_loss: 0.1722 - val_categorical_accuracy: 0.9437\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1544 - categorical_accuracy: 0.9517 - val_loss: 0.1712 - val_categorical_accuracy: 0.9409\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.0993 - categorical_accuracy: 0.9690 - val_loss: 0.2107 - val_categorical_accuracy: 0.9334\n",
            "---------------------------Iteration 2 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 114s 374ms/step - loss: 0.2193 - categorical_accuracy: 0.9270 - val_loss: 0.2186 - val_categorical_accuracy: 0.9024\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1293 - categorical_accuracy: 0.9536 - val_loss: 0.1649 - val_categorical_accuracy: 0.9493\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 97s 365ms/step - loss: 0.0675 - categorical_accuracy: 0.9765 - val_loss: 0.1831 - val_categorical_accuracy: 0.9428\n",
            "---------------------------Iteration 3 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 114s 379ms/step - loss: 0.2236 - categorical_accuracy: 0.9273 - val_loss: 0.1710 - val_categorical_accuracy: 0.9428\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1355 - categorical_accuracy: 0.9540 - val_loss: 0.1690 - val_categorical_accuracy: 0.9409\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.0668 - categorical_accuracy: 0.9782 - val_loss: 0.2222 - val_categorical_accuracy: 0.9465\n",
            "---------------------------Iteration 4 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 115s 379ms/step - loss: 0.2257 - categorical_accuracy: 0.9303 - val_loss: 0.1722 - val_categorical_accuracy: 0.9409\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1409 - categorical_accuracy: 0.9503 - val_loss: 0.1974 - val_categorical_accuracy: 0.9287\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.0767 - categorical_accuracy: 0.9758 - val_loss: 0.2309 - val_categorical_accuracy: 0.9465\n",
            "---------------------------Iteration 5 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 113s 375ms/step - loss: 0.2197 - categorical_accuracy: 0.9289 - val_loss: 0.1721 - val_categorical_accuracy: 0.9447\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1346 - categorical_accuracy: 0.9514 - val_loss: 0.1866 - val_categorical_accuracy: 0.9484\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.0590 - categorical_accuracy: 0.9808 - val_loss: 0.1890 - val_categorical_accuracy: 0.9456\n",
            "---------------------------Iteration 6 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 114s 377ms/step - loss: 0.2208 - categorical_accuracy: 0.9278 - val_loss: 0.1709 - val_categorical_accuracy: 0.9400\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1422 - categorical_accuracy: 0.9456 - val_loss: 0.1566 - val_categorical_accuracy: 0.9447\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.0833 - categorical_accuracy: 0.9667 - val_loss: 0.2122 - val_categorical_accuracy: 0.9381\n",
            "---------------------------Iteration 7 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 114s 379ms/step - loss: 0.2305 - categorical_accuracy: 0.9296 - val_loss: 0.1684 - val_categorical_accuracy: 0.9418\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1541 - categorical_accuracy: 0.9472 - val_loss: 0.1860 - val_categorical_accuracy: 0.9437\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1016 - categorical_accuracy: 0.9653 - val_loss: 0.1861 - val_categorical_accuracy: 0.9418\n",
            "---------------------------Iteration 8 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 113s 375ms/step - loss: 0.2482 - categorical_accuracy: 0.9205 - val_loss: 0.2105 - val_categorical_accuracy: 0.9315\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1675 - categorical_accuracy: 0.9392 - val_loss: 0.1860 - val_categorical_accuracy: 0.9447\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.0977 - categorical_accuracy: 0.9660 - val_loss: 0.1698 - val_categorical_accuracy: 0.9484\n",
            "---------------------------Iteration 9 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 114s 377ms/step - loss: 0.2131 - categorical_accuracy: 0.9303 - val_loss: 0.2426 - val_categorical_accuracy: 0.9418\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.1297 - categorical_accuracy: 0.9566 - val_loss: 0.1652 - val_categorical_accuracy: 0.9437\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.0733 - categorical_accuracy: 0.9744 - val_loss: 0.1998 - val_categorical_accuracy: 0.9447\n",
            "---------------------------Iteration 10 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 114s 378ms/step - loss: 0.2092 - categorical_accuracy: 0.9322 - val_loss: 0.1761 - val_categorical_accuracy: 0.9400\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 365ms/step - loss: 0.1268 - categorical_accuracy: 0.9526 - val_loss: 0.1658 - val_categorical_accuracy: 0.9428\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 366ms/step - loss: 0.0719 - categorical_accuracy: 0.9770 - val_loss: 0.2158 - val_categorical_accuracy: 0.9231\n",
            "---------------------------Iteration 11 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 113s 374ms/step - loss: 0.2467 - categorical_accuracy: 0.9259 - val_loss: 0.1748 - val_categorical_accuracy: 0.9400\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 365ms/step - loss: 0.1597 - categorical_accuracy: 0.9418 - val_loss: 0.1633 - val_categorical_accuracy: 0.9409\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 97s 365ms/step - loss: 0.1037 - categorical_accuracy: 0.9629 - val_loss: 0.1799 - val_categorical_accuracy: 0.9371\n",
            "---------------------------Iteration 12 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 114s 376ms/step - loss: 0.2119 - categorical_accuracy: 0.9322 - val_loss: 0.1847 - val_categorical_accuracy: 0.9287\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 98s 365ms/step - loss: 0.1243 - categorical_accuracy: 0.9566 - val_loss: 0.1876 - val_categorical_accuracy: 0.9484\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 98s 365ms/step - loss: 0.0624 - categorical_accuracy: 0.9784 - val_loss: 0.1963 - val_categorical_accuracy: 0.9522\n",
            "---------------------------Iteration 13 ---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "267/267 [==============================] - 113s 374ms/step - loss: 0.2218 - categorical_accuracy: 0.9289 - val_loss: 0.1948 - val_categorical_accuracy: 0.9409\n",
            "Epoch 2/3\n",
            "267/267 [==============================] - 97s 365ms/step - loss: 0.1384 - categorical_accuracy: 0.9512 - val_loss: 0.1773 - val_categorical_accuracy: 0.9437\n",
            "Epoch 3/3\n",
            "267/267 [==============================] - 97s 365ms/step - loss: 0.0791 - categorical_accuracy: 0.9714 - val_loss: 0.1842 - val_categorical_accuracy: 0.9343\n",
            "---------------------------Iteration 14 ---------------------------\n",
            "\n",
            "Class NGEN\n",
            "Mean f1-score = 0.908\n",
            "Standard deviation f1-score = 0.015\n",
            "\n",
            "Class GEN\n",
            "Mean f1-score = 0.479\n",
            "Standard deviation f1-score = 0.136\n",
            "\n",
            "Macro\n",
            "Mean f1-score = 0.694\n",
            "Standard deviation f1-score = 0.066\n",
            "\n",
            "Weighted\n",
            "Mean f1-score = 0.845\n",
            "Standard deviation f1-score = 0.02\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efcfaf92"
      },
      "source": [
        "## References\n",
        "\n",
        "- Pre-processing data: https://huggingface.co/transformers/preprocessing.html\n",
        "\n",
        "- Fine-tunning a pre-trained model: https://huggingface.co/transformers/training.html\n",
        "\n",
        "- BERT: https://huggingface.co/transformers/model_doc/bert.html\n"
      ],
      "id": "efcfaf92"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecf7c642"
      },
      "source": [
        ""
      ],
      "id": "ecf7c642",
      "execution_count": null,
      "outputs": []
    }
  ]
}