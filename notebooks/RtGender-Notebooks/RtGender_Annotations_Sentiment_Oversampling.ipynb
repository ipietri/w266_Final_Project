{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RtGender - Annotations - Sentiment - Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "N7PAJ1oIJZfY",
        "hErgyoZRHSA3",
        "OYm-yyHufXuD",
        "sc1LMqJyFbtw",
        "bdsxHUwoJFLf",
        "y1I3qA_jDRAk"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5a7d92e071624673b363dedcb051ab8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95feaa4dbb3e4cd3906c607db760c9ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a5c888ef8ce43579a6d07015e034f81",
              "IPY_MODEL_79102bf175cc4073bd0ca60218b09035",
              "IPY_MODEL_72a40c49c5df4407b67e3e35bf6f4490"
            ]
          }
        },
        "95feaa4dbb3e4cd3906c607db760c9ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a5c888ef8ce43579a6d07015e034f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db22a57aec8040acaa307887a60865ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a1c70bd0d344573bdc88964b4d851eb"
          }
        },
        "79102bf175cc4073bd0ca60218b09035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7abaec26e31e47819bd135998c273170",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e356bb853864ea49cd7c2b0c107e29d"
          }
        },
        "72a40c49c5df4407b67e3e35bf6f4490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_48069eeb9910434a9d2aa713abe68835",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:01&lt;00:00,  1.78s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd0b21fe4ab244828adc4c8d837e353e"
          }
        },
        "db22a57aec8040acaa307887a60865ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a1c70bd0d344573bdc88964b4d851eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7abaec26e31e47819bd135998c273170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e356bb853864ea49cd7c2b0c107e29d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48069eeb9910434a9d2aa713abe68835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd0b21fe4ab244828adc4c8d837e353e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d392872892e24f50b153b541b6517930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ea317e471d94fe69b955c5ff55bc9c4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_05f0ebef1a514809a8e82adaba1e180f",
              "IPY_MODEL_e44962f8f59f4ac2a59450e2ad838477",
              "IPY_MODEL_54786d151994400890298de6ce507fc5"
            ]
          }
        },
        "9ea317e471d94fe69b955c5ff55bc9c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05f0ebef1a514809a8e82adaba1e180f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aff27998b0084a2ab2a0133cd67d62e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f32eb3ea92dc437481ccd5b435140ea6"
          }
        },
        "e44962f8f59f4ac2a59450e2ad838477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_44d25262812e4f8890663e330de1dc9a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_591235111d3843b0a8c83c19d0d4bc28"
          }
        },
        "54786d151994400890298de6ce507fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4727eebfee845aca19045f49670854b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  7.30ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bcd1353e9764245925ae99dc36b42fe"
          }
        },
        "aff27998b0084a2ab2a0133cd67d62e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f32eb3ea92dc437481ccd5b435140ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44d25262812e4f8890663e330de1dc9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "591235111d3843b0a8c83c19d0d4bc28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4727eebfee845aca19045f49670854b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bcd1353e9764245925ae99dc36b42fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipietri/w266_Final_Project/blob/master/notebooks/RtGender-Notebooks/RtGender_Annotations_Sentiment_Oversampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OhO4xlwqExT"
      },
      "source": [
        "# RtGender - Annotations - Sentiment using PyTorch\n",
        "[Source](https://github.com/bhadreshpsavani/ExploringSentimentalAnalysis/blob/main/SentimentalAnalysisWithDistilbert.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cirVs78YksXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6457afba-521e-471f-ba47-38720fa725e8"
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  path = r'/content/drive/MyDrive/w266'\n",
        "except ModuleNotFoundError:\n",
        "  path = r'data'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7PAJ1oIJZfY"
      },
      "source": [
        "<a id='section01'></a>\n",
        "## Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IV4cb3abmJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4d99a4-5f83-463c-bbec-e9096be3afb7"
      },
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q datasets\n",
        "import datasets \n",
        "from datasets import load_dataset, Dataset, DatasetDict"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.1 MB 12.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 80.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 93.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 81.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 290 kB 13.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 88.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 80.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 93.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 192 kB 73.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 89.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 160 kB 90.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "979OUro5Eac3"
      },
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "#from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb1Q5N6LGK7z"
      },
      "source": [
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hErgyoZRHSA3"
      },
      "source": [
        "<a id='section02'></a>\n",
        "## Import and Reshape Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3FzcAlgEac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496c704c-6898-4f75-e642-ada34151f769"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/w266/train_oversampled.csv')\n",
        "dev_df = pd.read_csv('/content/drive/MyDrive/w266/annotations_dev.csv')\n",
        "\n",
        "print('train_shape: ',train_df.shape)\n",
        "print('dev_shape: ',dev_df.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_shape:  (21184, 9)\n",
            "dev_shape:  (2303, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntnIM3pjdQ2C",
        "outputId": "34703660-6d82-47e4-88df-e19ba3cdcc09"
      },
      "source": [
        "# there are NaNs in the dev dataset remove \n",
        "nan_values = dev_df[dev_df.isna().any(axis=1)] \n",
        "print(nan_values)\n",
        "\n",
        "# return without missing values in response_text\n",
        "dev_df.dropna(subset = [\"response_text\"], inplace=True)\n",
        "\n",
        "print(\"Train shape\", train_df.shape)\n",
        "print(\"Dev shape\", dev_df.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0         source op_gender  ...   relevance label labels_4\n",
            "830         2576  facebook_wiki         M  ...  Irrelevant     1        1\n",
            "1664        2722  facebook_wiki         W  ...  Irrelevant     1        1\n",
            "\n",
            "[2 rows x 9 columns]\n",
            "Train shape (21184, 9)\n",
            "Dev shape (2301, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9BHmHVnbaJm",
        "outputId": "f893f1e1-a165-496d-bfb8-f9938e168879"
      },
      "source": [
        "print(\"Unique sentiments: \", train_df['sentiment'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique sentiments:  ['Positive' 'Mixed' 'Neutral' 'Negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rIl4GMGbYVn"
      },
      "source": [
        "# Change Mixed to Neutral\n",
        "# train_df['sentiment'].replace({\"Mixed\":\"Neutral\"}, inplace = True)\n",
        "# dev_df['sentiment'].replace({\"Mixed\":\"Neutral\"}, inplace = True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGcvxwWXIbfq"
      },
      "source": [
        "# change to dataset to work with Huggingface transformer & remove unused columns\n",
        "columns_to_remove = ['op_gender', 'source', 'Unnamed: 0', 'relevance', 'sentiment','post_text','label']\n",
        "\n",
        "from datasets import load_dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "dev_dataset = Dataset.from_pandas(dev_df)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(column_names= columns_to_remove)\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= columns_to_remove)\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= '__index_level_0__')\n",
        "\n",
        "\n",
        "# rename labels_4 to labels\n",
        "train_dataset = train_dataset.rename_column(\"labels_4\", \"label\")\n",
        "dev_dataset = dev_dataset.rename_column(\"labels_4\", \"label\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMF7YvFgcDSW",
        "outputId": "a12241c5-7af0-4305-8cf5-f373a144e28f"
      },
      "source": [
        "# combine into a DataDictionary for huggingface use\n",
        "rtg_dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'dev': dev_dataset \n",
        "})\n",
        "\n",
        "rtg_dataset"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['response_text', 'label'],\n",
              "        num_rows: 21184\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['response_text', 'label'],\n",
              "        num_rows: 2301\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYm-yyHufXuD"
      },
      "source": [
        "## Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAWtxVO2b1Xf"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc1LMqJyFbtw"
      },
      "source": [
        "### Determine Max Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhylD3KfIFIy",
        "outputId": "78c0b116-dbe6-4299-a1a4-cb4d08ab2d5b"
      },
      "source": [
        "# find the P99 of length for response_text and set that as the max length \n",
        "max_length = train_df['response_text'].astype(str).map(len).quantile(0.99)\n",
        "print(f\"99th %tile of response_text length: {max_length}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99th %tile of response_text length: 289.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdsxHUwoJFLf"
      },
      "source": [
        "## Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8csnO6fRb5WY",
        "outputId": "b11c41a8-d784-4f29-9732-0b6677193d9a"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, max_length = max_length)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"response_text\"], padding=True, truncation=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_length\": 289.0,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "5a7d92e071624673b363dedcb051ab8b",
            "95feaa4dbb3e4cd3906c607db760c9ba",
            "3a5c888ef8ce43579a6d07015e034f81",
            "79102bf175cc4073bd0ca60218b09035",
            "72a40c49c5df4407b67e3e35bf6f4490",
            "db22a57aec8040acaa307887a60865ef",
            "0a1c70bd0d344573bdc88964b4d851eb",
            "7abaec26e31e47819bd135998c273170",
            "4e356bb853864ea49cd7c2b0c107e29d",
            "48069eeb9910434a9d2aa713abe68835",
            "dd0b21fe4ab244828adc4c8d837e353e",
            "d392872892e24f50b153b541b6517930",
            "9ea317e471d94fe69b955c5ff55bc9c4",
            "05f0ebef1a514809a8e82adaba1e180f",
            "e44962f8f59f4ac2a59450e2ad838477",
            "54786d151994400890298de6ce507fc5",
            "aff27998b0084a2ab2a0133cd67d62e6",
            "f32eb3ea92dc437481ccd5b435140ea6",
            "44d25262812e4f8890663e330de1dc9a",
            "591235111d3843b0a8c83c19d0d4bc28",
            "f4727eebfee845aca19045f49670854b",
            "3bcd1353e9764245925ae99dc36b42fe"
          ]
        },
        "id": "YKMeefM8f698",
        "outputId": "588dc9e8-cd1e-4d8c-cdb3-7a619dcfed29"
      },
      "source": [
        "rtg_encoded = rtg_dataset.map(tokenize, batched=True, batch_size=None)\n",
        "rtg_encoded['train'].features"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a7d92e071624673b363dedcb051ab8b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d392872892e24f50b153b541b6517930",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'label': Value(dtype='int64', id=None),\n",
              " 'response_text': Value(dtype='string', id=None),\n",
              " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_toVz-NgFKH"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ycuAMQWcQ-q",
        "outputId": "a3ec2f30-0c25-4d07-a31e-ceb4c905ad78"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "num_labels = 4\n",
        "epochs = 2\n",
        "iterations = 5\n",
        "model = (AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1bqyXiLgjLb",
        "outputId": "7b407416-83d0-4c7f-cb46-fe149ea55dce"
      },
      "source": [
        "rtg_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# check the type for each feature\n",
        "rtg_encoded[\"dev\"].features"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'label': Value(dtype='int64', id=None),\n",
              " 'response_text': Value(dtype='string', id=None),\n",
              " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0gITK_Rgpi5"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  '''return accuracy and f1 scores '''\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
        "  f1_macro = f1_score(labels, preds, average = 'macro')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\"accuracy\": acc, \"f1\": f1_weighted, \"f1_macro\": f1_macro} "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRmc5S3ygsUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "443dc19b-ea11-419f-d25f-e1349ba9d195"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 8\n",
        "logging_steps = len(rtg_encoded[\"train\"]) // batch_size\n",
        "training_args = TrainingArguments(output_dir=\"results\",\n",
        "                                  num_train_epochs=epochs,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  load_best_model_at_end=True,\n",
        "                                #  metric_for_best_model=\"f1_macro\", # default is loss\n",
        "                                 # weight_decay=0.01,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  save_strategy=\"epoch\",\n",
        "                                  disable_tqdm=False\n",
        "                                  )"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GdoDJbA7vu9"
      },
      "source": [
        "sentiment_mappings = {'Positive': 2, 'Mixed': 3, 'Neutral': 1, 'Negative':0}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YY_V0Pb3pNs4",
        "outputId": "0b49c2a8-8b0d-4e8c-ec90-716d2bf06a38"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "accuracy_list = []\n",
        "weighted_f1_score_list = []\n",
        "macro_f1_score_list = []\n",
        "negative_f1_score = []\n",
        "neutral_f1_score = []\n",
        "mixed_f1_score = []\n",
        "positive_f1_score = []\n",
        "\n",
        "\n",
        "for i in range(iterations):\n",
        "  try:\n",
        "    del trainer\n",
        "    del results\n",
        "    del cr\n",
        "  except: pass\n",
        "\n",
        "\n",
        "  trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=rtg_encoded[\"train\"],\n",
        "                  eval_dataset=rtg_encoded[\"dev\"])\n",
        "  trainer.train()\n",
        "  results = trainer.evaluate()\n",
        "\n",
        "  # append macro metrics to lists\n",
        "  accuracy_list.append(results.get('eval_accuracy'))\n",
        "  weighted_f1_score_list.append(results.get(\"eval_f1\"))\n",
        "  macro_f1_score_list.append(results.get(\"eval_f1_macro\"))\n",
        "\n",
        "  trainer.predict(rtg_encoded[\"dev\"])\n",
        "  # append the class-level F1 scores\n",
        "  outputs = trainer.predict(rtg_encoded[\"dev\"])\n",
        "  predictions = outputs.predictions.argmax(1)\n",
        "  labels = rtg_encoded[\"dev\"]['label']\n",
        "  cr = classification_report(labels, predictions, digits=3, output_dict=True)\n",
        "  negative_f1_score.append(cr.get('0').get(\"f1-score\"))\n",
        "  neutral_f1_score.append(cr.get('1').get(\"f1-score\"))\n",
        "  positive_f1_score.append(cr.get('2').get(\"f1-score\"))\n",
        "  mixed_f1_score.append(cr.get('3').get(\"f1-score\"))\n",
        "\n",
        "\n",
        "  print(f'---------------------------Iteration {i+1} Complete---------------------------\\n')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 21184\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5296\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5296' max='5296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5296/5296 08:44, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.589600</td>\n",
              "      <td>1.036714</td>\n",
              "      <td>0.672751</td>\n",
              "      <td>0.670450</td>\n",
              "      <td>0.565452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.320800</td>\n",
              "      <td>1.477628</td>\n",
              "      <td>0.673620</td>\n",
              "      <td>0.672882</td>\n",
              "      <td>0.571176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2648\n",
            "Configuration saved in results/checkpoint-2648/config.json\n",
            "Model weights saved in results/checkpoint-2648/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5296\n",
            "Configuration saved in results/checkpoint-5296/config.json\n",
            "Model weights saved in results/checkpoint-5296/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-2648 (score: 1.0367141962051392).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 21184\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 1 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5296' max='5296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5296/5296 08:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.217800</td>\n",
              "      <td>1.820308</td>\n",
              "      <td>0.675793</td>\n",
              "      <td>0.665568</td>\n",
              "      <td>0.556533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.181200</td>\n",
              "      <td>1.992797</td>\n",
              "      <td>0.664059</td>\n",
              "      <td>0.661245</td>\n",
              "      <td>0.556230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2648\n",
            "Configuration saved in results/checkpoint-2648/config.json\n",
            "Model weights saved in results/checkpoint-2648/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5296\n",
            "Configuration saved in results/checkpoint-5296/config.json\n",
            "Model weights saved in results/checkpoint-5296/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-2648 (score: 1.8203080892562866).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 21184\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 2 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5296' max='5296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5296/5296 08:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.109800</td>\n",
              "      <td>2.302059</td>\n",
              "      <td>0.650152</td>\n",
              "      <td>0.649771</td>\n",
              "      <td>0.548380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.140700</td>\n",
              "      <td>2.321678</td>\n",
              "      <td>0.665797</td>\n",
              "      <td>0.660011</td>\n",
              "      <td>0.557175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2648\n",
            "Configuration saved in results/checkpoint-2648/config.json\n",
            "Model weights saved in results/checkpoint-2648/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5296\n",
            "Configuration saved in results/checkpoint-5296/config.json\n",
            "Model weights saved in results/checkpoint-5296/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-2648 (score: 2.3020591735839844).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 21184\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 3 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5296' max='5296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5296/5296 08:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.065700</td>\n",
              "      <td>2.565919</td>\n",
              "      <td>0.667536</td>\n",
              "      <td>0.651474</td>\n",
              "      <td>0.536573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>2.481513</td>\n",
              "      <td>0.665797</td>\n",
              "      <td>0.657703</td>\n",
              "      <td>0.553636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2648\n",
            "Configuration saved in results/checkpoint-2648/config.json\n",
            "Model weights saved in results/checkpoint-2648/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5296\n",
            "Configuration saved in results/checkpoint-5296/config.json\n",
            "Model weights saved in results/checkpoint-5296/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-5296 (score: 2.481513261795044).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 21184\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 4 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5296' max='5296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5296/5296 08:45, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>2.885584</td>\n",
              "      <td>0.658409</td>\n",
              "      <td>0.649427</td>\n",
              "      <td>0.543324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.071300</td>\n",
              "      <td>2.831637</td>\n",
              "      <td>0.661452</td>\n",
              "      <td>0.656608</td>\n",
              "      <td>0.553101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2648\n",
            "Configuration saved in results/checkpoint-2648/config.json\n",
            "Model weights saved in results/checkpoint-2648/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5296\n",
            "Configuration saved in results/checkpoint-5296/config.json\n",
            "Model weights saved in results/checkpoint-5296/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-5296 (score: 2.831636667251587).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 5 Complete---------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmPCRDy4-fGh"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1UzIi5vYVrQ",
        "outputId": "62c63fef-95a2-4161-ff05-a648d697ff15"
      },
      "source": [
        "import statistics\n",
        "\n",
        "print(\"%15s %s (%s)\" % (\"\",\"Mean\", \"StDev\"))\n",
        "\n",
        "print(\"-\"*29)\n",
        "print(\"Macro Scores\")\n",
        "print(\"-\"*29)\n",
        "\n",
        "print(f\"%15s %s (%s)\" %(\"Accuracy\",\n",
        "    round(statistics.mean(accuracy_list),3),\n",
        "    round(statistics.stdev(accuracy_list),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Macro F1\",\n",
        "    round(statistics.mean(macro_f1_score_list),3),\n",
        "    round(statistics.stdev(macro_f1_score_list),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Weighted F1\",\n",
        "    round(statistics.mean(weighted_f1_score_list),3),\n",
        "    round(statistics.stdev(weighted_f1_score_list),3)))\n",
        "\n",
        "print(\"-\"*29)\n",
        "print(\"Class Scores\")\n",
        "print(\"-\"*29)\n",
        "\n",
        "print(f\"%15s %s (%s)\" %(\"Positive\",\n",
        "    round(statistics.mean(positive_f1_score),3),\n",
        "    round(statistics.stdev(positive_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Neutral\",\n",
        "    round(statistics.mean(neutral_f1_score),3),\n",
        "    round(statistics.stdev(neutral_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Negative\",\n",
        "    round(statistics.mean(negative_f1_score),3),\n",
        "    round(statistics.stdev(negative_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Mixed\",\n",
        "    round(statistics.mean(mixed_f1_score),3),\n",
        "    round(statistics.stdev(mixed_f1_score),3)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Mean (StDev)\n",
            "-----------------------------\n",
            "Macro Scores\n",
            "-----------------------------\n",
            "       Accuracy 0.665 (0.01)\n",
            "       Macro F1 0.555 (0.006)\n",
            "    Weighted F1  0.66 (0.008)\n",
            "-----------------------------\n",
            "Class Scores\n",
            "-----------------------------\n",
            "       Positive 0.815 (0.007)\n",
            "        Neutral 0.578 (0.021)\n",
            "       Negative 0.587 (0.011)\n",
            "          Mixed 0.241 (0.015)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eKt004BKjyT",
        "outputId": "47a2bb0e-1fdb-48d6-898d-5a3405f642b8"
      },
      "source": [
        "output_model_file = '/content/drive/MyDrive/w266/pytorch_bert_rtgender_sentiment_oversample.bin'\n",
        "output_vocab_file = './'\n",
        "\n",
        "model_to_save = model\n",
        "torch.save(model_to_save, output_model_file)\n",
        "tokenizer.save_vocabulary(output_vocab_file)\n",
        "\n",
        "print('All files saved')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1I3qA_jDRAk"
      },
      "source": [
        "# Parking Lot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlRNUAIsorxM"
      },
      "source": [
        "labels for sentiment\n",
        "{'Positive': 2, 'Mixed': 1, 'Neutral': 1, 'Negative':0}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t3JaMKw033s"
      },
      "source": [
        "# create dummy variables for target\n",
        "train_df = pd.get_dummies(train_df,columns=['sentiment'],drop_first=True, prefix = '', prefix_sep='')\n",
        "dev_df = pd.get_dummies(dev_df,columns=['sentiment'],drop_first=True, prefix = '', prefix_sep='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKMPm5kyy_G6"
      },
      "source": [
        "# convert to list\n",
        "train_df['list'] = train_df[train_df.columns[7:]].values.tolist()\n",
        "dev_df['list'] = dev_df[dev_df.columns[7:]].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baSmeDdIEadM"
      },
      "source": [
        "new_train = train_df[['response_text', 'list']]\n",
        "new_dev = dev_df[['response_text', 'list']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDGPhXrQasUu"
      },
      "source": [
        "https://colab.research.google.com/github/bhadreshpsavani/ExploringSentimentalAnalysis/blob/main/SentimentalAnalysisWithDistilbert.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDCDnWxKasCo"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"response_text\"], padding=True, truncation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJdhsT7Ga2o0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Q9NDdmqEyo"
      },
      "source": [
        "<a id='section03'></a>\n",
        "## Preprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvXxpfNCGER2"
      },
      "source": [
        "# Sections of config\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 150\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 2\n",
        "LEARNING_RATE = 1e-05\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
        "                                          do_lower_case = True,\n",
        "                                          do_basic_tokenize = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWP5cjTl2Jjc"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.comment_text = dataframe.response_text\n",
        "        self.targets = self.data.list\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        comment_text = str(self.comment_text[index])\n",
        "        comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REMD8uoq2KhA"
      },
      "source": [
        "train_data = new_train.reset_index(drop=True)\n",
        "dev_data = new_dev.reset_index(drop=True)\n",
        "\n",
        "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
        "print(\"DEV Dataset: {}\".format(dev_data.shape))\n",
        "\n",
        "training_set = CustomDataset(train_data, tokenizer, MAX_LEN)\n",
        "dev_set = CustomDataset(dev_data, tokenizer, MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1tInLk2Eadt"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "dev_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "dev_loader = DataLoader(dev_set, **dev_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZk0A9K8qE0C"
      },
      "source": [
        "<a id='section04'></a>\n",
        "### Creating the Neural Network for Fine Tuning\n",
        "\n",
        "#### Neural Network\n",
        " - We will be creating a neural network with the `BERTClass`. \n",
        " - This network will have the BERT Language model followed by a `dropout` and finally a `Linear` layer to obtain the final outputs. \n",
        " - Final layer outputs is what will be compared to the `Sentiment category` to determine the accuracy of models prediction. \n",
        " - We will initiate an instance of the network called `model`. This instance will be used for training and then to save the final trained model for future inference. \n",
        " \n",
        "#### Loss Function and Optimizer\n",
        " - `Loss Function` and `Optimizer` and defined in the next cell.\n",
        " - `Optimizer` is used to update the weights of the neural network to improve its performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMqQTafXEaei"
      },
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "%%capture\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        # self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 3)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      # output_2 = self.l2(output_1)\n",
        "      output = self.l3(output_1)\n",
        "      return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYZ7YuJ5InOS"
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDrEifFPnMK7"
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afXxXRFl55SZ"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%5000==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX7UdV2k58Hu"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEVh1DUKHpW3"
      },
      "source": [
        "## Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFiNcy16JLwt"
      },
      "source": [
        "def validation(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(dev_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcUylInzKdV-"
      },
      "source": [
        "f1_score_weighted = []\n",
        "accuracy = []\n",
        "\n",
        "for i in range(15):\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "      outputs, targets = validation(epoch)\n",
        "      outputs = np.array(outputs) >= 0.5\n",
        "      accuracy.append(metrics.accuracy_score(targets, outputs))\n",
        "      f1_score_weighted(metrics.f1_score(targets, outputs, average='weighted'))\n",
        "#      print(f\"Accuracy Score = {accuracy}\")\n",
        "#      print(f\"F1 Score (Weighted) = {f1_score_weighted}\")\n",
        "print(accuracy)\n",
        "print(f1_score_weighted)    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}