{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RtGender - Annotations - Sentiment - Greyscaling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "N7PAJ1oIJZfY"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "151486ca7bfa428586e7cba522ced8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e3281e0787b4d749da2f29906f2a65a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8de31ed6e92c44619127044ac9959e50",
              "IPY_MODEL_63e97823d8eb425a87f4da62d6985487",
              "IPY_MODEL_10f24d4f07784d87a5f3d5e07f8ecff8"
            ]
          }
        },
        "8e3281e0787b4d749da2f29906f2a65a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8de31ed6e92c44619127044ac9959e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2994d7f6088049b38eba247f6b263b33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a98dd5cd21024b6d9b14ff98c958f58d"
          }
        },
        "63e97823d8eb425a87f4da62d6985487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a8b3093567a4527b641e5b24f2643bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2f6cc3fa62d4d2bb87239ed3e00aa79"
          }
        },
        "10f24d4f07784d87a5f3d5e07f8ecff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5636ddc59bab40b2a4c270518aa008b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:04&lt;00:00,  4.24s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b0438ba68f84351a6334f9f28f91725"
          }
        },
        "2994d7f6088049b38eba247f6b263b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a98dd5cd21024b6d9b14ff98c958f58d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a8b3093567a4527b641e5b24f2643bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2f6cc3fa62d4d2bb87239ed3e00aa79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5636ddc59bab40b2a4c270518aa008b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b0438ba68f84351a6334f9f28f91725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cddc241d862d431a9f11b16496546cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9935af1140344113bb9c8adc36bc08ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3813f270badc4d638bf630d2ab6df2e6",
              "IPY_MODEL_3a72e84d8e87491c9127fcfe3dc7fe16",
              "IPY_MODEL_60aaab40ba0041589d8286b5bb9e3314"
            ]
          }
        },
        "9935af1140344113bb9c8adc36bc08ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3813f270badc4d638bf630d2ab6df2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11b33b34c98a49bca94820e5a5e46254",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4b61ce8d8674d129f344aa84ead706a"
          }
        },
        "3a72e84d8e87491c9127fcfe3dc7fe16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ef63434504c4665b5b31a4463add82e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a456a084b1447bdad1e7d00aa3ca382"
          }
        },
        "60aaab40ba0041589d8286b5bb9e3314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_17125ee3909b41c7b3fa2f034ab53c4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  6.51ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab6a3ef6c6fc4d169383afc045ec9a71"
          }
        },
        "11b33b34c98a49bca94820e5a5e46254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4b61ce8d8674d129f344aa84ead706a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ef63434504c4665b5b31a4463add82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a456a084b1447bdad1e7d00aa3ca382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17125ee3909b41c7b3fa2f034ab53c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab6a3ef6c6fc4d169383afc045ec9a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipietri/w266_Final_Project/blob/master/notebooks/RtGender-Notebooks/RtGender_Annotations_Sentiment_Grayscaling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OhO4xlwqExT"
      },
      "source": [
        "# RtGender - Annotations - Sentiment w/ Grayscaling\n",
        "[Code Source](https://github.com/ainagari/scalar_adjs)\n",
        "\n",
        "* [BERT Knows Punta Cana is not just beautiful, it’s gorgeous:\n",
        "Ranking Scalar Adjectives with Contextualised Representations](https://aclanthology.org/2020.emnlp-main.598.pdf)\\\n",
        "*[Scalar Adjective Identification and Multilingual Ranking\n",
        "](https://arxiv.org/abs/2105.01180)\\\n",
        "*[Identifying and Ordering Scalar Adjectives Using Lexical Substitution](https://www.proquest.com/openview/aade435a5bbdcf41e2b8c24e648826cc/1.pdf?pq-origsite=gscholar&cbl=18750)\\\n",
        "*[A Gold Standard for Scalar Adjectives](https://aclanthology.org/L16-1424/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cirVs78YksXS",
        "outputId": "b9dbc583-da2a-41b0-af3e-e78741e8589e"
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  path = r'/content/drive/MyDrive/w266'\n",
        "except ModuleNotFoundError:\n",
        "  path = r'data'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7PAJ1oIJZfY"
      },
      "source": [
        "<a id='section01'></a>\n",
        "## Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "p--X9MlxQP05",
        "outputId": "0f999eef-f3f4-4555-e9e3-c2c1bd43389f"
      },
      "source": [
        "#!pip install -U nltk\n",
        "import nltk; nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-GlywkSFegL"
      },
      "source": [
        "%%capture\n",
        "#!pip install transformers==3.0.2\n",
        "!pip install -q transformers\n",
        "#!pip install pymagnitude"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IV4cb3abmJP"
      },
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "import datasets \n",
        "from datasets import load_dataset, Dataset, DatasetDict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "979OUro5Eac3"
      },
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "#from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb1Q5N6LGK7z"
      },
      "source": [
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-eMCGrpkQ1E"
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "import sys\n",
        "from scipy.spatial.distance import cosine\n",
        "from operator import itemgetter\n",
        "from collections import defaultdict\n",
        "#from pymagnitude import *\n",
        "import argparse\n",
        "\n",
        "import itertools"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VcTXavwcTzGT",
        "outputId": "1a9f0239-e632-422a-a65d-f8ead7afca8a"
      },
      "source": [
        "# import eda script from github\n",
        "!git clone https://github.com/ainagari/scalar_adjs"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'scalar_adjs'...\n",
            "remote: Enumerating objects: 854, done.\u001b[K\n",
            "remote: Counting objects: 100% (438/438), done.\u001b[K\n",
            "remote: Compressing objects: 100% (189/189), done.\u001b[K\n",
            "remote: Total 854 (delta 91), reused 358 (delta 45), pack-reused 416\u001b[K\n",
            "Receiving objects: 100% (854/854), 13.47 MiB | 4.40 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HucjuuC6RGk"
      },
      "source": [
        "# import fucntions from scalar_adjs\n",
        "import sys\n",
        "\n",
        "# sys.path is a list of absolute path strings\n",
        "sys.path.append('/content/scalar_adjs/')\n",
        "\n",
        "from read_scalar_datasets import read_scales\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hErgyoZRHSA3"
      },
      "source": [
        "<a id='section02'></a>\n",
        "# Import and Reshape Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J3FzcAlgEac8",
        "outputId": "04aa44c0-0175-4714-d01b-e8798b6cb339"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/w266/train_oversampled.csv')\n",
        "dev_df = pd.read_csv('/content/drive/MyDrive/w266/annotations_dev.csv')\n",
        "\n",
        "print('train_shape: ',train_df.shape)\n",
        "print('dev_shape: ',dev_df.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_shape:  (21184, 9)\n",
            "dev_shape:  (2303, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IYDrLGC8Vs8I",
        "outputId": "6f9aa09d-9023-4bcd-9286-35f6ad61fc83"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>source</th>\n",
              "      <th>op_gender</th>\n",
              "      <th>post_text</th>\n",
              "      <th>response_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>relevance</th>\n",
              "      <th>label</th>\n",
              "      <th>labels_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3845</td>\n",
              "      <td>facebook_congress</td>\n",
              "      <td>W</td>\n",
              "      <td>Im reading the 3/1 GAO report that finds billi...</td>\n",
              "      <td>Thank you Congresswoman Bass. Keep up the grea...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>ContentPoster</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9743</td>\n",
              "      <td>fitocracy</td>\n",
              "      <td>M</td>\n",
              "      <td>Being followed by the famous DBJ? Quite an honor.</td>\n",
              "      <td>Well, I am very honored you feel so honored</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Content</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13041</td>\n",
              "      <td>ted</td>\n",
              "      <td>W</td>\n",
              "      <td>Penelope Boston gave a talk about Planets, exp...</td>\n",
              "      <td>Her opinions seem driven by wishful thinking. ...</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Content</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4265</td>\n",
              "      <td>facebook_congress</td>\n",
              "      <td>W</td>\n",
              "      <td>Congress must act to help the 41 million Ameri...</td>\n",
              "      <td>There's no other way out of the enormity excep...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Content</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13145</td>\n",
              "      <td>ted</td>\n",
              "      <td>W</td>\n",
              "      <td>Pardis Sabeti gave a talk about Africa, big pr...</td>\n",
              "      <td>What were the benefits of the larger community...</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Content</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21179</th>\n",
              "      <td>6561</td>\n",
              "      <td>facebook_congress</td>\n",
              "      <td>W</td>\n",
              "      <td>It was terrific to have the chance to hear fro...</td>\n",
              "      <td>\"Committed to making sure we don't lose our he...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Poster</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21180</th>\n",
              "      <td>3829</td>\n",
              "      <td>facebook_congress</td>\n",
              "      <td>M</td>\n",
              "      <td>Johnny will join Tim Bryant on WGAU 1340 AM (A...</td>\n",
              "      <td>Both Isakson and Chambliss voted to TABLE Rand...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Poster</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21181</th>\n",
              "      <td>11700</td>\n",
              "      <td>reddit</td>\n",
              "      <td>W</td>\n",
              "      <td>It wouldnt disintegrate you.</td>\n",
              "      <td>I think a magic beam of pure light would disin...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Content</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21182</th>\n",
              "      <td>5668</td>\n",
              "      <td>facebook_congress</td>\n",
              "      <td>M</td>\n",
              "      <td>Our contest for a chance to attend a special c...</td>\n",
              "      <td>I'd rather have a root canal . . .</td>\n",
              "      <td>Negative</td>\n",
              "      <td>ContentPoster</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21183</th>\n",
              "      <td>5920</td>\n",
              "      <td>facebook_congress</td>\n",
              "      <td>W</td>\n",
              "      <td>Looking forward to appearing on the Alex Witt ...</td>\n",
              "      <td>You get elected to lead....then you get on TV ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>ContentPoster</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21184 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0             source op_gender  ...      relevance label labels_4\n",
              "0            3845  facebook_congress         W  ...  ContentPoster     2        2\n",
              "1            9743          fitocracy         M  ...        Content     2        2\n",
              "2           13041                ted         W  ...        Content     1        3\n",
              "3            4265  facebook_congress         W  ...        Content     2        2\n",
              "4           13145                ted         W  ...        Content     1        3\n",
              "...           ...                ...       ...  ...            ...   ...      ...\n",
              "21179        6561  facebook_congress         W  ...         Poster     0        0\n",
              "21180        3829  facebook_congress         M  ...         Poster     0        0\n",
              "21181       11700             reddit         W  ...        Content     0        0\n",
              "21182        5668  facebook_congress         M  ...  ContentPoster     0        0\n",
              "21183        5920  facebook_congress         W  ...  ContentPoster     0        0\n",
              "\n",
              "[21184 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ntnIM3pjdQ2C",
        "outputId": "62649256-34d8-4cec-870a-a5e8cce39cb8"
      },
      "source": [
        "# there are NaNs in the dev dataset remove \n",
        "nan_values = dev_df[dev_df.isna().any(axis=1)] \n",
        "print(nan_values)\n",
        "\n",
        "# return without missing values in response_text\n",
        "dev_df.dropna(subset = [\"response_text\"], inplace=True)\n",
        "\n",
        "print(\"Train shape\", train_df.shape)\n",
        "print(\"Dev shape\", dev_df.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0         source op_gender  ...   relevance label labels_4\n",
            "830         2576  facebook_wiki         M  ...  Irrelevant     1        1\n",
            "1664        2722  facebook_wiki         W  ...  Irrelevant     1        1\n",
            "\n",
            "[2 rows x 9 columns]\n",
            "Train shape (21184, 9)\n",
            "Dev shape (2301, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "k9BHmHVnbaJm",
        "outputId": "48b9e88d-a0de-4975-b62c-a08f9f894bc4"
      },
      "source": [
        "print(\"Unique sentiments: \", train_df['sentiment'].unique())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique sentiments:  ['Positive' 'Mixed' 'Neutral' 'Negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vki-cYpURWf4"
      },
      "source": [
        "# Greyscale\n",
        "Adapted from Scalar Adj Code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMxa-W_awyUI"
      },
      "source": [
        "# [Extract Relevant Text](https://github.com/ainagari/scalar_adjs/blob/master/extract_flickr_scalar.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzYGg8Nfukpr"
      },
      "source": [
        "import pickle\n",
        "import pdb\n",
        "import spacy\n",
        "import os\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "language_str = \"en\" #set to english -- one dataset in English only"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vswkCWT-ewNj"
      },
      "source": [
        "### Identify the location of every word present the three types of scales\n",
        "Extract and save out as a dictionary for every example that contains at least one scaled word. Adapted from extract_flickr_scalar.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y5gFIVbveKy"
      },
      "source": [
        "rankings = dict()\n",
        "datanames = [\"demelo\", \"crowd\", \"wilkinson\"]\n",
        "for dataname in datanames:\n",
        "    r = read_scales(\"/content/scalar_adjs/data/\" + dataname + \"/gold_rankings/\")\n",
        "    rankings[dataname] = r\n",
        "\n",
        "my_words = set()\n",
        "for dataname in rankings:\n",
        "    for scale in rankings[dataname]:\n",
        "        for word in rankings[dataname][scale]:\n",
        "            words = word.split(\" || \")\n",
        "            for w in words:\n",
        "                my_words.add(w)\n",
        "\n",
        "word_sentence_dict = dict()\n",
        "for word in my_words:\n",
        "    word_sentence_dict[word] = set()\n",
        "\n",
        "def accepted_pos(pos):\n",
        "    if pos in [\"ADJ\",\"ADV\", \"ADP\",\"VERB\",\"DET\"]:\n",
        "        return True\n",
        "    return False\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiDXVUW7Vn_y"
      },
      "source": [
        "## Identify the position of the word which exists in any of the scales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rT3mxLL4wJ7"
      },
      "source": [
        "## Toy example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "7UBya26gV02M",
        "outputId": "4b40f9c9-7143-4d32-d6e6-da78b7a73ac4"
      },
      "source": [
        "mini_train_df = train_df[1:100]\n",
        "mini_train_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>source</th>\n",
              "      <th>op_gender</th>\n",
              "      <th>post_text</th>\n",
              "      <th>response_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>relevance</th>\n",
              "      <th>label</th>\n",
              "      <th>labels_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9743</td>\n",
              "      <td>fitocracy</td>\n",
              "      <td>M</td>\n",
              "      <td>Being followed by the famous DBJ? Quite an honor.</td>\n",
              "      <td>Well, I am very honored you feel so honored</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Content</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13041</td>\n",
              "      <td>ted</td>\n",
              "      <td>W</td>\n",
              "      <td>Penelope Boston gave a talk about Planets, exp...</td>\n",
              "      <td>Her opinions seem driven by wishful thinking. ...</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Content</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4265</td>\n",
              "      <td>facebook_congress</td>\n",
              "      <td>W</td>\n",
              "      <td>Congress must act to help the 41 million Ameri...</td>\n",
              "      <td>There's no other way out of the enormity excep...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Content</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13145</td>\n",
              "      <td>ted</td>\n",
              "      <td>W</td>\n",
              "      <td>Pardis Sabeti gave a talk about Africa, big pr...</td>\n",
              "      <td>What were the benefits of the larger community...</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Content</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>743</td>\n",
              "      <td>facebook_wiki</td>\n",
              "      <td>M</td>\n",
              "      <td>Happy New Day from CNN's Studio 71 where the L...</td>\n",
              "      <td>I'm looking forward to seeing some *Good News*...</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Content</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0             source op_gender  ... relevance label labels_4\n",
              "1        9743          fitocracy         M  ...   Content     2        2\n",
              "2       13041                ted         W  ...   Content     1        3\n",
              "3        4265  facebook_congress         W  ...   Content     2        2\n",
              "4       13145                ted         W  ...   Content     1        3\n",
              "5         743      facebook_wiki         M  ...   Content     1        3\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fod_2GUQ4_Gh"
      },
      "source": [
        "## Create Scaled Dictionaries with Grey Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77YAYRVDc2xb"
      },
      "source": [
        "# create a nested dictionary with every scale, scale list with equalities, and all words in the scale\n",
        "\n",
        "import collections\n",
        "\n",
        "scales_dict = collections.defaultdict(dict)\n",
        "\n",
        "for dataname in datanames:\n",
        "  for scale_file_name, scale in rankings[dataname].items():\n",
        "    words_in_scale = []\n",
        "    for ws in scale:\n",
        "      # split if there are ties\n",
        "      words_in_scale.extend(ws.split(\" || \"))\n",
        "    scales_dict[dataname][str(scale)] = tuple(words_in_scale)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM_7-hjn5DRS"
      },
      "source": [
        "  Since there are ties in our scales\n",
        "  the milder word may be one or more words.\n",
        "  So if the original word is foo || bar and the \n",
        "  milder word is foolish || barish this \n",
        "  {foo: foolish, foo: barish, bar: foolish,  bar: barish}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvfsP1y8jJwz"
      },
      "source": [
        "scales_with_milder_option = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(dict)))\n",
        "\n",
        "### iterate through temp dictionaries and create a master dictionary\n",
        "for data_name in datanames:\n",
        "  for scale_name, words in scales_dict[data_name].items():\n",
        "    '''\n",
        "    Sample input: scale_name = ['harmful', 'toxic', 'deadly']\n",
        "    Sample output: {'deadly': ['harmful', 'toxic'], 'toxic': ['harmful']}\n",
        "    '''\n",
        "    ### convert key from string to list\n",
        "    # drop first and last characters which are brackets[]\n",
        "    scale_name = scale_name[2:-1].replace(\"'\", \"\")\n",
        "    scale_name = scale_name.split(\", \") \n",
        "\n",
        "    while len(scale_name) > 1:\n",
        "      most_extreme_words = scale_name[-1].split(\" || \")\n",
        "      \n",
        "      milder_words = scale_name[:-1]\n",
        "      milder_list = []\n",
        "      for words in milder_words:\n",
        "        milder_list.extend(words.split(\" || \"))\n",
        "      instance = dict(itertools.product(most_extreme_words, milder_list))\n",
        "\n",
        "      for k in most_extreme_words:\n",
        "          scales_with_milder_option[data_name][k] = milder_list\n",
        "      \n",
        "      # drop most extreme terms\n",
        "      scale_name.pop()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK-UMglqn50l",
        "outputId": "77b998de-5990-40f1-b48b-d2a50267906b"
      },
      "source": [
        "def locate_scale_word(test_col, label_col):\n",
        "  '''\n",
        "  return a column with any scale_words \n",
        "  in the text column and their position\n",
        "  '''\n",
        "  more_test = collections.defaultdict(lambda: collections.defaultdict(dict))\n",
        "  for data_name in datanames:\n",
        "      for scale_name, words in scales_dict[data_name].items():\n",
        "        for word in words:\n",
        "          # convert text into a list of words to avoid partial matches found using .find()\n",
        "          \n",
        "          sentence_words = test_col.replace(\"'\", \"\") \n",
        "          sentence_words = sentence_words.lower().split(\" \")\n",
        "          \n",
        "          if word in sentence_words:\n",
        "            pos = sentence_words.index(word)\n",
        "         #   more_test[data_name]['label'] = label_col\n",
        "            # assume only one word to be replaced\n",
        "            more_test[data_name][word]['position'] = int(pos)\n",
        "          #  more_test[data_name]['sentence'][word] = test_col\n",
        "            more_test[data_name][word]['milder_words'] = scales_with_milder_option[data_name][word]\n",
        "            \n",
        "\n",
        "  return more_test\n",
        "\n",
        "train_df['new_col'] = train_df.apply(lambda x: locate_scale_word(x['response_text'], x['labels_4']), axis = 1)\n",
        "train_df.iloc[1]['new_col']"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.locate_scale_word.<locals>.<lambda>>, {})"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moetrn9Ml5TR"
      },
      "source": [
        "# convert relevant df columns to dictionary\n",
        "dict_from_df = train_df[['response_text', 'labels_4','new_col']].T.to_dict()"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AcyNtFvzJZC",
        "outputId": "9e6b73f0-f705-4347-a3a4-c9055c3bea6d"
      },
      "source": [
        "dict_from_df[3]"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels_4': 2,\n",
              " 'new_col': defaultdict(<function __main__.locate_scale_word.<locals>.<lambda>>,\n",
              "             {'demelo': defaultdict(dict,\n",
              "                          {'clean': {'milder_words': defaultdict(dict, {}),\n",
              "                            'position': 17},\n",
              "                           'far': {'milder_words': defaultdict(dict, {}),\n",
              "                            'position': 38}})}),\n",
              " 'response_text': \"There's no other way out of the enormity except to forgive the debt and start with a clean slate. Otherwise, this is going to lead to the next collapse in the U.S. economy, which will result in far, far more cost to every American.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "AI_wu667BHEQ",
        "outputId": "e9b6182e-4297-4d08-cf9b-da09947070b0"
      },
      "source": [
        "dict_from_df[3]['response_text']"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"There's no other way out of the enormity except to forgive the debt and start with a clean slate. Otherwise, this is going to lead to the next collapse in the U.S. economy, which will result in far, far more cost to every American.\""
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wJRNe_L8W4v",
        "outputId": "dec3d8d7-b674-401e-b648-cefab71b6816"
      },
      "source": [
        "sentence_words = dict_from_df[3]['response_text'].replace(\"'\", \"\")\n",
        "sentence_words = sentence_words.split(\" \") \n",
        "sentence_words.index('clean')"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrpzm3_iXjq0",
        "outputId": "6805d760-d30c-48f3-b791-930265e61552"
      },
      "source": [
        "for i in dict_from_df[8]['new_col']['crowd']['pretty']['milder_words']:\n",
        "  print(i)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6A-jtFgzV0Q"
      },
      "source": [
        "# Augment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phGv973SUOmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a3605d-815a-49be-afc7-571f66b433db"
      },
      "source": [
        "from transformers import BertTokenizer, BertConfig, BertModel, AutoTokenizer, AutoModel, FlaubertTokenizer, FlaubertModel, AutoConfig, FlaubertConfig\n",
        "\n",
        "language_str = \"en\"\n",
        "#whether we exclude the last bpe of words when words are split into multiple wordpieces\n",
        "exclude_last_bpe =\"True\"\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "#sentences = train_df['response_text']"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYoJZkPznrsb"
      },
      "source": [
        "# from extract_representations.py\n",
        "def special_tokenization(sentence, tokenizer, model_name):\n",
        "    map_ori_to_bert = []\n",
        "    if \"flaubert\" in model_name:\n",
        "        tok_sent = ['<s>']\n",
        "    else:\n",
        "        tok_sent = ['[CLS]']\n",
        "\n",
        "    for orig_token in sentence.split():\n",
        "        current_tokens_bert_idx = [len(tok_sent)]\n",
        "        bert_token = tokenizer.tokenize(orig_token) # tokenize\n",
        "        tok_sent.extend(bert_token) # add to my new tokens\n",
        "        if len(bert_token) > 1: # if the new token has been 'wordpieced'\n",
        "            extra = len(bert_token) - 1\n",
        "            for i in range(extra):\n",
        "                current_tokens_bert_idx.append(current_tokens_bert_idx[-1]+1) # list of new positions of the target word in the new tokenization\n",
        "        map_ori_to_bert.append(tuple(current_tokens_bert_idx))\n",
        "\n",
        "    if \"flaubert\" in model_name:\n",
        "        tok_sent.append('</s>')\n",
        "    else:\n",
        "        tok_sent.append('[SEP]')\n",
        "\n",
        "    return tok_sent, map_ori_to_bert\n"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXo8SeYksW3o"
      },
      "source": [
        "import copy\n",
        "infos = []\n",
        "final_dict = []\n",
        "labels_list = []\n",
        "augmented_text_list = []\n",
        "\n",
        "#collections.defaultdict(lambda: collections.defaultdict(dict))\n",
        "# collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(dict))))\n",
        "\n",
        "for id, values in dict_from_df.items():\n",
        "  num_positions = 0\n",
        "  for data_name in datanames:\n",
        "    # number of word positions for replacement\n",
        "    num_positions += len(dict_from_df[id]['new_col'][data_name])\n",
        "\n",
        "    if num_positions == 0:\n",
        "      continue\n",
        "\n",
        "    else:\n",
        "      for word, values in dict_from_df[id]['new_col'][data_name].items():\n",
        "        num_mild_words = len(dict_from_df[id]['new_col'][data_name][word]['milder_words'])\n",
        "        \n",
        "        if num_mild_words == 0:\n",
        "          continue\n",
        "\n",
        "        else:\n",
        "          # assume the word is only in one location in the example text\n",
        "          position_scaleword = dict_from_df[id]['new_col'][data_name][word]['position']\n",
        "          cinstance = dict()\n",
        "          cinstance['response_text'] = copy.deepcopy(dict_from_df[id]['response_text'])\n",
        "\n",
        "          # convert text to a list\n",
        "          sentence_words = dict_from_df[id]['response_text'].replace(\"'\", \"\") \n",
        "          sentence_words = sentence_words.split(\" \")\n",
        "          for scale_word in dict_from_df[id]['new_col'][data_name][word]['milder_words']:\n",
        "\n",
        "            # change a to an and vice versa depending on first letter of the scaleword \n",
        "            if sentence_words[position_scaleword-1] == \"a\" and scale_word[0] in \"aeiou\":\n",
        "              sentence_words[position_scaleword-1] = \"an\"\n",
        "            elif sentence_words[position_scaleword-1] == \"an\" and scale_word[0] not in \"aeiou\":\n",
        "              sentence_words[position_scaleword-1] = \"a\"\n",
        "            \n",
        "            # and replace the scaleword\n",
        "            sentence_words[position_scaleword] = scale_word\n",
        "              \n",
        "            # scaleword_position = cinstance[\"position\"]\n",
        "            cinstance[\"position\"] = [position_scaleword]# = [cinstance[0].get(\"position\")]\n",
        "            \n",
        "            ## extract and tokenize the original sentence\n",
        "            example = ' '.join(sentence_words)\n",
        "\n",
        "            # add augmented text to final dictionary\n",
        "            test_df.loc[len(test_df)] = [dict_from_df[id]['labels_4'], \n",
        "                                         ' '.join(sentence_words)]\n",
        "            labels_list.append(dict_from_df[id]['labels_4'])\n",
        "            augmented_text_list.append(' '.join(sentence_words))\n",
        "\n",
        "            bert_tokenized_sentence, mapp = special_tokenization(example, tokenizer, model_name)\n",
        "            \n",
        "            current_positions = cinstance['position']\n",
        "            if len(current_positions) == 1:\n",
        "                bert_position = mapp[cinstance['position'][0]] # this is a list of positions (it might have been split into wordpieces)\n",
        "            elif len(current_positions) > 1:\n",
        "              bert_position = []\n",
        "              for p in current_positions:\n",
        "                  bert_position.extend(mapp[p])\n",
        "            \n",
        "            cinstance[id] = id\n",
        "            cinstance[\"bert_tokenized_sentence\"] = bert_tokenized_sentence\n",
        "            cinstance[\"bert_position\"] = bert_position\n",
        "            cinstance[\"scale\"] = scale\n",
        "            cinstance[\"lemma\"] = scale_word\n",
        "            infos.append(cinstance)\n"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g57XalZjDNc"
      },
      "source": [
        "# Pre-process "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2W5K-QhuP6x"
      },
      "source": [
        "# append the augmented data plus labels\n",
        "\n",
        "test_list = list(zip(labels_list, augmented_text_list))\n",
        "train_df_aug = train_df.append(pd.DataFrame(test_list,\n",
        "                                      columns = ['labels_4', 'response_text']),\n",
        "                         ignore_index = True)\n",
        "# save out greyscale adjusted dataset\n",
        "train_df_aug.to_csv('/content/drive/MyDrive/w266/grey_scaled_augmented_oversampled_train_data.csv', index=False)\n",
        "\n",
        "train_df_aug = train_df_aug.drop(['Unnamed: 0', 'source', 'op_gender', 'post_text', 'sentiment', 'relevance', 'label',  'new_col'], axis = 1)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrUpD9HgjQ1f"
      },
      "source": [
        "## Transform into Hugging Friendly Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCBZbwZG1P8s"
      },
      "source": [
        "# change to dataset to work with Huggingface transformer & remove unused columns\n",
        "columns_to_remove = ['op_gender', 'source', 'Unnamed: 0', 'relevance', 'sentiment', 'post_text','label']\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df_aug)\n",
        "dev_dataset = Dataset.from_pandas(dev_df)\n",
        "\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= columns_to_remove)\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= '__index_level_0__')\n",
        "\n",
        "\n",
        "# rename labels_4 to labels\n",
        "train_dataset = train_dataset.rename_column(\"labels_4\", \"label\")\n",
        "dev_dataset = dev_dataset.rename_column(\"labels_4\", \"label\")"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJj0RTQVjUqC"
      },
      "source": [
        "train_dataset = Dataset.from_pandas(train_df_aug)\n",
        "dev_dataset = Dataset.from_pandas(dev_df)\n",
        "\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= columns_to_remove)\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= '__index_level_0__')\n",
        "\n",
        "# rename sentiment to labels\n",
        "train_dataset = train_dataset.rename_column(\"labels_4\", \"label\")\n",
        "dev_dataset = dev_dataset.rename_column(\"labels_4\", \"label\")"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wWAUlGE23Os",
        "outputId": "561d9717-8cd6-4666-aeca-f1138ce91f6c"
      },
      "source": [
        "# combine into a DataDictionary for huggingface use\n",
        "rtg_dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'dev': dev_dataset \n",
        "})\n",
        "\n",
        "rtg_dataset"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['response_text', 'label'],\n",
              "        num_rows: 40817\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['response_text', 'label'],\n",
              "        num_rows: 2301\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PE9TY9o3Sg6"
      },
      "source": [
        "# Tokenize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2X4Zwzr3SKw",
        "outputId": "edce9b72-d60d-429c-a9ec-790dad34da42"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "max_length = train_df['response_text'].astype(str).map(len).quantile(0.99).astype(int)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, max_length = int(max_length))\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"response_text\"], padding=True, truncation=True)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_length\": 289,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "151486ca7bfa428586e7cba522ced8f0",
            "8e3281e0787b4d749da2f29906f2a65a",
            "8de31ed6e92c44619127044ac9959e50",
            "63e97823d8eb425a87f4da62d6985487",
            "10f24d4f07784d87a5f3d5e07f8ecff8",
            "2994d7f6088049b38eba247f6b263b33",
            "a98dd5cd21024b6d9b14ff98c958f58d",
            "6a8b3093567a4527b641e5b24f2643bc",
            "d2f6cc3fa62d4d2bb87239ed3e00aa79",
            "5636ddc59bab40b2a4c270518aa008b5",
            "8b0438ba68f84351a6334f9f28f91725",
            "cddc241d862d431a9f11b16496546cb1",
            "9935af1140344113bb9c8adc36bc08ec",
            "3813f270badc4d638bf630d2ab6df2e6",
            "3a72e84d8e87491c9127fcfe3dc7fe16",
            "60aaab40ba0041589d8286b5bb9e3314",
            "11b33b34c98a49bca94820e5a5e46254",
            "a4b61ce8d8674d129f344aa84ead706a",
            "5ef63434504c4665b5b31a4463add82e",
            "1a456a084b1447bdad1e7d00aa3ca382",
            "17125ee3909b41c7b3fa2f034ab53c4a",
            "ab6a3ef6c6fc4d169383afc045ec9a71"
          ]
        },
        "id": "T8u9yQdZ3RjN",
        "outputId": "868e06de-782e-4952-d098-2fa621c036b3"
      },
      "source": [
        "rtg_encoded = rtg_dataset.map(tokenize, batched=True, batch_size=None)\n",
        "rtg_encoded['train'].features"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "151486ca7bfa428586e7cba522ced8f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cddc241d862d431a9f11b16496546cb1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'label': Value(dtype='int64', id=None),\n",
              " 'response_text': Value(dtype='string', id=None),\n",
              " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeGuzSZK4EI0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlt8MZae3PbD",
        "outputId": "fbb221f3-7c2c-4a64-e6e5-c162b35c671d"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "num_labels = 4\n",
        "epochs = 2\n",
        "iterations = 5\n",
        "model = (AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device))"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-lbumOp4GfJ",
        "outputId": "886cd935-f064-4171-d1dc-796992bfb03f"
      },
      "source": [
        "rtg_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# check the type for each feature\n",
        "rtg_encoded[\"dev\"].features"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'label': Value(dtype='int64', id=None),\n",
              " 'response_text': Value(dtype='string', id=None),\n",
              " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBfk25D94H7Z"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
        "    f1_macro = f1_score(labels, preds, average = 'macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1_weighted, \"f1_macro\": f1_macro} "
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pnJ9_Vt4Jia",
        "outputId": "15cb3f24-2ef6-47c9-94e2-1592504bf8d7"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 8\n",
        "logging_steps = len(rtg_encoded[\"train\"]) // batch_size\n",
        "training_args = TrainingArguments(output_dir=\"results\",\n",
        "                                  num_train_epochs=epochs,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  load_best_model_at_end=False,\n",
        "                                 # metric_for_best_model=\"f1_macro\",\n",
        "                                 # weight_decay=0.01,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                #  save_strategy=\"epoch\",\n",
        "                                  disable_tqdm=False\n",
        "                                  )"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JdM1WXA04Lz-",
        "outputId": "bb2d1e91-4fbd-49bc-f239-1b19d7c6ad04"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "accuracy_list = []\n",
        "weighted_f1_score_list = []\n",
        "macro_f1_score_list = []\n",
        "negative_f1_score = []\n",
        "neutral_f1_score = []\n",
        "mixed_f1_score = []\n",
        "positive_f1_score = []\n",
        "\n",
        "\n",
        "for i in range(iterations):\n",
        "  try:\n",
        "    del trainer\n",
        "    del results\n",
        "    del cr\n",
        "  except: pass\n",
        "\n",
        "\n",
        "  trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=rtg_encoded[\"train\"],\n",
        "                  eval_dataset=rtg_encoded[\"dev\"])\n",
        "  trainer.train()\n",
        "  results = trainer.evaluate()\n",
        "\n",
        "  # append macro metrics to lists\n",
        "  accuracy_list.append(results.get('eval_accuracy'))\n",
        "  weighted_f1_score_list.append(results.get(\"eval_f1\"))\n",
        "  macro_f1_score_list.append(results.get(\"eval_f1_macro\"))\n",
        "\n",
        "  trainer.predict(rtg_encoded[\"dev\"])\n",
        "  # append the class-level F1 scores\n",
        "  outputs = trainer.predict(rtg_encoded[\"dev\"])\n",
        "  predictions = outputs.predictions.argmax(1)\n",
        "  labels = rtg_encoded[\"dev\"]['label']\n",
        "  cr = classification_report(labels, predictions, digits=3, output_dict=True)\n",
        "  negative_f1_score.append(cr.get('0').get(\"f1-score\"))\n",
        "  neutral_f1_score.append(cr.get('1').get(\"f1-score\"))\n",
        "  positive_f1_score.append(cr.get('2').get(\"f1-score\"))\n",
        "  mixed_f1_score.append(cr.get('3').get(\"f1-score\"))\n",
        "\n",
        "\n",
        "  print(f'---------------------------Iteration {i+1} Complete---------------------------\\n')"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 40817\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10206\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10206' max='10206' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10206/10206 17:46, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.281000</td>\n",
              "      <td>1.548057</td>\n",
              "      <td>0.664059</td>\n",
              "      <td>0.655926</td>\n",
              "      <td>0.550990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>1.973267</td>\n",
              "      <td>0.673620</td>\n",
              "      <td>0.665973</td>\n",
              "      <td>0.563731</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 40817\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 1 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10206' max='10206' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10206/10206 17:31, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>2.541944</td>\n",
              "      <td>0.639722</td>\n",
              "      <td>0.639758</td>\n",
              "      <td>0.534619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.062000</td>\n",
              "      <td>2.501655</td>\n",
              "      <td>0.662321</td>\n",
              "      <td>0.651957</td>\n",
              "      <td>0.547058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 40817\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 2 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10206' max='10206' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10206/10206 17:32, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.029500</td>\n",
              "      <td>2.823220</td>\n",
              "      <td>0.654498</td>\n",
              "      <td>0.637388</td>\n",
              "      <td>0.521529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.028100</td>\n",
              "      <td>2.888439</td>\n",
              "      <td>0.651456</td>\n",
              "      <td>0.641710</td>\n",
              "      <td>0.534598</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 40817\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 3 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10206' max='10206' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10206/10206 17:34, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.024600</td>\n",
              "      <td>3.305914</td>\n",
              "      <td>0.626249</td>\n",
              "      <td>0.630576</td>\n",
              "      <td>0.527584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.029200</td>\n",
              "      <td>3.207432</td>\n",
              "      <td>0.652325</td>\n",
              "      <td>0.644541</td>\n",
              "      <td>0.542503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 40817\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 4 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10206' max='10206' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10206/10206 17:18, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.024200</td>\n",
              "      <td>3.403502</td>\n",
              "      <td>0.642764</td>\n",
              "      <td>0.637392</td>\n",
              "      <td>0.535186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.026100</td>\n",
              "      <td>3.387181</td>\n",
              "      <td>0.654933</td>\n",
              "      <td>0.643076</td>\n",
              "      <td>0.536609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 5 Complete---------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l2tLYmc56bW"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzcRzODY57oH",
        "outputId": "7f7edf1a-582f-4b59-e8d5-fec4dba5410a"
      },
      "source": [
        "import statistics\n",
        "\n",
        "print(\"%15s %s (%s)\" % (\"\",\"Mean\", \"StDev\"))\n",
        "\n",
        "print(\"-\"*29)\n",
        "print(\"Macro Scores\")\n",
        "print(\"-\"*29)\n",
        "\n",
        "print(f\"%15s %s (%s)\" %(\"Accuracy\",\n",
        "    round(statistics.mean(accuracy_list),3),\n",
        "    round(statistics.stdev(accuracy_list),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Macro F1\",\n",
        "    round(statistics.mean(macro_f1_score_list),3),\n",
        "    round(statistics.stdev(macro_f1_score_list),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Weighted F1\",\n",
        "    round(statistics.mean(weighted_f1_score_list),3),\n",
        "    round(statistics.stdev(weighted_f1_score_list),3)))\n",
        "\n",
        "print(\"-\"*29)\n",
        "print(\"Class Scores\")\n",
        "print(\"-\"*29)\n",
        "\n",
        "print(f\"%15s %s (%s)\" %(\"Positive\",\n",
        "    round(statistics.mean(positive_f1_score),3),\n",
        "    round(statistics.stdev(positive_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Neutral\",\n",
        "    round(statistics.mean(neutral_f1_score),3),\n",
        "    round(statistics.stdev(neutral_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Negative\",\n",
        "    round(statistics.mean(negative_f1_score),3),\n",
        "    round(statistics.stdev(negative_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Mixed\",\n",
        "    round(statistics.mean(mixed_f1_score),3),\n",
        "    round(statistics.stdev(mixed_f1_score),3)))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Mean (StDev)\n",
            "-----------------------------\n",
            "Macro Scores\n",
            "-----------------------------\n",
            "       Accuracy 0.659 (0.009)\n",
            "       Macro F1 0.545 (0.012)\n",
            "    Weighted F1 0.649 (0.01)\n",
            "-----------------------------\n",
            "Class Scores\n",
            "-----------------------------\n",
            "       Positive 0.804 (0.005)\n",
            "        Neutral  0.57 (0.018)\n",
            "       Negative 0.574 (0.02)\n",
            "          Mixed 0.231 (0.021)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcUm3TiIz8lo"
      },
      "source": [
        "# PARKING LOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IGPf6J6BvySx",
        "outputId": "35089f65-652c-48cf-98d2-3f7625e819e3"
      },
      "source": [
        "num_of_sentences = 0\n",
        "\n",
        "for l in mini_train_df['response_text']:       \n",
        "      l = l.strip()#.split(\"\\t\")[1]\n",
        "      sentence_tokens = tuple(l.split())\n",
        "      # if len(sentence_tokens) > 100:\n",
        "      #      continue\n",
        "#       # first check if any of my words is present. otherwise is not worth tagging it.\n",
        "      found = False\n",
        "      for token in sentence_tokens:\n",
        "        if token in my_words:\n",
        "          found = True\n",
        "          break\n",
        "      if found:\n",
        "        doc = nlp(l)\n",
        "        new_tokenization = []\n",
        "        for token in doc:\n",
        "            new_tokenization.append(token.text)\n",
        "        if \"double-decker\" in sentence_tokens:\n",
        "            pdb.set_trace()\n",
        "        for i, token in enumerate(doc):\n",
        "            if token.text in my_words and accepted_pos(token.pos_):\n",
        "                word_sentence_dict[token.text].add((tuple(new_tokenization), i)) # sentence and position \n",
        "                num_of_sentences +=1\n",
        "print(num_of_sentences)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYUFPuO1icXX"
      },
      "source": [
        "# check if a scale word exists in a response_text, if so capture position\n",
        "# text_column = mini_train_df['response_text']\n",
        "# label_column = mini_train_df['labels_4']\n",
        "position_list = []\n",
        "def na(text_column, label_column):\n",
        "  scale_word_position = collections.defaultdict(dict) #collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(dict)))\n",
        "  for data_name in datanames:\n",
        "    for scale_name, words in scales_dict[data_name].items():\n",
        "      #for word in words:          \n",
        "          \n",
        "          # -1 indicates the value is not present\n",
        "         # position = text_column.find(str(word))\n",
        "          # if position == -1:\n",
        "          #   #if the word doesn't exist add an empty list\n",
        "          #   scale_word_position[data_name]= [] #[str(scale_name)][word] \n",
        "          # else:\n",
        "          #   # add the text and the position\n",
        "          #instance = dict()\n",
        "          #   instance['sentence_words'] = text_column \n",
        "         # instance['position'] = int(position)\n",
        "            # instance['label'] = label_column\n",
        "            # add replacement greyscaled words\n",
        "            #instance['milder_words'] = scales_with_milder_option[data_name][word]\n",
        "\n",
        "        #  scale_word_position[data_name][word]= instance #instance[str(scale_name)][word] \n",
        "        return words\n",
        "#scale_word_position\n",
        "# add scale information           "
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVrMvw5nua48"
      },
      "source": [
        "dict_for_lm = dict()\n",
        "\n",
        "for dataname in rankings:\n",
        "  for scale in rankings[dataname]:\t\n",
        "      words_in_scale = []\n",
        "\n",
        "      for ws in rankings[dataname].get(scale):\n",
        "        # split and add words that are equally weighted in each scale\n",
        "        words_in_scale.extend(ws.split(\" || \"))\n",
        "      words_in_scale = tuple(words_in_scale)\n",
        "      dict_for_lm[words_in_scale] = dict()\n",
        "\n",
        "      for word in word_sentence_dict:\n",
        "          if word in words_in_scale:\n",
        "              dict_for_lm[words_in_scale][word] = []\n",
        "              for sentence, position in word_sentence_dict[word]:\n",
        "                  instance = dict()\n",
        "                  instance['sentence_words'] = sentence \n",
        "                  instance['position'] = int(position)\n",
        "                  instance['label'] = \n",
        "                  dict_for_lm[words_in_scale][word].append(instance)\n",
        "\n",
        "#save out\n",
        "pickle.dump(dict_for_lm, open(\"/content/drive/MyDrive/w266/unfiltered_rtgender_scalar_sentences_for_lm.pkl\",\"wb\"))\n"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xawAk8BjhQ2"
      },
      "source": [
        "### scalrel_extract_representations.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZzYb20PlpHH"
      },
      "source": [
        "filename = \"/content/drive/MyDrive/w266/unfiltered_rtgender_scalar_sentences_for_lm.pkl\"#\"/content/scalar_adjs/scal-rel/relational_sentences.pkl\"\n",
        "data = pickle.load(open(filename, \"rb\"))\n",
        "\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv6sD6kcUKs9"
      },
      "source": [
        "### adapted from extract_representations.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnmkZjm7qtHn"
      },
      "source": [
        "def check_correct_token_mapping(bert_tokenized_sentence, positions, word):\n",
        "    berttoken = ''\n",
        "    for p in positions:\n",
        "        berttoken += bert_tokenized_sentence[p].strip(\"##\")\n",
        "    if berttoken.lower() == word.lower():\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkmx2dKjrKUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "c3c2d238-40ef-4008-91ab-724506556f4c"
      },
      "source": [
        "for scale, values in data.items():\n",
        "    for i, item in values.items():\n",
        "      if len(item) != 0: \n",
        "        sentence_words = item[0].get(\"sentence_words\")\n",
        "\n",
        "        # extract and tokenize the original sentence\n",
        "        example = ' '.join(sentence_words)\n",
        "        bert_tokenized_sentence, mapp = special_tokenization(example, tokenizer, model_name)\n",
        "        bert_position = mapp[item[0].get(\"position\")]\n",
        "        if not check_correct_token_mapping(bert_tokenized_sentence, bert_position, i):\n",
        "                sys.out(\"Tokenization mismatch!\")\n",
        "        cinstance = dict()\n",
        "        cinstance['adj'] = i\n",
        "     #   cinstance['class'] = data[adj]['class']\n",
        "        cinstance['sentence_words'] = sentence_words\n",
        "        cinstance[\"bert_tokenized_sentence\"] = bert_tokenized_sentence\n",
        "        cinstance[\"bert_position\"] = bert_position\n",
        "        infos.append(cinstance)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-afcff727b93d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcinstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bert_tokenized_sentence\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_tokenized_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcinstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bert_position\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0minfos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcinstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'infos' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjrSr1Cb3p-4"
      },
      "source": [
        "## Replace with alternative scale word\n",
        "adapted from extract_representations.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ANURyYk_GFq"
      },
      "source": [
        "def extract_representations(infos, tokenizer, model_name):\n",
        "    reps = []\n",
        "    if model_name in [\"bert-base-uncased\", \"bert-base-cased\", \"bert-base-multilingual-uncased\", \"bert-base-multilingual-cased\"]:\n",
        "        config_class, model_class = BertConfig, BertModel        \n",
        "    elif \"flaubert\" in model_name:\n",
        "        config_class, model_class = FlaubertConfig, FlaubertModel\n",
        "    elif \"greek\" in model_name or \"spanish\" in model_name:\n",
        "        config_class, model_class = AutoConfig, AutoModel\n",
        "\n",
        "    config = config_class.from_pretrained(model_name, output_hidden_states=True)\n",
        "    model = model_class.from_pretrained(model_name, config=config)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for info in infos:\n",
        "            tok_sent = info['bert_tokenized_sentence']            \n",
        "            input_ids = torch.tensor([tokenizer.convert_tokens_to_ids(tok_sent)]).to(device)            \n",
        "            outputs = model(input_ids)            \n",
        "            if \"flaubert\" in model_name:\n",
        "                hidden_states = outputs[1]\n",
        "            else:\n",
        "                hidden_states = outputs[2]\n",
        "            if not exclude_last_bpe: #args.exclude_last_bpe:\n",
        "                bpositions = info[\"bert_position\"]\n",
        "            else:\n",
        "                if len(info[\"bert_position\"]) == 1:\n",
        "                    bpositions = info[\"bert_position\"]\n",
        "                if len(info[\"bert_position\"]) > 1:\n",
        "                    bpositions = info[\"bert_position\"][:-1]                    \n",
        "            \n",
        "            reps_for_this_instance = dict()                \n",
        "            for i, w in enumerate(info[\"bert_tokenized_sentence\"]):\n",
        "                if i in bpositions: \n",
        "                    for l in range(len(hidden_states)): # all layers\n",
        "                        if l not in reps_for_this_instance:\n",
        "                            reps_for_this_instance[l] = []\n",
        "                        reps_for_this_instance[l].append((w, hidden_states[l][0][i].cpu()))                        \n",
        "            reps.append(reps_for_this_instance)            \n",
        "\n",
        "    return reps, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY7Lvaz1U3D9"
      },
      "source": [
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "batch_size = 1 "
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cII7LwA_ln2"
      },
      "source": [
        "try:\n",
        "  sys.argv=['']\n",
        "  del sys\n",
        "except: pass\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "args = parser.parse_args()"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbhMZg-EGo-c"
      },
      "source": [
        "##Extract Representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "AbO1d-sxFZEU",
        "outputId": "3fcea59a-4439-4772-db2f-c52f64598c13"
      },
      "source": [
        "#\"whether we exclude the last bpe of words when words are split into multiple wordpieces\"\n",
        "exclude_last_bpe = True\n",
        "reps, model = extract_representations(infos, tokenizer, model_name)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-0fe67af40b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#\"whether we exclude the last bpe of words when words are split into multiple wordpieces\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexclude_last_bpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mreps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_representations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'extract_representations' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSUSqTLhLEXe"
      },
      "source": [
        "def aggregate_reps(reps_list, hidden_size):\n",
        "    '''This function averages representations of a word that has been split into wordpieces.'''\n",
        "    reps = torch.zeros([len(reps_list), hidden_size])\n",
        "    for i, wrep in enumerate(reps_list):\n",
        "        w, rep = wrep\n",
        "        reps[i] = rep\n",
        "\n",
        "    if len(reps) > 1:\n",
        "        reps = torch.mean(reps, axis=0)\n",
        "    reps = reps.view(hidden_size)\n",
        "\n",
        "    return reps.cpu()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTibuw5R3z18"
      },
      "source": [
        "# added Bert embeddings for each example (scaled and not) to data \n",
        "for rep, instance in zip(reps, infos):\n",
        "    scale = instance[\"scale\"]\n",
        "    lemma = instance[\"lemma\"]\n",
        "    for scale, values in data.items():\n",
        "      for i, ins2 in values.items():\n",
        "        if len(ins2) != 0: \n",
        "          if  ins2[0].get(\"sentence_words\") == instance[\"sentence_words\"]:\n",
        "              ins2[0][\"representations\"] = dict()\n",
        "              ins2[0][\"representations\"][lemma] = dict()\n",
        "              for l in rep:\n",
        "                ins2[0]['representations'][lemma][l] = aggregate_reps(rep[l], model.config.hidden_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHsY99WKQfqH"
      },
      "source": [
        "# save out\n",
        "args.data_dir = \"/content/drive/MyDrive/w266/\"\n",
        "\n",
        "if not exclude_last_bpe:\n",
        "    bpe_str = \"all-bpes\"\n",
        "else:\n",
        "    bpe_str = \"exclude-last-bpes\"\n",
        "\n",
        "language_str = \"en\"\n",
        "out_fn = args.data_dir + \"scalar_embeddings_\" + language_str + \"_\" + bpe_str + \".pkl\" \n",
        "pickle.dump(data, open(out_fn, \"wb\"))"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgNrcAY0UpMh"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMHdGAJoClPb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1319327f-489c-4937-e94e-24cd29998aa0"
      },
      "source": [
        "import pymagnitude\n",
        "from predict import load_rankings, assign_ranking_numbers, extract_gold_mildest_extreme"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymagnitude\n",
            "  Downloading pymagnitude-0.1.143.tar.gz (5.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4 MB 15.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pymagnitude\n",
            "  Building wheel for pymagnitude (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymagnitude: filename=pymagnitude-0.1.143-cp37-cp37m-linux_x86_64.whl size=360988340 sha256=f5e72968f54bd59c786582d261cc90d6ea0741c852306b61285279324759021c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/96/d6/b765a1ce34517c193d764b634b1ff7db5e1dcfea2520f17273\n",
            "Successfully built pymagnitude\n",
            "Installing collected packages: pymagnitude\n",
            "Successfully installed pymagnitude-0.1.143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7KwYo4WVoi-"
      },
      "source": [
        "#import scale rankings\n",
        "datanames = ['demelo', 'crowd', 'wilkinson']\n",
        "rankings, adjs_by_dataset = load_rankings(\"/content/scalar_adjs/data/\",\\\n",
        "                                          datanames=datanames)\n",
        "#import scalar embeddings \n",
        "data_dir = \"/content/drive/MyDrive/w266/\"\n",
        "scalar_dataset = pickle.load(open(data_dir + \"scalar_embeddings_\" + language_str + \"_exclude-last-bpes\" + \".pkl\", \"rb\"))"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "r5qMDFwNNCft",
        "outputId": "30e38481-80b6-4fb6-8fe6-b74830fe9515"
      },
      "source": [
        "scalar_dataset[('smart', 'intelligent')]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intelligent': [], 'smart': []}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvVEWi2qAUoE"
      },
      "source": [
        "#def calculate_diff_vector(data, scalar_dataset, dataname, X=10,  avoid_overlap=True):\n",
        "    #### dataset used to build diffvec - dataset for which we will make predictions\n",
        "dataname = 'crowd'\n",
        "avoid_overlap = 'True'\n",
        "\n",
        "\n",
        "relevant_dds = [dataname + \"-\" + d for d in datanames if d != dataname]\n",
        "\n",
        "diff_vectors_by_layer = dict()\n",
        "pairs_by_layer = dict()\n",
        "for dd in relevant_dds:\n",
        "    diff_vectors_by_layer[dd] = dict()\n",
        "    pairs_by_layer[dd] = dict()\n",
        "    for layer in range(1, 13):\n",
        "        diff_vectors_by_layer[dd][layer] = []\n",
        "        pairs_by_layer[dd][layer] = []\n",
        "\n",
        "missing = 0\n",
        "\n",
        "for scale in scalar_dataset:\n",
        "    ordered_words, mildest_words, extreme_words = extract_gold_mildest_extreme(data[scale])\n",
        "    if tuple(ordered_words) not in data:\n",
        "        missing += 1\n",
        "        continue\n",
        "    mildest_word = mildest_words[0]\n",
        "    print(data[scale])\n",
        "    print(mildest_word)\n",
        "    print(\"-\"*80)\n",
        "    # extreme_word = extreme_words[0]\n",
        "    # for dd in relevant_dds:\n",
        "    #         if avoid_overlap:\n",
        "    #             if mildest_word in adjs_by_dataset[dd.split(\"-\")[1]] or extreme_word in adjs_by_dataset[dd.split(\"-\")[1]]:\n",
        "    #                 continue\n",
        "    #         diff_vectors_one_scale = dict()\n",
        "    #         pairs_one_scale = dict()\n",
        "    #         for layer in range(1, 13):\n",
        "    #             diff_vectors_one_scale[layer] = []\n",
        "    #             pairs_one_scale[layer] = []\n",
        "    #         for key, instance in scalar_dataset[tuple(ordered_words)].items():\n",
        "    #           if len(instance) != 0:\n",
        "    #             #for layer in range(1,13):\n",
        "    #             print(ordered_words)\n",
        "    #             print(instance[0]) #[0]['representations'].keys()\n",
        "    #             print(\"-\"*80)\n",
        "                    # mild_rep = instance[0]['representations'][mildest_word][layer].numpy()\n",
        "                    # extreme_rep = instance[0]['representations'][extreme_word][layer].numpy()\n",
        "                    # diffvec_ex = extreme_rep - mild_rep\n",
        "                    # diff_vectors_one_scale[layer].append(diffvec_ex)\n",
        "                    # print(diff_vectors_one_scale)\n",
        "\n",
        "    #         for layer in range(1, 13):\n",
        "    #             av_ex = np.average(diff_vectors_one_scale[layer], axis=0)\n",
        "    #             diff_vectors_by_layer[dd][layer].append(av_ex)\n",
        "\n",
        "    # final_diff_vector_by_layer = dict()\n",
        "    # for dd in diff_vectors_by_layer:\n",
        "    #     final_diff_vector_by_layer[dd] = dict()\n",
        "    #     for layer in range(1,13):\n",
        "    #         av_ex = np.average(diff_vectors_by_layer[dd][layer], axis=0)\n",
        "    #         final_diff_vector_by_layer[dd][layer] = av_ex\n",
        "\n",
        "    # print('missing scales:', missing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Y77F0_hs-P"
      },
      "source": [
        "scalar_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zGjVhB4O5lI"
      },
      "source": [
        "for key, instance in scalar_dataset[tuple(ordered_words)].items():\n",
        "              if len(instance) != 0:\n",
        "                for layer in range(1,13):\n",
        "                    print(instance[0]['representations'].keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjqtH_K9Tfny"
      },
      "source": [
        "# add to train df\n",
        "train_df_aug = train_df\n",
        "train_df_aug['augmented_response_text'] = augmented_sentences_2\n",
        "train_df_aug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QhabasyTaAU"
      },
      "source": [
        "# Transform to HuggingFace friendly format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGcvxwWXIbfq"
      },
      "source": [
        "# change to dataset to work with Huggingface transformer & remove unused columns\n",
        "columns_to_remove = ['op_gender', 'source', 'Unnamed: 0', 'relevance', 'sentiment','post_text', 'label']\n",
        "\n",
        "from datasets import load_dataset\n",
        "train_dataset = Dataset.from_pandas(train_df_aug)\n",
        "dev_dataset = Dataset.from_pandas(dev_df)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(column_names= columns_to_remove)\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= columns_to_remove)\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= '__index_level_0__')\n",
        "\n",
        "# rename sentiment to labels\n",
        "train_dataset = train_dataset.rename_column(\"labels_4\", \"label\")\n",
        "dev_dataset = dev_dataset.rename_column(\"labels_4\", \"label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMF7YvFgcDSW",
        "outputId": "376d0ba3-3279-4eb6-c374-ebbee9dc6b02"
      },
      "source": [
        "# combine into a DataDictionary for huggingface use\n",
        "rtg_dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'dev': dev_dataset \n",
        "})\n",
        "\n",
        "rtg_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['response_text', 'label', 'augmented_response_text'],\n",
              "        num_rows: 10746\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['response_text', 'label'],\n",
              "        num_rows: 2301\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eKt004BKjyT",
        "outputId": "daf2cad0-ce9f-46c7-cac3-7783d7013478"
      },
      "source": [
        "output_model_file = '/content/drive/MyDrive/w266/pytorch_bert_rtgender_easy_data_aug.bin'\n",
        "output_vocab_file = './'\n",
        "\n",
        "model_to_save = model\n",
        "torch.save(model_to_save, output_model_file)\n",
        "tokenizer.save_vocabulary(output_vocab_file)\n",
        "\n",
        "print('All files saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All files saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6laXtqCRe5B3"
      },
      "source": [
        " # for dataname in datanames:\n",
        "  # for scale_name, scale_values in scales_dict[dataname].items():\n",
        "#scale_name = str(\"'big', 'substantial || major', 'tremendous || staggering'\")\n",
        "\n",
        "# create scales with ranks of words from extremes to middle ground\n",
        "\n",
        "def update_dict(dataname, word, mod_term_pos):\n",
        "  '''return dictionary with milder words'''\n",
        "  key_word = word.split(\" || \")  \n",
        "  value_word = scale_name[mod_term_pos].split(\" || \")\n",
        "  instance = dict(itertools.product(key_word,value_word))\n",
        "  for k,v in instance.items():\n",
        "    scales_with_milder_option[dataname][k] = v\n",
        "  return scales_with_milder_option\n",
        "### scale attributes\n",
        "# scale_size = len(scale_name) #number of ranks in scale\n",
        "# # does the scale have an even number of elements\n",
        "# even_scale = (scale_size %2 ==0)\n",
        "# # find the position of the middle term  \n",
        "# # adjust down 1 for indexing  \n",
        "# midpoint = scale_size // 2 -1\n",
        "# # exclude scales with fewer than 3 ranks  \n",
        "    # if scale_size <3:\n",
        "    #   continue\n",
        "\n",
        "    # else:\n",
        "    #   if even_scale:\n",
        "    #     if current_pos <= midpoint:\n",
        "    #       mod_term_pos = current_pos + 1 # find the position of the next term\n",
        "    #       # scales_with_milder_option = update_dict(dataname, word, mod_term_pos)\n",
        "    #       key_word = word.split(\" || \")  \n",
        "    #       value_word = scale_name[mod_term_pos].split(\" || \")\n",
        "    #       instance = dict(itertools.product(key_word,value_word))\n",
        "    #       print(instance)# for k,v in instance.items():\n",
        "    #       #   scales_with_milder_option[dataname][k] = v\n",
        "\n",
        "    #     elif current_pos >= midpoint:\n",
        "    #       mod_term_pos = current_pos - 1 # find the position of the next term\n",
        "    #       # scales_with_milder_option = update_dict(dataname, word, mod_term_pos)\n",
        "    #       key_word = word.split(\" || \")  \n",
        "    #       value_word = scale_name[mod_term_pos].split(\" || \")\n",
        "\n",
        "    #       instance = dict(itertools.product(key_word,value_word))\n",
        "    #       print(instance)# for k,v in instance.items():\n",
        "    #       #   scales_with_milder_option[dataname][k] = v\n",
        "\n",
        "    #   else:  \n",
        "    #     if current_pos < midpoint:\n",
        "    #       mod_term_pos = current_pos + 1 # find the position of the next term\n",
        "    #       # scales_with_milder_option = update_dict(dataname, word, mod_term_pos)\n",
        "    #       key_word = word.split(\" || \")  \n",
        "    #       value_word = scale_name[mod_term_pos].split(\" || \")\n",
        "    #       instance = dict(itertools.product(key_word,value_word))\n",
        "    #       print(instance)# for k,v in instance.items():\n",
        "    #       #   scales_with_milder_option[dataname][k] = v\n",
        "\n",
        "    #     elif current_pos > midpoint:\n",
        "    #       mod_term_pos = current_pos - 1 # find the position of the next term\n",
        "    #       # scales_with_milder_option = update_dict(dataname, word, mod_term_pos)\n",
        "    #       key_word = word.split(\" || \")  \n",
        "    #       value_word = scale_name[mod_term_pos].split(\" || \")\n",
        "    #       instance = dict(itertools.product(key_word,value_word))\n",
        "    #       print(instance)# for k,v in instance.items():\n",
        "    #       #   scales_with_milder_option[dataname][k] = v"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
