{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RtGender - Annotations - Sentiment - Greyscaling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "N7PAJ1oIJZfY",
        "vswkCWT-ewNj"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60445e3d0ba343f0a83727aac4091966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3e0a1224f4842daa3d5b85ff66473c9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_015078e611d9431d923b38e2f7b55b1d",
              "IPY_MODEL_55dc2eb0e3cf4be7bea32503a5f290c4",
              "IPY_MODEL_dd9a1028f4f347d4908d1cea809e4991"
            ]
          }
        },
        "c3e0a1224f4842daa3d5b85ff66473c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "015078e611d9431d923b38e2f7b55b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4ad8e53598248f186ce9a7a4b5aeb0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8929c8f47bd848fcbf3b374d8c648f77"
          }
        },
        "55dc2eb0e3cf4be7bea32503a5f290c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0aa7e57e8dbb403f9dd6dc49262c44e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7dce7a8b336423fb3a1239b37a95c8b"
          }
        },
        "dd9a1028f4f347d4908d1cea809e4991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5769809fcf3945a7be16ee7b269efc3e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:03&lt;00:00,  3.75s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b15cb415e374b2cb7a64ae15e02edb4"
          }
        },
        "e4ad8e53598248f186ce9a7a4b5aeb0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8929c8f47bd848fcbf3b374d8c648f77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0aa7e57e8dbb403f9dd6dc49262c44e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7dce7a8b336423fb3a1239b37a95c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5769809fcf3945a7be16ee7b269efc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b15cb415e374b2cb7a64ae15e02edb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b90b074efb54b9a90ae32ba635f9283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d84ca505899a466187ed5e625c9d3170",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9e7875e646b4ac4a7c8a9b611fd4a6f",
              "IPY_MODEL_053e3df2e88b45b396641c850df38432",
              "IPY_MODEL_9f1ce0487c204794a68a936ba8bac10d"
            ]
          }
        },
        "d84ca505899a466187ed5e625c9d3170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9e7875e646b4ac4a7c8a9b611fd4a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb902fc32a0c402e81bec09e0cd20fee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6172d85a99148d89e1b79424409de91"
          }
        },
        "053e3df2e88b45b396641c850df38432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9c247ddc5f8464e92abdf41dbff68f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93d8523730ed404d8c7e65e61aff68c8"
          }
        },
        "9f1ce0487c204794a68a936ba8bac10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_997b43b8ad7a4cefa2dbd32568949a70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  2.29ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a65b7a35b9c44828a2c4effd493efcf"
          }
        },
        "cb902fc32a0c402e81bec09e0cd20fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6172d85a99148d89e1b79424409de91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9c247ddc5f8464e92abdf41dbff68f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93d8523730ed404d8c7e65e61aff68c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "997b43b8ad7a4cefa2dbd32568949a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a65b7a35b9c44828a2c4effd493efcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipietri/w266_Final_Project/blob/master/notebooks/RtGender-Notebooks/Greyscaling/RtGender_Annotations_Sentiment_Greyscaling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OhO4xlwqExT"
      },
      "source": [
        "RtGender - Annotations - Sentiment w/ Greyscaling\n",
        "[Code Source](https://github.com/ainagari/scalar_adjs)\n",
        "---\n",
        "*[BERT Knows Punta Cana is not just beautiful, it’s gorgeous:\n",
        "Ranking Scalar Adjectives with Contextualised Representations](https://aclanthology.org/2020.emnlp-main.598.pdf)\\\n",
        "*[Scalar Adjective Identification and Multilingual Ranking\n",
        "](https://arxiv.org/abs/2105.01180)\\\n",
        "*[Identifying and Ordering Scalar Adjectives Using Lexical Substitution](https://www.proquest.com/openview/aade435a5bbdcf41e2b8c24e648826cc/1.pdf?pq-origsite=gscholar&cbl=18750)\\\n",
        "*[A Gold Standard for Scalar Adjectives](https://aclanthology.org/L16-1424/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cirVs78YksXS",
        "outputId": "d6dd55dd-da57-4365-b858-320f4bd8e67e"
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  path = r'/content/drive/MyDrive/w266'\n",
        "except ModuleNotFoundError:\n",
        "  path = r'data'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7PAJ1oIJZfY"
      },
      "source": [
        "<a id='section01'></a>\n",
        "## Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p--X9MlxQP05",
        "outputId": "5d212284-f96f-4d87-ff22-0a2d427fbb7c"
      },
      "source": [
        "#!pip install -U nltk\n",
        "import nltk; nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-GlywkSFegL"
      },
      "source": [
        "%%capture\n",
        "#!pip install transformers==3.0.2\n",
        "!pip install -q transformers\n",
        "#!pip install pymagnitude"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IV4cb3abmJP"
      },
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "import datasets \n",
        "from datasets import load_dataset, Dataset, DatasetDict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "979OUro5Eac3"
      },
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "#from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb1Q5N6LGK7z"
      },
      "source": [
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-eMCGrpkQ1E"
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "import sys\n",
        "from scipy.spatial.distance import cosine\n",
        "from operator import itemgetter\n",
        "from collections import defaultdict\n",
        "#from pymagnitude import *\n",
        "import argparse\n",
        "\n",
        "import itertools"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcTXavwcTzGT",
        "outputId": "4c18f4d8-2cf8-4b01-d9b3-f2a8e2f54327"
      },
      "source": [
        "# import eda script from github\n",
        "!git clone https://github.com/ainagari/scalar_adjs"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'scalar_adjs'...\n",
            "remote: Enumerating objects: 854, done.\u001b[K\n",
            "remote: Counting objects: 100% (438/438), done.\u001b[K\n",
            "remote: Compressing objects: 100% (189/189), done.\u001b[K\n",
            "remote: Total 854 (delta 91), reused 358 (delta 45), pack-reused 416\u001b[K\n",
            "Receiving objects: 100% (854/854), 13.47 MiB | 3.51 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HucjuuC6RGk"
      },
      "source": [
        "# import fucntions from scalar_adjs\n",
        "import sys\n",
        "\n",
        "# sys.path is a list of absolute path strings\n",
        "sys.path.append('/content/scalar_adjs/')\n",
        "\n",
        "from read_scalar_datasets import read_scales\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hErgyoZRHSA3"
      },
      "source": [
        "<a id='section02'></a>\n",
        "# Import and Reshape Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3FzcAlgEac8",
        "outputId": "1e7ca891-bfbd-4ea6-e4da-5bd5c3f66620"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/w266/train_oversampled.csv')\n",
        "dev_df = pd.read_csv('/content/drive/MyDrive/w266/annotations_dev.csv')\n",
        "\n",
        "print('train_shape: ',train_df.shape)\n",
        "print('dev_shape: ',dev_df.shape)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_shape:  (21184, 9)\n",
            "dev_shape:  (2303, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntnIM3pjdQ2C",
        "outputId": "3859df95-fe34-4906-c5e4-2a0a7589e89d"
      },
      "source": [
        "# there are NaNs in the dev dataset remove \n",
        "nan_values = dev_df[dev_df.isna().any(axis=1)] \n",
        "print(nan_values)\n",
        "\n",
        "# return without missing values in response_text\n",
        "dev_df.dropna(subset = [\"response_text\"], inplace=True)\n",
        "\n",
        "print(\"Train shape\", train_df.shape)\n",
        "print(\"Dev shape\", dev_df.shape)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0         source op_gender  ...   relevance label labels_4\n",
            "830         2576  facebook_wiki         M  ...  Irrelevant     1        1\n",
            "1664        2722  facebook_wiki         W  ...  Irrelevant     1        1\n",
            "\n",
            "[2 rows x 9 columns]\n",
            "Train shape (21184, 9)\n",
            "Dev shape (2301, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9BHmHVnbaJm",
        "outputId": "fa91478c-8cac-487f-91af-908f8fb05a6b"
      },
      "source": [
        "print(\"Unique sentiments: \", train_df['sentiment'].unique())"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique sentiments:  ['Positive' 'Mixed' 'Neutral' 'Negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2glKqfDNL4Fj",
        "outputId": "3931ec95-5e9e-40e6-a211-a3d4b4692564"
      },
      "source": [
        "# keep only a few columns\n",
        "train_df = train_df[['response_text', 'labels_4']]\n",
        "dev_df = dev_df[['response_text', 'labels_4']]\n",
        "# rename columns\n",
        "train_df.rename(columns = {'response_text':'text', 'labels_4': 'label'}, inplace = True)\n",
        "dev_df.rename(columns = {'response_text':'text', 'labels_4': 'label'}, inplace = True)\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vki-cYpURWf4"
      },
      "source": [
        "# Augment\n",
        "Adapted from Scalar Adj Code\n",
        "[Extract Relevant Text](https://github.com/ainagari/scalar_adjs/blob/master/extract_flickr_scalar.py)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzYGg8Nfukpr"
      },
      "source": [
        "import pickle\n",
        "import pdb\n",
        "import spacy\n",
        "import os\n",
        "import collections\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "language_str = \"en\" #set to english -- one dataset in English only"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vswkCWT-ewNj"
      },
      "source": [
        "### Word Position\n",
        "Identify the location of all scalewords in each example. Extract and save out as a dictionary for every example that contains at least one scaled word. Adapted from extract_flickr_scalar.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y5gFIVbveKy"
      },
      "source": [
        "rankings = dict()\n",
        "datanames = [\"demelo\", \"crowd\", \"wilkinson\"]\n",
        "\n",
        "import dill\n",
        "filename = \"/content/drive/MyDrive/w266/scales_with_milder_option.pickle\"\n",
        "scales_with_milder_option = dill.load(open(filename, \"rb\"))\n",
        "\n"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNhCN_lPM9xu"
      },
      "source": [
        "rankings = dict()\n",
        "datanames = [\"demelo\", \"crowd\", \"wilkinson\"]\n",
        "for dataname in datanames:\n",
        "    r = read_scales(\"/content/scalar_adjs/data/\" + dataname + \"/gold_rankings/\")\n",
        "    rankings[dataname] = r\n",
        "\n",
        "my_words = set()\n",
        "for dataname in rankings:\n",
        "    for scale in rankings[dataname]:\n",
        "        for word in rankings[dataname][scale]:\n",
        "            words = word.split(\" || \")\n",
        "            for w in words:\n",
        "                my_words.add(w)\n",
        "\n",
        "word_sentence_dict = dict()\n",
        "for word in my_words:\n",
        "    word_sentence_dict[word] = set()\n",
        "\n",
        "def accepted_pos(pos):\n",
        "    if pos in [\"ADJ\",\"ADV\", \"ADP\",\"VERB\",\"DET\"]:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V86620dUMaDb"
      },
      "source": [
        "## Return synthetic examples\n",
        "\n",
        "Since there are ties in our scales the milder word may be one or more words. So if the original word is foo || bar and the milder word is foolish || barish this {foo: foolish, foo: barish, bar: foolish, bar: barish}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbY9kY2xNA45"
      },
      "source": [
        "# create a nested dictionary with every scale, scale list with equalities, and all words in the scale\n",
        "\n",
        "import collections\n",
        "scales_dict = collections.defaultdict(dict)\n",
        "\n",
        "for dataname in datanames:\n",
        "  for scale_file_name, scale in rankings[dataname].items():\n",
        "    words_in_scale = []\n",
        "    for ws in scale:\n",
        "      # split if there are ties\n",
        "      words_in_scale.extend(ws.split(\" || \"))\n",
        "    scales_dict[dataname][str(scale)] = tuple(words_in_scale)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrvFMgq3MZzr"
      },
      "source": [
        "def locate_scale_word(test_col, label_col):\n",
        "  '''\n",
        "  return a column with any scale_words \n",
        "  in the text column and their position\n",
        "  '''\n",
        "  more_test = collections.defaultdict(lambda: collections.defaultdict(dict))\n",
        "  for data_name in datanames:\n",
        "      for scale_name, words in scales_dict[data_name].items():\n",
        "        for word in words:\n",
        "          # convert text into a list of words to avoid partial matches found using .find()\n",
        "          \n",
        "          sentence_words = test_col.replace(\"'\", \"\") \n",
        "          sentence_words = sentence_words.lower().split(\" \")\n",
        "          \n",
        "          if word in sentence_words:\n",
        "            pos = sentence_words.index(word)\n",
        "            # assume only one word to be replaced at a time\n",
        "            more_test[data_name][word]['position'] = int(pos)\n",
        "            more_test[data_name][word]['milder_words'] = scales_with_milder_option[data_name][word]\n",
        "            \n",
        "\n",
        "  return more_test"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrpzm3_iXjq0"
      },
      "source": [
        "# convert relevant df columns to dictionary\n",
        "train_df['new_col'] = train_df.apply(lambda x: locate_scale_word(x['text'], x['label']), axis = 1)\n",
        "dict_from_df = train_df.to_dict('index')"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6A-jtFgzV0Q"
      },
      "source": [
        "### Run augmentation script \n",
        "reference grey_scale_augmentation.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2nrAP8_NNth",
        "outputId": "eed7353f-9255-43df-f561-71c1174f012f"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/w266\"\n",
        "%run grey_scale_augmentation.ipynb\n",
        "labels_list, augmented_text_list, id_list = augment_greyscaling(dict_from_df, datanames, 'text', 'label')\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/w266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbB6Dr3uNRrH",
        "outputId": "17ffc848-5b05-43ed-8402-557d7344b9af"
      },
      "source": [
        "# append the augmented data plus labels\n",
        "\n",
        "new_df = pd.DataFrame({'id':id_list, 'text':augmented_text_list, \n",
        "              'label':labels_list})\n",
        "print(\"Number of augmented examples: \", len(new_df))\n",
        "\n",
        "# add an example id column\n",
        "train_df['id'] = train_df.index\n",
        "\n",
        "# add labels indicating original vs augmented examples\n",
        "train_df['is_og'] = 1\n",
        "new_df['is_og'] = 0\n",
        "\n",
        "# append to the original examples and create new augmented dataframe\n",
        "train_df_aug = new_df.append(train_df)\n",
        "\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of augmented examples:  20989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5krXcuKUWcS",
        "outputId": "1ff1bcd6-fa94-4831-ea0c-f98a30429a55"
      },
      "source": [
        "# save out greyscale adjusted dataset\n",
        "train_df_aug.to_csv('/content/drive/MyDrive/w266/grey_scaled_augmented_oversampled_rtgender_train_data.csv', index=False)\n",
        "print(\"Total number of examples: \", len(train_df_aug))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of examples:  42173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVOoY6h1NwVV"
      },
      "source": [
        "# Convert to Hugging Face friendly format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phGv973SUOmr"
      },
      "source": [
        "from transformers import BertTokenizer, BertConfig, BertModel, AutoTokenizer, AutoModel, FlaubertTokenizer, FlaubertModel, AutoConfig, FlaubertConfig\n",
        "\n",
        "language_str = \"en\"\n",
        "#whether we exclude the last bpe of words when words are split into multiple wordpieces\n",
        "exclude_last_bpe =\"True\"\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
        "#sentences = train_df['response_text']"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrUpD9HgjQ1f"
      },
      "source": [
        "## Transform into Hugging Friendly Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3hDU30n4hwBB",
        "outputId": "99888ef4-8e06-46ce-9d69-d0e1e5c2ac5a"
      },
      "source": [
        "train_df_aug"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>is_og</th>\n",
              "      <th>new_col</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Thank you Congresswoman Bass. Keep up the good...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>I'm looking forward to seeing some *Good News*...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>I'm looking forward to seeing some *Good News*...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>I'm looking forward to seeing some *Good News*...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>I'm looking forward to seeing some *Good News*...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21179</th>\n",
              "      <td>21179</td>\n",
              "      <td>\"Committed to making sure we don't lose our he...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>{'demelo': {}, 'crowd': {}, 'wilkinson': {}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21180</th>\n",
              "      <td>21180</td>\n",
              "      <td>Both Isakson and Chambliss voted to TABLE Rand...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>{'demelo': {}, 'crowd': {}, 'wilkinson': {}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21181</th>\n",
              "      <td>21181</td>\n",
              "      <td>I think a magic beam of pure light would disin...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>{'wilkinson': {'light': {'position': 7, 'milde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21182</th>\n",
              "      <td>21182</td>\n",
              "      <td>I'd rather have a root canal . . .</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>{'demelo': {}, 'crowd': {}, 'wilkinson': {}}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21183</th>\n",
              "      <td>21183</td>\n",
              "      <td>You get elected to lead....then you get on TV ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>{'demelo': {}, 'crowd': {}, 'wilkinson': {}}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42173 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                            new_col\n",
              "0          0  ...                                                NaN\n",
              "1          5  ...                                                NaN\n",
              "2          5  ...                                                NaN\n",
              "3          5  ...                                                NaN\n",
              "4          5  ...                                                NaN\n",
              "...      ...  ...                                                ...\n",
              "21179  21179  ...       {'demelo': {}, 'crowd': {}, 'wilkinson': {}}\n",
              "21180  21180  ...       {'demelo': {}, 'crowd': {}, 'wilkinson': {}}\n",
              "21181  21181  ...  {'wilkinson': {'light': {'position': 7, 'milde...\n",
              "21182  21182  ...       {'demelo': {}, 'crowd': {}, 'wilkinson': {}}\n",
              "21183  21183  ...       {'demelo': {}, 'crowd': {}, 'wilkinson': {}}\n",
              "\n",
              "[42173 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCBZbwZG1P8s"
      },
      "source": [
        "# change to dataset to work with Huggingface transformer & remove unused columns\n",
        "columns_to_remove = ['id', 'is_og', 'new_col','__index_level_0__']\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df_aug)\n",
        "dev_dataset = Dataset.from_pandas(dev_df)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(column_names= columns_to_remove)\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= '__index_level_0__')\n"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wWAUlGE23Os",
        "outputId": "10a8039e-c688-4894-cd59-748d4b364f7d"
      },
      "source": [
        "# combine into a DataDictionary for huggingface use\n",
        "rtg_dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'dev': dev_dataset \n",
        "})\n",
        "\n",
        "rtg_dataset"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 42173\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2301\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PE9TY9o3Sg6"
      },
      "source": [
        "# Tokenize "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2X4Zwzr3SKw"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "max_length = train_df['text'].astype(str).map(len).quantile(0.99).astype(int)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, max_length = int(max_length))\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "60445e3d0ba343f0a83727aac4091966",
            "c3e0a1224f4842daa3d5b85ff66473c9",
            "015078e611d9431d923b38e2f7b55b1d",
            "55dc2eb0e3cf4be7bea32503a5f290c4",
            "dd9a1028f4f347d4908d1cea809e4991",
            "e4ad8e53598248f186ce9a7a4b5aeb0a",
            "8929c8f47bd848fcbf3b374d8c648f77",
            "0aa7e57e8dbb403f9dd6dc49262c44e8",
            "b7dce7a8b336423fb3a1239b37a95c8b",
            "5769809fcf3945a7be16ee7b269efc3e",
            "0b15cb415e374b2cb7a64ae15e02edb4",
            "8b90b074efb54b9a90ae32ba635f9283",
            "d84ca505899a466187ed5e625c9d3170",
            "e9e7875e646b4ac4a7c8a9b611fd4a6f",
            "053e3df2e88b45b396641c850df38432",
            "9f1ce0487c204794a68a936ba8bac10d",
            "cb902fc32a0c402e81bec09e0cd20fee",
            "e6172d85a99148d89e1b79424409de91",
            "e9c247ddc5f8464e92abdf41dbff68f0",
            "93d8523730ed404d8c7e65e61aff68c8",
            "997b43b8ad7a4cefa2dbd32568949a70",
            "3a65b7a35b9c44828a2c4effd493efcf"
          ]
        },
        "id": "T8u9yQdZ3RjN",
        "outputId": "4208f9a5-df11-41b6-d699-41a609702301"
      },
      "source": [
        "rtg_encoded = rtg_dataset.map(tokenize, batched=True, batch_size=None)\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60445e3d0ba343f0a83727aac4091966",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b90b074efb54b9a90ae32ba635f9283",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'label': Value(dtype='int64', id=None),\n",
              " 'text': Value(dtype='string', id=None),\n",
              " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeGuzSZK4EI0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlt8MZae3PbD",
        "outputId": "3ed278c2-cede-4077-95b0-2e104813f5f0"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "num_labels = 4\n",
        "epochs = 2\n",
        "iterations = 5\n",
        "model = (AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-lbumOp4GfJ"
      },
      "source": [
        "rtg_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBfk25D94H7Z"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
        "    f1_macro = f1_score(labels, preds, average = 'macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1_weighted, \"f1_macro\": f1_macro} "
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pnJ9_Vt4Jia"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 8\n",
        "logging_steps = len(rtg_encoded[\"train\"]) // batch_size\n",
        "training_args = TrainingArguments(output_dir=\"results\",\n",
        "                                  num_train_epochs=epochs,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  load_best_model_at_end=True,\n",
        "                                 # metric_for_best_model=\"f1_macro\",\n",
        "                                 # weight_decay=0.01,\n",
        "                                  evaluation_strategy=\"steps\",\n",
        "                                  save_strategy=\"steps\",\n",
        "                                  disable_tqdm=False\n",
        "                                  )"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JdM1WXA04Lz-",
        "outputId": "6c1e8962-9040-4e9d-c333-e20cf795c64d"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "accuracy_list = []\n",
        "weighted_f1_score_list = []\n",
        "macro_f1_score_list = []\n",
        "negative_f1_score = []\n",
        "neutral_f1_score = []\n",
        "mixed_f1_score = []\n",
        "positive_f1_score = []\n",
        "\n",
        "\n",
        "for i in range(iterations):\n",
        "  try:\n",
        "    del trainer\n",
        "    del results\n",
        "    del cr\n",
        "  except: pass\n",
        "\n",
        "\n",
        "  trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=rtg_encoded[\"train\"],\n",
        "                  eval_dataset=rtg_encoded[\"dev\"])\n",
        "  trainer.train()\n",
        "  results = trainer.evaluate()\n",
        "\n",
        "  # append macro metrics to lists\n",
        "  accuracy_list.append(results.get('eval_accuracy'))\n",
        "  weighted_f1_score_list.append(results.get(\"eval_f1\"))\n",
        "  macro_f1_score_list.append(results.get(\"eval_f1_macro\"))\n",
        "\n",
        "  trainer.predict(rtg_encoded[\"dev\"])\n",
        "  # append the class-level F1 scores\n",
        "  outputs = trainer.predict(rtg_encoded[\"dev\"])\n",
        "  predictions = outputs.predictions.argmax(1)\n",
        "  labels = rtg_encoded[\"dev\"]['label']\n",
        "  cr = classification_report(labels, predictions, digits=3, output_dict=True)\n",
        "  negative_f1_score.append(cr.get('0').get(\"f1-score\"))\n",
        "  neutral_f1_score.append(cr.get('1').get(\"f1-score\"))\n",
        "  positive_f1_score.append(cr.get('2').get(\"f1-score\"))\n",
        "  mixed_f1_score.append(cr.get('3').get(\"f1-score\"))\n",
        "\n",
        "\n",
        "  print(f'---------------------------Iteration {i+1} Complete---------------------------\\n')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running training *****\n",
            "  Num examples = 42173\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10544\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10544' max='10544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10544/10544 21:08, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.063600</td>\n",
              "      <td>0.970260</td>\n",
              "      <td>0.623207</td>\n",
              "      <td>0.645063</td>\n",
              "      <td>0.557193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.793900</td>\n",
              "      <td>1.002658</td>\n",
              "      <td>0.627119</td>\n",
              "      <td>0.635867</td>\n",
              "      <td>0.534096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.640800</td>\n",
              "      <td>0.999097</td>\n",
              "      <td>0.632768</td>\n",
              "      <td>0.648704</td>\n",
              "      <td>0.553282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.536300</td>\n",
              "      <td>1.117371</td>\n",
              "      <td>0.624946</td>\n",
              "      <td>0.641822</td>\n",
              "      <td>0.549745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.453100</td>\n",
              "      <td>1.236581</td>\n",
              "      <td>0.636245</td>\n",
              "      <td>0.652777</td>\n",
              "      <td>0.551670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.443300</td>\n",
              "      <td>1.271717</td>\n",
              "      <td>0.655367</td>\n",
              "      <td>0.665582</td>\n",
              "      <td>0.568861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.395800</td>\n",
              "      <td>1.340580</td>\n",
              "      <td>0.657540</td>\n",
              "      <td>0.668933</td>\n",
              "      <td>0.571137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.356600</td>\n",
              "      <td>1.329309</td>\n",
              "      <td>0.659279</td>\n",
              "      <td>0.657459</td>\n",
              "      <td>0.549900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.322100</td>\n",
              "      <td>1.500182</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.668921</td>\n",
              "      <td>0.571722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.317400</td>\n",
              "      <td>1.533113</td>\n",
              "      <td>0.665797</td>\n",
              "      <td>0.656871</td>\n",
              "      <td>0.546056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.252300</td>\n",
              "      <td>1.580458</td>\n",
              "      <td>0.681443</td>\n",
              "      <td>0.677376</td>\n",
              "      <td>0.573635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.191900</td>\n",
              "      <td>1.721302</td>\n",
              "      <td>0.654933</td>\n",
              "      <td>0.664325</td>\n",
              "      <td>0.566491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.156700</td>\n",
              "      <td>1.769320</td>\n",
              "      <td>0.669709</td>\n",
              "      <td>0.665061</td>\n",
              "      <td>0.561094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>1.816454</td>\n",
              "      <td>0.673620</td>\n",
              "      <td>0.660849</td>\n",
              "      <td>0.550932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.154800</td>\n",
              "      <td>1.920286</td>\n",
              "      <td>0.660582</td>\n",
              "      <td>0.656424</td>\n",
              "      <td>0.553299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.159600</td>\n",
              "      <td>1.922621</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.662979</td>\n",
              "      <td>0.559324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.146900</td>\n",
              "      <td>1.868361</td>\n",
              "      <td>0.674055</td>\n",
              "      <td>0.669497</td>\n",
              "      <td>0.568162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>1.887033</td>\n",
              "      <td>0.671447</td>\n",
              "      <td>0.667331</td>\n",
              "      <td>0.568285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.123600</td>\n",
              "      <td>1.923742</td>\n",
              "      <td>0.673186</td>\n",
              "      <td>0.669800</td>\n",
              "      <td>0.567680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.137600</td>\n",
              "      <td>1.913139</td>\n",
              "      <td>0.678401</td>\n",
              "      <td>0.671167</td>\n",
              "      <td>0.567497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.115800</td>\n",
              "      <td>1.929627</td>\n",
              "      <td>0.677097</td>\n",
              "      <td>0.670662</td>\n",
              "      <td>0.566859</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10500\n",
            "Configuration saved in results/checkpoint-10500/config.json\n",
            "Model weights saved in results/checkpoint-10500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-500 (score: 0.9702604413032532).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running training *****\n",
            "  Num examples = 42173\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 1 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10544' max='10544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10544/10544 25:08, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.473600</td>\n",
              "      <td>1.332232</td>\n",
              "      <td>0.624946</td>\n",
              "      <td>0.640750</td>\n",
              "      <td>0.546347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>1.030627</td>\n",
              "      <td>0.631899</td>\n",
              "      <td>0.643727</td>\n",
              "      <td>0.542383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.570100</td>\n",
              "      <td>1.077134</td>\n",
              "      <td>0.622338</td>\n",
              "      <td>0.636439</td>\n",
              "      <td>0.536556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.469100</td>\n",
              "      <td>1.159600</td>\n",
              "      <td>0.643633</td>\n",
              "      <td>0.652419</td>\n",
              "      <td>0.551662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.413100</td>\n",
              "      <td>1.334085</td>\n",
              "      <td>0.636680</td>\n",
              "      <td>0.651740</td>\n",
              "      <td>0.551021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.416300</td>\n",
              "      <td>1.310199</td>\n",
              "      <td>0.645372</td>\n",
              "      <td>0.653063</td>\n",
              "      <td>0.549897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.363200</td>\n",
              "      <td>1.386161</td>\n",
              "      <td>0.659279</td>\n",
              "      <td>0.662302</td>\n",
              "      <td>0.558268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.341900</td>\n",
              "      <td>1.450207</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.663143</td>\n",
              "      <td>0.558807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.303900</td>\n",
              "      <td>1.566233</td>\n",
              "      <td>0.657540</td>\n",
              "      <td>0.659696</td>\n",
              "      <td>0.553773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.286500</td>\n",
              "      <td>1.591459</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.659447</td>\n",
              "      <td>0.550961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.236200</td>\n",
              "      <td>1.667605</td>\n",
              "      <td>0.659713</td>\n",
              "      <td>0.660765</td>\n",
              "      <td>0.556374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.161600</td>\n",
              "      <td>1.857968</td>\n",
              "      <td>0.649718</td>\n",
              "      <td>0.654784</td>\n",
              "      <td>0.555064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.131800</td>\n",
              "      <td>1.915334</td>\n",
              "      <td>0.664928</td>\n",
              "      <td>0.660824</td>\n",
              "      <td>0.554162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.135500</td>\n",
              "      <td>1.948317</td>\n",
              "      <td>0.663190</td>\n",
              "      <td>0.662220</td>\n",
              "      <td>0.557177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.126600</td>\n",
              "      <td>1.937663</td>\n",
              "      <td>0.671013</td>\n",
              "      <td>0.663771</td>\n",
              "      <td>0.556272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.138300</td>\n",
              "      <td>2.023566</td>\n",
              "      <td>0.662321</td>\n",
              "      <td>0.662889</td>\n",
              "      <td>0.560687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.130800</td>\n",
              "      <td>1.944276</td>\n",
              "      <td>0.671013</td>\n",
              "      <td>0.665634</td>\n",
              "      <td>0.560354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.121600</td>\n",
              "      <td>1.982728</td>\n",
              "      <td>0.664928</td>\n",
              "      <td>0.658992</td>\n",
              "      <td>0.554555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.113400</td>\n",
              "      <td>2.000763</td>\n",
              "      <td>0.664059</td>\n",
              "      <td>0.661546</td>\n",
              "      <td>0.558785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.129600</td>\n",
              "      <td>2.003531</td>\n",
              "      <td>0.667970</td>\n",
              "      <td>0.661641</td>\n",
              "      <td>0.557267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.107900</td>\n",
              "      <td>1.996269</td>\n",
              "      <td>0.670578</td>\n",
              "      <td>0.664007</td>\n",
              "      <td>0.558823</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10500\n",
            "Configuration saved in results/checkpoint-10500/config.json\n",
            "Model weights saved in results/checkpoint-10500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-1000 (score: 1.0306274890899658).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running training *****\n",
            "  Num examples = 42173\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 2 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10544' max='10544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10544/10544 24:33, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.141100</td>\n",
              "      <td>2.288732</td>\n",
              "      <td>0.595828</td>\n",
              "      <td>0.621926</td>\n",
              "      <td>0.518669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.239500</td>\n",
              "      <td>1.788576</td>\n",
              "      <td>0.627988</td>\n",
              "      <td>0.632212</td>\n",
              "      <td>0.520936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.572800</td>\n",
              "      <td>1.173756</td>\n",
              "      <td>0.619731</td>\n",
              "      <td>0.633993</td>\n",
              "      <td>0.535929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.452700</td>\n",
              "      <td>1.335976</td>\n",
              "      <td>0.629726</td>\n",
              "      <td>0.641360</td>\n",
              "      <td>0.543676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.393800</td>\n",
              "      <td>1.375853</td>\n",
              "      <td>0.628422</td>\n",
              "      <td>0.643640</td>\n",
              "      <td>0.546380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.388500</td>\n",
              "      <td>1.396222</td>\n",
              "      <td>0.644937</td>\n",
              "      <td>0.652818</td>\n",
              "      <td>0.552099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.342100</td>\n",
              "      <td>1.560298</td>\n",
              "      <td>0.647979</td>\n",
              "      <td>0.653575</td>\n",
              "      <td>0.551056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.326500</td>\n",
              "      <td>1.492197</td>\n",
              "      <td>0.662755</td>\n",
              "      <td>0.662521</td>\n",
              "      <td>0.559017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.289900</td>\n",
              "      <td>1.650985</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.651655</td>\n",
              "      <td>0.537396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.254500</td>\n",
              "      <td>1.764250</td>\n",
              "      <td>0.670578</td>\n",
              "      <td>0.660733</td>\n",
              "      <td>0.553556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.229900</td>\n",
              "      <td>1.792044</td>\n",
              "      <td>0.664494</td>\n",
              "      <td>0.661704</td>\n",
              "      <td>0.558738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.143900</td>\n",
              "      <td>1.923850</td>\n",
              "      <td>0.653194</td>\n",
              "      <td>0.657117</td>\n",
              "      <td>0.555243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.120300</td>\n",
              "      <td>1.967456</td>\n",
              "      <td>0.665797</td>\n",
              "      <td>0.655905</td>\n",
              "      <td>0.541285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.113200</td>\n",
              "      <td>1.995789</td>\n",
              "      <td>0.663190</td>\n",
              "      <td>0.651649</td>\n",
              "      <td>0.534461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.108000</td>\n",
              "      <td>2.131140</td>\n",
              "      <td>0.664494</td>\n",
              "      <td>0.658001</td>\n",
              "      <td>0.548845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>2.022703</td>\n",
              "      <td>0.667970</td>\n",
              "      <td>0.661154</td>\n",
              "      <td>0.552847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.117400</td>\n",
              "      <td>2.024478</td>\n",
              "      <td>0.667101</td>\n",
              "      <td>0.657303</td>\n",
              "      <td>0.541744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.115300</td>\n",
              "      <td>2.057531</td>\n",
              "      <td>0.671882</td>\n",
              "      <td>0.659882</td>\n",
              "      <td>0.548271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.103700</td>\n",
              "      <td>2.074097</td>\n",
              "      <td>0.667536</td>\n",
              "      <td>0.661432</td>\n",
              "      <td>0.550855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.115400</td>\n",
              "      <td>2.033401</td>\n",
              "      <td>0.669709</td>\n",
              "      <td>0.656256</td>\n",
              "      <td>0.541285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.098500</td>\n",
              "      <td>2.046608</td>\n",
              "      <td>0.668840</td>\n",
              "      <td>0.656909</td>\n",
              "      <td>0.543829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10500\n",
            "Configuration saved in results/checkpoint-10500/config.json\n",
            "Model weights saved in results/checkpoint-10500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-1500 (score: 1.1737563610076904).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running training *****\n",
            "  Num examples = 42173\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 3 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10544' max='10544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10544/10544 24:57, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>2.595079</td>\n",
              "      <td>0.630161</td>\n",
              "      <td>0.638026</td>\n",
              "      <td>0.539374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.103500</td>\n",
              "      <td>2.730372</td>\n",
              "      <td>0.604520</td>\n",
              "      <td>0.623074</td>\n",
              "      <td>0.522704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.212200</td>\n",
              "      <td>2.295998</td>\n",
              "      <td>0.597132</td>\n",
              "      <td>0.619669</td>\n",
              "      <td>0.523732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.488900</td>\n",
              "      <td>1.389710</td>\n",
              "      <td>0.635376</td>\n",
              "      <td>0.636851</td>\n",
              "      <td>0.526531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.385100</td>\n",
              "      <td>1.515229</td>\n",
              "      <td>0.646241</td>\n",
              "      <td>0.652978</td>\n",
              "      <td>0.550274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.383700</td>\n",
              "      <td>1.516756</td>\n",
              "      <td>0.645372</td>\n",
              "      <td>0.646582</td>\n",
              "      <td>0.541094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.330600</td>\n",
              "      <td>1.573614</td>\n",
              "      <td>0.665363</td>\n",
              "      <td>0.659930</td>\n",
              "      <td>0.549705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.302700</td>\n",
              "      <td>1.630700</td>\n",
              "      <td>0.666232</td>\n",
              "      <td>0.664749</td>\n",
              "      <td>0.561205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.298300</td>\n",
              "      <td>1.707129</td>\n",
              "      <td>0.663625</td>\n",
              "      <td>0.659142</td>\n",
              "      <td>0.552786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.234000</td>\n",
              "      <td>1.994638</td>\n",
              "      <td>0.660148</td>\n",
              "      <td>0.652212</td>\n",
              "      <td>0.544573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.218500</td>\n",
              "      <td>1.873738</td>\n",
              "      <td>0.664059</td>\n",
              "      <td>0.659673</td>\n",
              "      <td>0.553242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.131700</td>\n",
              "      <td>1.971559</td>\n",
              "      <td>0.663190</td>\n",
              "      <td>0.656109</td>\n",
              "      <td>0.544969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.108200</td>\n",
              "      <td>2.123653</td>\n",
              "      <td>0.662755</td>\n",
              "      <td>0.649332</td>\n",
              "      <td>0.534582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.098900</td>\n",
              "      <td>2.148885</td>\n",
              "      <td>0.658844</td>\n",
              "      <td>0.640772</td>\n",
              "      <td>0.528450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.107000</td>\n",
              "      <td>2.201576</td>\n",
              "      <td>0.653629</td>\n",
              "      <td>0.641522</td>\n",
              "      <td>0.530998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.131700</td>\n",
              "      <td>2.129946</td>\n",
              "      <td>0.658844</td>\n",
              "      <td>0.650208</td>\n",
              "      <td>0.540653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.101100</td>\n",
              "      <td>2.117831</td>\n",
              "      <td>0.675793</td>\n",
              "      <td>0.659289</td>\n",
              "      <td>0.542037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.103400</td>\n",
              "      <td>2.109603</td>\n",
              "      <td>0.667536</td>\n",
              "      <td>0.658753</td>\n",
              "      <td>0.548143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.091400</td>\n",
              "      <td>2.168495</td>\n",
              "      <td>0.673186</td>\n",
              "      <td>0.660290</td>\n",
              "      <td>0.546100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.112400</td>\n",
              "      <td>2.158619</td>\n",
              "      <td>0.667970</td>\n",
              "      <td>0.655799</td>\n",
              "      <td>0.548811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.088900</td>\n",
              "      <td>2.151153</td>\n",
              "      <td>0.667970</td>\n",
              "      <td>0.656162</td>\n",
              "      <td>0.549404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10500\n",
            "Configuration saved in results/checkpoint-10500/config.json\n",
            "Model weights saved in results/checkpoint-10500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-2000 (score: 1.3897101879119873).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:19]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running training *****\n",
            "  Num examples = 42173\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 4 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10544' max='10544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10544/10544 24:39, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.036700</td>\n",
              "      <td>2.988211</td>\n",
              "      <td>0.623642</td>\n",
              "      <td>0.637135</td>\n",
              "      <td>0.537346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.064300</td>\n",
              "      <td>3.081467</td>\n",
              "      <td>0.605824</td>\n",
              "      <td>0.623672</td>\n",
              "      <td>0.521026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.121600</td>\n",
              "      <td>2.678847</td>\n",
              "      <td>0.627553</td>\n",
              "      <td>0.638222</td>\n",
              "      <td>0.535593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>2.046541</td>\n",
              "      <td>0.644502</td>\n",
              "      <td>0.639213</td>\n",
              "      <td>0.531981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.398600</td>\n",
              "      <td>1.791668</td>\n",
              "      <td>0.625815</td>\n",
              "      <td>0.642993</td>\n",
              "      <td>0.542713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.382200</td>\n",
              "      <td>1.448394</td>\n",
              "      <td>0.657540</td>\n",
              "      <td>0.651146</td>\n",
              "      <td>0.542451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.311300</td>\n",
              "      <td>1.599640</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.668044</td>\n",
              "      <td>0.565227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.287800</td>\n",
              "      <td>1.651729</td>\n",
              "      <td>0.663190</td>\n",
              "      <td>0.657954</td>\n",
              "      <td>0.550276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.278200</td>\n",
              "      <td>1.634111</td>\n",
              "      <td>0.667536</td>\n",
              "      <td>0.655442</td>\n",
              "      <td>0.543734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.233700</td>\n",
              "      <td>1.864262</td>\n",
              "      <td>0.671013</td>\n",
              "      <td>0.655072</td>\n",
              "      <td>0.548036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.196100</td>\n",
              "      <td>1.943606</td>\n",
              "      <td>0.668840</td>\n",
              "      <td>0.654634</td>\n",
              "      <td>0.546880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.118200</td>\n",
              "      <td>2.031738</td>\n",
              "      <td>0.662321</td>\n",
              "      <td>0.655989</td>\n",
              "      <td>0.544762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.096900</td>\n",
              "      <td>2.183115</td>\n",
              "      <td>0.663190</td>\n",
              "      <td>0.653163</td>\n",
              "      <td>0.548039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>2.102567</td>\n",
              "      <td>0.668405</td>\n",
              "      <td>0.651670</td>\n",
              "      <td>0.537587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.088400</td>\n",
              "      <td>2.191583</td>\n",
              "      <td>0.671447</td>\n",
              "      <td>0.655267</td>\n",
              "      <td>0.538479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.109800</td>\n",
              "      <td>2.241187</td>\n",
              "      <td>0.673186</td>\n",
              "      <td>0.656795</td>\n",
              "      <td>0.544700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.101500</td>\n",
              "      <td>2.204563</td>\n",
              "      <td>0.675359</td>\n",
              "      <td>0.667322</td>\n",
              "      <td>0.557486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.085200</td>\n",
              "      <td>2.219684</td>\n",
              "      <td>0.675793</td>\n",
              "      <td>0.662704</td>\n",
              "      <td>0.552570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.074200</td>\n",
              "      <td>2.277405</td>\n",
              "      <td>0.669709</td>\n",
              "      <td>0.653248</td>\n",
              "      <td>0.540051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.109000</td>\n",
              "      <td>2.248942</td>\n",
              "      <td>0.670143</td>\n",
              "      <td>0.653558</td>\n",
              "      <td>0.541340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.093400</td>\n",
              "      <td>2.228366</td>\n",
              "      <td>0.671882</td>\n",
              "      <td>0.658037</td>\n",
              "      <td>0.548778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10500\n",
            "Configuration saved in results/checkpoint-10500/config.json\n",
            "Model weights saved in results/checkpoint-10500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-3000 (score: 1.4483939409255981).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='864' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:20]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 2301\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 5 Complete---------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l2tLYmc56bW"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzcRzODY57oH",
        "outputId": "80e03f20-97d8-4b0d-e1d7-7b6117854ece"
      },
      "source": [
        "import statistics\n",
        "\n",
        "print(\"%15s %s (%s)\" % (\"\",\"Mean\", \"StDev\"))\n",
        "\n",
        "print(\"-\"*29)\n",
        "print(\"Macro Scores\")\n",
        "print(\"-\"*29)\n",
        "\n",
        "print(f\"%15s %s (%s)\" %(\"Accuracy\",\n",
        "    round(statistics.mean(accuracy_list),3),\n",
        "    round(statistics.stdev(accuracy_list),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Macro F1\",\n",
        "    round(statistics.mean(macro_f1_score_list),3),\n",
        "    round(statistics.stdev(macro_f1_score_list),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Weighted F1\",\n",
        "    round(statistics.mean(weighted_f1_score_list),3),\n",
        "    round(statistics.stdev(weighted_f1_score_list),3)))\n",
        "\n",
        "print(\"-\"*29)\n",
        "print(\"Class Scores\")\n",
        "print(\"-\"*29)\n",
        "\n",
        "print(f\"%15s %s (%s)\" %(\"Positive\",\n",
        "    round(statistics.mean(positive_f1_score),3),\n",
        "    round(statistics.stdev(positive_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Neutral\",\n",
        "    round(statistics.mean(neutral_f1_score),3),\n",
        "    round(statistics.stdev(neutral_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Negative\",\n",
        "    round(statistics.mean(negative_f1_score),3),\n",
        "    round(statistics.stdev(negative_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Mixed\",\n",
        "    round(statistics.mean(mixed_f1_score),3),\n",
        "    round(statistics.stdev(mixed_f1_score),3)))"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Mean (StDev)\n",
            "-----------------------------\n",
            "Macro Scores\n",
            "-----------------------------\n",
            "       Accuracy 0.634 (0.015)\n",
            "       Macro F1 0.541 (0.011)\n",
            "    Weighted F1 0.642 (0.007)\n",
            "-----------------------------\n",
            "Class Scores\n",
            "-----------------------------\n",
            "       Positive 0.798 (0.015)\n",
            "        Neutral 0.556 (0.008)\n",
            "       Negative 0.553 (0.024)\n",
            "          Mixed 0.257 (0.031)\n"
          ]
        }
      ]
    }
  ]
}