{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RtGender - Sentiment - Easy Data Augmentation Techniques- Removed & Mixed Sentiment Irrelevant.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "N7PAJ1oIJZfY",
        "_QhabasyTaAU",
        "OYm-yyHufXuD"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51c33a7d927a48a696ee94e11fb6f2da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6eac04909a664237923874b8492ffdc2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b67af53f448457884c89b63ffd43552",
              "IPY_MODEL_b33b09703a0f4b589be1744f4bec8cb5",
              "IPY_MODEL_37b382984c8e49d2ae5504633820d8e7"
            ]
          }
        },
        "6eac04909a664237923874b8492ffdc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b67af53f448457884c89b63ffd43552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5bb75379d9934e638fccefbd77b87813",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19f3dfdb80f549fcba5d6578e5cd1e40"
          }
        },
        "b33b09703a0f4b589be1744f4bec8cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d0c3e57581846679a06c75d273d7d44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d36610b2a6aa47d48b232da187144766"
          }
        },
        "37b382984c8e49d2ae5504633820d8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e704e06d6e724004833979f08bf06f43",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:03&lt;00:00,  3.25s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18e770fb3ec54d2681b766ccc3dbd48a"
          }
        },
        "5bb75379d9934e638fccefbd77b87813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19f3dfdb80f549fcba5d6578e5cd1e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d0c3e57581846679a06c75d273d7d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d36610b2a6aa47d48b232da187144766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e704e06d6e724004833979f08bf06f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18e770fb3ec54d2681b766ccc3dbd48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bed27d19f37c43af9ba153022859892d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d16e159db746426888329fae8a69baa6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4c3f21af0404170ab36f71b86b4d2da",
              "IPY_MODEL_ae71bcc42e1049b196f02a924973cd8d",
              "IPY_MODEL_8cffec8e59b34ca2a9f80b1d98c0999d"
            ]
          }
        },
        "d16e159db746426888329fae8a69baa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4c3f21af0404170ab36f71b86b4d2da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c2bacee53284ad0a1dbbb32fc6209a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_930c51b0d74a4ecc93864c010ceac441"
          }
        },
        "ae71bcc42e1049b196f02a924973cd8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_53def5f78b3e4aad90824b2795c0385c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d97857e12884d0db4e9b4ebf92fab08"
          }
        },
        "8cffec8e59b34ca2a9f80b1d98c0999d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ed58ab3ed4d342e2aa86135fc7a5a0db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  8.05ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_295761e6a00143119c39079eae7c943d"
          }
        },
        "5c2bacee53284ad0a1dbbb32fc6209a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "930c51b0d74a4ecc93864c010ceac441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53def5f78b3e4aad90824b2795c0385c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d97857e12884d0db4e9b4ebf92fab08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed58ab3ed4d342e2aa86135fc7a5a0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "295761e6a00143119c39079eae7c943d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipietri/w266_Final_Project/blob/master/notebooks/RtGender-Notebooks/Experiments_Excluding_Irrelevant_and_Mixed_Sentiment_Examples/RtGender_BERT_Easy_Data_Augmentation_Techniques_Removed_%26_Mixed_Sentiment_Irrelevant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OhO4xlwqExT"
      },
      "source": [
        "RtGender - Annotations - Sentiment w/ Easy Data Augmentation Techniques\n",
        "Removed Irrelevant & Mixed Sentiment Examples\\\n",
        "With oversampled data\\\n",
        "[Source](https://github.com/jasonwei20/eda_nlp)\n",
        "\n",
        "[Paper that explores these techniques](https://arxiv.org/abs/1901.11196)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cirVs78YksXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa5f7cf-8b13-4b3e-f547-83b6d1ffb8e4"
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  path = r'/content/drive/MyDrive/w266'\n",
        "except ModuleNotFoundError:\n",
        "  path = r'data'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7PAJ1oIJZfY"
      },
      "source": [
        "<a id='section01'></a>\n",
        "## Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p--X9MlxQP05",
        "outputId": "9193a61e-d23a-410c-8a9b-6ef327eae2fc"
      },
      "source": [
        "!pip install -U nltk\n",
        "import nltk; nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 40.1 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 47.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 42.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 133 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 184 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 225 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 276 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 296 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 307 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 317 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 327 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 337 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 348 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 358 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 368 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 378 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 389 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 399 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 419 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 430 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 440 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 460 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 471 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 481 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 491 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 512 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 522 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 532 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 552 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 563 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 573 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 583 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 593 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 604 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 614 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 624 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 645 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 655 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 665 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 675 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 686 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 696 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 706 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 716 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 727 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 737 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 747 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 757 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 768 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 778 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 788 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 798 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 808 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 829 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 839 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 849 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 860 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 870 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 880 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 890 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 901 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 911 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 921 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 931 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 942 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 952 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 962 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 972 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 983 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 993 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.0 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.0 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.0 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 82.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.62.3)\n",
            "Installing collected packages: regex, nltk\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.6.5 regex-2021.11.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-GlywkSFegL"
      },
      "source": [
        "%%capture\n",
        "#!pip install transformers==3.0.2\n",
        "!pip install -q transformers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IV4cb3abmJP"
      },
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "import datasets \n",
        "from datasets import load_dataset, Dataset, DatasetDict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "979OUro5Eac3"
      },
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "#from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb1Q5N6LGK7z"
      },
      "source": [
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hErgyoZRHSA3"
      },
      "source": [
        "<a id='section02'></a>\n",
        "## Import and Reshape Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3FzcAlgEac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b864cbb-c848-4306-d7de-e05d2c22d8c8"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/w266/train_oversampled.csv')\n",
        "dev_df = pd.read_csv('/content/drive/MyDrive/w266/annotations_dev.csv')\n",
        "\n",
        "print('train_shape: ',train_df.shape)\n",
        "print('dev_shape: ',dev_df.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_shape:  (21184, 9)\n",
            "dev_shape:  (2303, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntnIM3pjdQ2C",
        "outputId": "aaf80506-1761-45ae-fd9e-bac9c2c48537"
      },
      "source": [
        "# there are NaNs in the dev dataset remove \n",
        "nan_values = dev_df[dev_df.isna().any(axis=1)] \n",
        "print(nan_values)\n",
        "\n",
        "# return without missing values in response_text\n",
        "dev_df.dropna(subset = [\"response_text\"], inplace=True)\n",
        "\n",
        "print(\"Train shape\", train_df.shape)\n",
        "print(\"Dev shape\", dev_df.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0         source op_gender  ...   relevance label labels_4\n",
            "830         2576  facebook_wiki         M  ...  Irrelevant     1        1\n",
            "1664        2722  facebook_wiki         W  ...  Irrelevant     1        1\n",
            "\n",
            "[2 rows x 9 columns]\n",
            "Train shape (21184, 9)\n",
            "Dev shape (2301, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9BHmHVnbaJm",
        "outputId": "cea563bc-cdda-4edb-a6bc-368b8179fb9b"
      },
      "source": [
        "print(\"Unique sentiments: \", train_df['sentiment'].unique())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique sentiments:  ['Positive' 'Mixed' 'Neutral' 'Negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rIl4GMGbYVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f0c78c-4b6f-4668-fd4f-09660f84bc93"
      },
      "source": [
        "# remove mixed sentiment and irrelevant examples\n",
        "train_df  = train_df[train_df['relevance'] != 'Irrelevant']\n",
        "dev_df = dev_df[dev_df['relevance'] != 'Irrelevant']\n",
        "train_df  = train_df[train_df['sentiment'] != 'Mixed']\n",
        "dev_df = dev_df[dev_df['sentiment'] != 'Mixed']\n",
        "\n",
        "print('updated train_shape: ',train_df.shape)\n",
        "print('updated dev_shape: ',dev_df.shape)\n",
        "print(\"Unique sentiments: \", train_df['sentiment'].unique())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updated train_shape:  (13576, 9)\n",
            "updated dev_shape:  (1821, 9)\n",
            "Unique sentiments:  ['Positive' 'Neutral' 'Negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vki-cYpURWf4"
      },
      "source": [
        "# Run through Easy Data Augmentation Techniques package\n",
        "[augment](https://github.com/jasonwei20/eda_nlp/blob/master/code/augment.py)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0gJDRCbgi-P"
      },
      "source": [
        "#### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcTXavwcTzGT",
        "outputId": "513f1cf4-cbd7-40a0-9547-9e92a30ab8e7"
      },
      "source": [
        "# import eda script from github\n",
        "!git clone https://github.com/jasonwei20/eda_nlp"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'eda_nlp'...\n",
            "remote: Enumerating objects: 396, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 396 (delta 6), reused 8 (delta 4), pack-reused 379\u001b[K\n",
            "Receiving objects: 100% (396/396), 20.42 MiB | 25.16 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNy4tEvPXCeE"
      },
      "source": [
        "import sys\n",
        "# sys.path is a list of absolute path strings\n",
        "sys.path.append('/content/eda_nlp/code/')\n",
        "\n",
        "from eda import *"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foi-kqbQd5tC"
      },
      "source": [
        "\n",
        "#### Random deletion & Synonym Replacement\n",
        "Randomly delete words from the sentence with probability p\\\n",
        "Run through the EDA three times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LI4lk6etMI1"
      },
      "source": [
        "def run_del_and_syn_replacement(train_df, iterations):\n",
        "  augmented_sentences = []\n",
        "  labels_list = []\n",
        "  alpha_sr=0.1\n",
        "\n",
        "  for i in range(iterations):\n",
        "    for idx in range(len(train_df)):\n",
        "      example = train_df.iloc[idx]\n",
        "      labels_list.append(example.labels_4)\n",
        "      sentence = example.response_text\n",
        "      \n",
        "      words = sentence.split(' ')\n",
        "      # apply random deletion \n",
        "      a_words = random_deletion(words, 0.1)\n",
        "      \n",
        "      # replace a word with synonyms\n",
        "      num_words = len(a_words)\n",
        "      n_sr = max(1, int(alpha_sr*num_words))\n",
        "      b_words = synonym_replacement(a_words, n_sr)\n",
        "      augmented_sentences.append(' '.join(b_words))\n",
        "      \n",
        "  return augmented_sentences, labels_list\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX7SWjrvubuu",
        "outputId": "55cdcdae-922f-43f2-b49b-0ca36eda785f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " augmented_sentences, labels_list = run_del_and_syn_replacement(train_df, 3)\n",
        " print(\"number of synthetic examples: \", len(labels_list)/len(train_df))\n",
        "\n",
        " "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of synthetic examples:  3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XaZ-97MwjYr",
        "outputId": "2feb50a5-0676-46bd-f963-bd8a624115e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# combine with original dataframe\n",
        "augmented = pd.DataFrame({'response_text': augmented_sentences,\n",
        "                           'labels_4': labels_list})\n",
        "original = train_df[['labels_4', 'response_text']]\n",
        "\n",
        "train_df_aug = original.append(augmented)\n",
        "print(\"number of total examples: \", len(train_df_aug))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of total examples:  54304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QhabasyTaAU"
      },
      "source": [
        "# Transform to HuggingFace friendly format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGcvxwWXIbfq"
      },
      "source": [
        "# change to dataset to work with Huggingface transformer & remove unused columns\n",
        "\n",
        "from datasets import load_dataset\n",
        "train_dataset = Dataset.from_pandas(train_df_aug)\n",
        "dev_dataset = Dataset.from_pandas(dev_df)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(column_names= '__index_level_0__')\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= columns_to_remove)\n",
        "dev_dataset = dev_dataset.remove_columns(column_names= '__index_level_0__')\n",
        "\n",
        "# rename sentiment to labels\n",
        "train_dataset = train_dataset.rename_column(\"labels_4\", \"label\")\n",
        "dev_dataset = dev_dataset.rename_column(\"labels_4\", \"label\")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMF7YvFgcDSW",
        "outputId": "be40f4f9-40c4-4643-e02c-8740c8399584"
      },
      "source": [
        "# combine into a DataDictionary for huggingface use\n",
        "rtg_dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'dev': dev_dataset \n",
        "})\n",
        "\n",
        "rtg_dataset"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'response_text'],\n",
              "        num_rows: 54304\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['response_text', 'label'],\n",
              "        num_rows: 1821\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYm-yyHufXuD"
      },
      "source": [
        "## Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAWtxVO2b1Xf"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JXXScXOWHIb",
        "outputId": "e1c1ba85-4599-4ad0-a206-fd7c2059a7d7"
      },
      "source": [
        "# find the P99 of length for response_text and set that as the max length \n",
        "max_length = train_df['response_text'].astype(str).map(len).quantile(0.99)\n",
        "print(f\"99th %tile of response_text length: {max_length}\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99th %tile of response_text length: 286.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8csnO6fRb5WY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830a8771-26f3-4c26-f937-267704748fbc"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, max_length = max_length)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"response_text\"], padding=True, truncation=True)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_length\": 286.0,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "51c33a7d927a48a696ee94e11fb6f2da",
            "6eac04909a664237923874b8492ffdc2",
            "2b67af53f448457884c89b63ffd43552",
            "b33b09703a0f4b589be1744f4bec8cb5",
            "37b382984c8e49d2ae5504633820d8e7",
            "5bb75379d9934e638fccefbd77b87813",
            "19f3dfdb80f549fcba5d6578e5cd1e40",
            "9d0c3e57581846679a06c75d273d7d44",
            "d36610b2a6aa47d48b232da187144766",
            "e704e06d6e724004833979f08bf06f43",
            "18e770fb3ec54d2681b766ccc3dbd48a",
            "bed27d19f37c43af9ba153022859892d",
            "d16e159db746426888329fae8a69baa6",
            "d4c3f21af0404170ab36f71b86b4d2da",
            "ae71bcc42e1049b196f02a924973cd8d",
            "8cffec8e59b34ca2a9f80b1d98c0999d",
            "5c2bacee53284ad0a1dbbb32fc6209a7",
            "930c51b0d74a4ecc93864c010ceac441",
            "53def5f78b3e4aad90824b2795c0385c",
            "2d97857e12884d0db4e9b4ebf92fab08",
            "ed58ab3ed4d342e2aa86135fc7a5a0db",
            "295761e6a00143119c39079eae7c943d"
          ]
        },
        "id": "YKMeefM8f698",
        "outputId": "33c7525e-4045-438e-d58f-8fb32c0c3e9c"
      },
      "source": [
        "rtg_encoded = rtg_dataset.map(tokenize, batched=True, batch_size=None)\n",
        "rtg_encoded['train'].features"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51c33a7d927a48a696ee94e11fb6f2da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bed27d19f37c43af9ba153022859892d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'label': Value(dtype='int64', id=None),\n",
              " 'response_text': Value(dtype='string', id=None),\n",
              " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_toVz-NgFKH"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ycuAMQWcQ-q",
        "outputId": "9283f965-b561-4d69-f800-0b729cb8b7be"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "num_labels = 3\n",
        "model = (AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1bqyXiLgjLb"
      },
      "source": [
        "rtg_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0gITK_Rgpi5"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
        "    f1_macro = f1_score(labels, preds, average = 'macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1_weighted, \"f1_macro\": f1_macro} "
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRmc5S3ygsUH",
        "outputId": "6c3697e0-ccf6-4a79-cf03-573a8e22856a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 8\n",
        "logging_steps = len(rtg_encoded[\"train\"]) // (batch_size *3)\n",
        "training_args = TrainingArguments(output_dir=\"results\",\n",
        "                                  num_train_epochs=2,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  load_best_model_at_end=True,\n",
        "                                 # metric_for_best_model=\"f1_macro\",\n",
        "                                 # weight_decay=0.01,\n",
        "                                  evaluation_strategy=\"steps\",\n",
        "                                  save_strategy=\"steps\",\n",
        "                                  disable_tqdm=False\n",
        "                                  )"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 500\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YY_V0Pb3pNs4",
        "outputId": "19445299-3e14-42f2-c998-761b35d7311f"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "accuracy_list = []\n",
        "weighted_f1_score_list = []\n",
        "macro_f1_score_list = []\n",
        "negative_f1_score = []\n",
        "neutral_f1_score = []\n",
        "positive_f1_score = []\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  try:\n",
        "    del trainer\n",
        "    del results\n",
        "    del cr\n",
        "  except: pass\n",
        "\n",
        "\n",
        "  trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=rtg_encoded[\"train\"],\n",
        "                  eval_dataset=rtg_encoded[\"dev\"])\n",
        "  trainer.train()\n",
        "  results = trainer.evaluate()\n",
        "\n",
        "  # append macro metrics to lists\n",
        "  accuracy_list.append(results.get('eval_accuracy'))\n",
        "  weighted_f1_score_list.append(results.get(\"eval_f1\"))\n",
        "  macro_f1_score_list.append(results.get(\"eval_f1_macro\"))\n",
        "\n",
        "  trainer.predict(rtg_encoded[\"dev\"])\n",
        "  # append the class-level F1 scores\n",
        "  outputs = trainer.predict(rtg_encoded[\"dev\"])\n",
        "  predictions = outputs.predictions.argmax(1)\n",
        "  labels = rtg_encoded[\"dev\"]['label']\n",
        "  cr = classification_report(labels, predictions, digits=3, output_dict=True)\n",
        "  negative_f1_score.append(cr.get('0').get(\"f1-score\"))\n",
        "  neutral_f1_score.append(cr.get('1').get(\"f1-score\"))\n",
        "  positive_f1_score.append(cr.get('2').get(\"f1-score\"))\n",
        "\n",
        "  print(f'---------------------------Iteration {i+1} Complete---------------------------\\n')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 54304\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 13576\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13576' max='13576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13576/13576 21:18, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.755500</td>\n",
              "      <td>0.617552</td>\n",
              "      <td>0.748490</td>\n",
              "      <td>0.754031</td>\n",
              "      <td>0.691613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.607500</td>\n",
              "      <td>0.617604</td>\n",
              "      <td>0.755080</td>\n",
              "      <td>0.757117</td>\n",
              "      <td>0.695015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.507900</td>\n",
              "      <td>0.661896</td>\n",
              "      <td>0.760571</td>\n",
              "      <td>0.760942</td>\n",
              "      <td>0.698577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.473400</td>\n",
              "      <td>0.701221</td>\n",
              "      <td>0.760022</td>\n",
              "      <td>0.763452</td>\n",
              "      <td>0.704021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.436300</td>\n",
              "      <td>0.892119</td>\n",
              "      <td>0.749588</td>\n",
              "      <td>0.744314</td>\n",
              "      <td>0.672996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.399900</td>\n",
              "      <td>0.805987</td>\n",
              "      <td>0.762219</td>\n",
              "      <td>0.759872</td>\n",
              "      <td>0.693430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.375900</td>\n",
              "      <td>0.863002</td>\n",
              "      <td>0.762219</td>\n",
              "      <td>0.766185</td>\n",
              "      <td>0.708597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.371400</td>\n",
              "      <td>0.914270</td>\n",
              "      <td>0.759473</td>\n",
              "      <td>0.758337</td>\n",
              "      <td>0.692721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.365700</td>\n",
              "      <td>0.960575</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>0.756638</td>\n",
              "      <td>0.700215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.306000</td>\n",
              "      <td>1.018252</td>\n",
              "      <td>0.764964</td>\n",
              "      <td>0.760953</td>\n",
              "      <td>0.698559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.307800</td>\n",
              "      <td>1.065217</td>\n",
              "      <td>0.763866</td>\n",
              "      <td>0.757054</td>\n",
              "      <td>0.694042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.267600</td>\n",
              "      <td>1.185970</td>\n",
              "      <td>0.760571</td>\n",
              "      <td>0.757101</td>\n",
              "      <td>0.694684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.269200</td>\n",
              "      <td>1.184053</td>\n",
              "      <td>0.756178</td>\n",
              "      <td>0.755348</td>\n",
              "      <td>0.694548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.198900</td>\n",
              "      <td>1.357642</td>\n",
              "      <td>0.757825</td>\n",
              "      <td>0.750675</td>\n",
              "      <td>0.687619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.145300</td>\n",
              "      <td>1.400603</td>\n",
              "      <td>0.759473</td>\n",
              "      <td>0.751974</td>\n",
              "      <td>0.688663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.138700</td>\n",
              "      <td>1.440244</td>\n",
              "      <td>0.751785</td>\n",
              "      <td>0.742711</td>\n",
              "      <td>0.676478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.126300</td>\n",
              "      <td>1.485903</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.754587</td>\n",
              "      <td>0.689190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.161500</td>\n",
              "      <td>1.400153</td>\n",
              "      <td>0.760571</td>\n",
              "      <td>0.753615</td>\n",
              "      <td>0.691189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.109000</td>\n",
              "      <td>1.441538</td>\n",
              "      <td>0.761120</td>\n",
              "      <td>0.757804</td>\n",
              "      <td>0.697371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.118300</td>\n",
              "      <td>1.509054</td>\n",
              "      <td>0.751236</td>\n",
              "      <td>0.750552</td>\n",
              "      <td>0.689871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.122300</td>\n",
              "      <td>1.552463</td>\n",
              "      <td>0.752334</td>\n",
              "      <td>0.743336</td>\n",
              "      <td>0.677189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.090700</td>\n",
              "      <td>1.626655</td>\n",
              "      <td>0.748490</td>\n",
              "      <td>0.738113</td>\n",
              "      <td>0.668631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.101100</td>\n",
              "      <td>1.536470</td>\n",
              "      <td>0.759473</td>\n",
              "      <td>0.752225</td>\n",
              "      <td>0.688446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.089600</td>\n",
              "      <td>1.613470</td>\n",
              "      <td>0.756178</td>\n",
              "      <td>0.746542</td>\n",
              "      <td>0.681697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.089500</td>\n",
              "      <td>1.614537</td>\n",
              "      <td>0.756727</td>\n",
              "      <td>0.749272</td>\n",
              "      <td>0.685598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.103600</td>\n",
              "      <td>1.610244</td>\n",
              "      <td>0.760571</td>\n",
              "      <td>0.753547</td>\n",
              "      <td>0.690988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.080700</td>\n",
              "      <td>1.613775</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.751896</td>\n",
              "      <td>0.688679</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10500\n",
            "Configuration saved in results/checkpoint-10500/config.json\n",
            "Model weights saved in results/checkpoint-10500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-11000\n",
            "Configuration saved in results/checkpoint-11000/config.json\n",
            "Model weights saved in results/checkpoint-11000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-11500\n",
            "Configuration saved in results/checkpoint-11500/config.json\n",
            "Model weights saved in results/checkpoint-11500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-12000\n",
            "Configuration saved in results/checkpoint-12000/config.json\n",
            "Model weights saved in results/checkpoint-12000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-12500\n",
            "Configuration saved in results/checkpoint-12500/config.json\n",
            "Model weights saved in results/checkpoint-12500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-13000\n",
            "Configuration saved in results/checkpoint-13000/config.json\n",
            "Model weights saved in results/checkpoint-13000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-13500\n",
            "Configuration saved in results/checkpoint-13500/config.json\n",
            "Model weights saved in results/checkpoint-13500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-500 (score: 0.617551863193512).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='684' max='228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [228/228 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 54304\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 13576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 1 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13576' max='13576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13576/13576 21:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.309500</td>\n",
              "      <td>1.225323</td>\n",
              "      <td>0.710599</td>\n",
              "      <td>0.724204</td>\n",
              "      <td>0.665406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.604800</td>\n",
              "      <td>0.616496</td>\n",
              "      <td>0.762219</td>\n",
              "      <td>0.763128</td>\n",
              "      <td>0.703144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.701295</td>\n",
              "      <td>0.750686</td>\n",
              "      <td>0.750171</td>\n",
              "      <td>0.684892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.457200</td>\n",
              "      <td>0.751717</td>\n",
              "      <td>0.766612</td>\n",
              "      <td>0.765937</td>\n",
              "      <td>0.705459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.413700</td>\n",
              "      <td>0.959337</td>\n",
              "      <td>0.744646</td>\n",
              "      <td>0.742063</td>\n",
              "      <td>0.672775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.392500</td>\n",
              "      <td>0.865063</td>\n",
              "      <td>0.754530</td>\n",
              "      <td>0.751320</td>\n",
              "      <td>0.685529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.356400</td>\n",
              "      <td>0.967710</td>\n",
              "      <td>0.757825</td>\n",
              "      <td>0.758432</td>\n",
              "      <td>0.696252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.352900</td>\n",
              "      <td>0.992793</td>\n",
              "      <td>0.760022</td>\n",
              "      <td>0.755130</td>\n",
              "      <td>0.691194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.342400</td>\n",
              "      <td>1.028133</td>\n",
              "      <td>0.754530</td>\n",
              "      <td>0.756382</td>\n",
              "      <td>0.695206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.319200</td>\n",
              "      <td>1.097770</td>\n",
              "      <td>0.758375</td>\n",
              "      <td>0.747485</td>\n",
              "      <td>0.681382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.301200</td>\n",
              "      <td>1.117582</td>\n",
              "      <td>0.757825</td>\n",
              "      <td>0.747281</td>\n",
              "      <td>0.680720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.269400</td>\n",
              "      <td>1.257149</td>\n",
              "      <td>0.755080</td>\n",
              "      <td>0.746071</td>\n",
              "      <td>0.679017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.245600</td>\n",
              "      <td>1.203283</td>\n",
              "      <td>0.755629</td>\n",
              "      <td>0.749905</td>\n",
              "      <td>0.683123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.182700</td>\n",
              "      <td>1.441141</td>\n",
              "      <td>0.756178</td>\n",
              "      <td>0.741719</td>\n",
              "      <td>0.672109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.120700</td>\n",
              "      <td>1.503075</td>\n",
              "      <td>0.756727</td>\n",
              "      <td>0.747971</td>\n",
              "      <td>0.682237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.128400</td>\n",
              "      <td>1.503674</td>\n",
              "      <td>0.758375</td>\n",
              "      <td>0.751748</td>\n",
              "      <td>0.688278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.121000</td>\n",
              "      <td>1.555709</td>\n",
              "      <td>0.756727</td>\n",
              "      <td>0.747342</td>\n",
              "      <td>0.680810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.134400</td>\n",
              "      <td>1.495943</td>\n",
              "      <td>0.750686</td>\n",
              "      <td>0.744316</td>\n",
              "      <td>0.676891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.126600</td>\n",
              "      <td>1.493621</td>\n",
              "      <td>0.757825</td>\n",
              "      <td>0.752557</td>\n",
              "      <td>0.687883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.104400</td>\n",
              "      <td>1.592689</td>\n",
              "      <td>0.757276</td>\n",
              "      <td>0.751205</td>\n",
              "      <td>0.686157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.105400</td>\n",
              "      <td>1.617604</td>\n",
              "      <td>0.757276</td>\n",
              "      <td>0.751278</td>\n",
              "      <td>0.685580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.087000</td>\n",
              "      <td>1.649285</td>\n",
              "      <td>0.755629</td>\n",
              "      <td>0.746838</td>\n",
              "      <td>0.678497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.091200</td>\n",
              "      <td>1.618815</td>\n",
              "      <td>0.757825</td>\n",
              "      <td>0.752115</td>\n",
              "      <td>0.688404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.081200</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>0.757825</td>\n",
              "      <td>0.746909</td>\n",
              "      <td>0.679035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.079600</td>\n",
              "      <td>1.645067</td>\n",
              "      <td>0.756178</td>\n",
              "      <td>0.750333</td>\n",
              "      <td>0.687079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.088100</td>\n",
              "      <td>1.644366</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.752883</td>\n",
              "      <td>0.689994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.085000</td>\n",
              "      <td>1.656007</td>\n",
              "      <td>0.758375</td>\n",
              "      <td>0.750332</td>\n",
              "      <td>0.685842</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10500\n",
            "Configuration saved in results/checkpoint-10500/config.json\n",
            "Model weights saved in results/checkpoint-10500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-11000\n",
            "Configuration saved in results/checkpoint-11000/config.json\n",
            "Model weights saved in results/checkpoint-11000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-11500\n",
            "Configuration saved in results/checkpoint-11500/config.json\n",
            "Model weights saved in results/checkpoint-11500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-12000\n",
            "Configuration saved in results/checkpoint-12000/config.json\n",
            "Model weights saved in results/checkpoint-12000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-12500\n",
            "Configuration saved in results/checkpoint-12500/config.json\n",
            "Model weights saved in results/checkpoint-12500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-13000\n",
            "Configuration saved in results/checkpoint-13000/config.json\n",
            "Model weights saved in results/checkpoint-13000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-13500\n",
            "Configuration saved in results/checkpoint-13500/config.json\n",
            "Model weights saved in results/checkpoint-13500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-1000 (score: 0.6164957284927368).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='684' max='228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [228/228 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 54304\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 13576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 2 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13576' max='13576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13576/13576 21:41, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.119200</td>\n",
              "      <td>1.755886</td>\n",
              "      <td>0.702910</td>\n",
              "      <td>0.717951</td>\n",
              "      <td>0.660080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.188900</td>\n",
              "      <td>1.401120</td>\n",
              "      <td>0.747392</td>\n",
              "      <td>0.750329</td>\n",
              "      <td>0.688682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.515400</td>\n",
              "      <td>0.671573</td>\n",
              "      <td>0.753981</td>\n",
              "      <td>0.755287</td>\n",
              "      <td>0.691384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.435800</td>\n",
              "      <td>0.803046</td>\n",
              "      <td>0.753981</td>\n",
              "      <td>0.757434</td>\n",
              "      <td>0.695656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.408800</td>\n",
              "      <td>0.974176</td>\n",
              "      <td>0.764415</td>\n",
              "      <td>0.756091</td>\n",
              "      <td>0.687088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.383600</td>\n",
              "      <td>0.853063</td>\n",
              "      <td>0.760571</td>\n",
              "      <td>0.754081</td>\n",
              "      <td>0.687259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.347200</td>\n",
              "      <td>1.077794</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.761387</td>\n",
              "      <td>0.700392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.340400</td>\n",
              "      <td>1.060785</td>\n",
              "      <td>0.746842</td>\n",
              "      <td>0.743735</td>\n",
              "      <td>0.674564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.339700</td>\n",
              "      <td>1.089638</td>\n",
              "      <td>0.755629</td>\n",
              "      <td>0.753291</td>\n",
              "      <td>0.690008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.294900</td>\n",
              "      <td>1.127014</td>\n",
              "      <td>0.760571</td>\n",
              "      <td>0.756279</td>\n",
              "      <td>0.693682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.292800</td>\n",
              "      <td>1.186649</td>\n",
              "      <td>0.759473</td>\n",
              "      <td>0.755581</td>\n",
              "      <td>0.691439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.249100</td>\n",
              "      <td>1.286367</td>\n",
              "      <td>0.758375</td>\n",
              "      <td>0.749925</td>\n",
              "      <td>0.683370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.224000</td>\n",
              "      <td>1.202559</td>\n",
              "      <td>0.762768</td>\n",
              "      <td>0.759703</td>\n",
              "      <td>0.696952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.167500</td>\n",
              "      <td>1.470778</td>\n",
              "      <td>0.758375</td>\n",
              "      <td>0.748479</td>\n",
              "      <td>0.679085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.118400</td>\n",
              "      <td>1.479365</td>\n",
              "      <td>0.769907</td>\n",
              "      <td>0.764295</td>\n",
              "      <td>0.702922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.122600</td>\n",
              "      <td>1.555682</td>\n",
              "      <td>0.751785</td>\n",
              "      <td>0.734924</td>\n",
              "      <td>0.664337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.091600</td>\n",
              "      <td>1.621307</td>\n",
              "      <td>0.757276</td>\n",
              "      <td>0.749173</td>\n",
              "      <td>0.678387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.131800</td>\n",
              "      <td>1.533338</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.753324</td>\n",
              "      <td>0.689053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.093500</td>\n",
              "      <td>1.508401</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.751630</td>\n",
              "      <td>0.683876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.082900</td>\n",
              "      <td>1.633475</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.752573</td>\n",
              "      <td>0.686529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.095100</td>\n",
              "      <td>1.659712</td>\n",
              "      <td>0.758375</td>\n",
              "      <td>0.749875</td>\n",
              "      <td>0.682711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.081600</td>\n",
              "      <td>1.698083</td>\n",
              "      <td>0.753432</td>\n",
              "      <td>0.745352</td>\n",
              "      <td>0.675728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.089000</td>\n",
              "      <td>1.674630</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.752343</td>\n",
              "      <td>0.687087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.072500</td>\n",
              "      <td>1.741978</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.750755</td>\n",
              "      <td>0.683063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.075800</td>\n",
              "      <td>1.703668</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>0.741309</td>\n",
              "      <td>0.671405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.080400</td>\n",
              "      <td>1.710390</td>\n",
              "      <td>0.757276</td>\n",
              "      <td>0.750985</td>\n",
              "      <td>0.685405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.076600</td>\n",
              "      <td>1.721494</td>\n",
              "      <td>0.756727</td>\n",
              "      <td>0.749488</td>\n",
              "      <td>0.682804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10500\n",
            "Configuration saved in results/checkpoint-10500/config.json\n",
            "Model weights saved in results/checkpoint-10500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-11000\n",
            "Configuration saved in results/checkpoint-11000/config.json\n",
            "Model weights saved in results/checkpoint-11000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-11500\n",
            "Configuration saved in results/checkpoint-11500/config.json\n",
            "Model weights saved in results/checkpoint-11500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-12000\n",
            "Configuration saved in results/checkpoint-12000/config.json\n",
            "Model weights saved in results/checkpoint-12000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-12500\n",
            "Configuration saved in results/checkpoint-12500/config.json\n",
            "Model weights saved in results/checkpoint-12500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-13000\n",
            "Configuration saved in results/checkpoint-13000/config.json\n",
            "Model weights saved in results/checkpoint-13000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-13500\n",
            "Configuration saved in results/checkpoint-13500/config.json\n",
            "Model weights saved in results/checkpoint-13500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-1500 (score: 0.6715725660324097).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='684' max='228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [228/228 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 54304\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 13576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 3 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13576' max='13576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13576/13576 21:40, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.052900</td>\n",
              "      <td>1.777084</td>\n",
              "      <td>0.742998</td>\n",
              "      <td>0.746182</td>\n",
              "      <td>0.681517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.093300</td>\n",
              "      <td>1.732805</td>\n",
              "      <td>0.757825</td>\n",
              "      <td>0.751023</td>\n",
              "      <td>0.686320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.201400</td>\n",
              "      <td>1.599025</td>\n",
              "      <td>0.750686</td>\n",
              "      <td>0.750194</td>\n",
              "      <td>0.684224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.477600</td>\n",
              "      <td>0.860748</td>\n",
              "      <td>0.761120</td>\n",
              "      <td>0.761415</td>\n",
              "      <td>0.697476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.391400</td>\n",
              "      <td>1.054086</td>\n",
              "      <td>0.752334</td>\n",
              "      <td>0.742416</td>\n",
              "      <td>0.669168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.390200</td>\n",
              "      <td>0.940853</td>\n",
              "      <td>0.752334</td>\n",
              "      <td>0.746013</td>\n",
              "      <td>0.676071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.334400</td>\n",
              "      <td>1.118318</td>\n",
              "      <td>0.751785</td>\n",
              "      <td>0.756944</td>\n",
              "      <td>0.697065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.328900</td>\n",
              "      <td>1.082150</td>\n",
              "      <td>0.753432</td>\n",
              "      <td>0.751015</td>\n",
              "      <td>0.685712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.329800</td>\n",
              "      <td>1.148284</td>\n",
              "      <td>0.749588</td>\n",
              "      <td>0.748596</td>\n",
              "      <td>0.683650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.279300</td>\n",
              "      <td>1.259982</td>\n",
              "      <td>0.753981</td>\n",
              "      <td>0.740736</td>\n",
              "      <td>0.670309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.267500</td>\n",
              "      <td>1.287081</td>\n",
              "      <td>0.752334</td>\n",
              "      <td>0.747978</td>\n",
              "      <td>0.680933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.236600</td>\n",
              "      <td>1.367574</td>\n",
              "      <td>0.748490</td>\n",
              "      <td>0.737337</td>\n",
              "      <td>0.667970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.241400</td>\n",
              "      <td>1.281076</td>\n",
              "      <td>0.764415</td>\n",
              "      <td>0.759728</td>\n",
              "      <td>0.697445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>1.616544</td>\n",
              "      <td>0.742998</td>\n",
              "      <td>0.726164</td>\n",
              "      <td>0.651209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.110300</td>\n",
              "      <td>1.482121</td>\n",
              "      <td>0.757276</td>\n",
              "      <td>0.749266</td>\n",
              "      <td>0.682919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.117000</td>\n",
              "      <td>1.618801</td>\n",
              "      <td>0.739154</td>\n",
              "      <td>0.719171</td>\n",
              "      <td>0.646381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>1.700925</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>0.738396</td>\n",
              "      <td>0.670204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.117300</td>\n",
              "      <td>1.602615</td>\n",
              "      <td>0.754530</td>\n",
              "      <td>0.744533</td>\n",
              "      <td>0.677812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.087900</td>\n",
              "      <td>1.497011</td>\n",
              "      <td>0.752334</td>\n",
              "      <td>0.748534</td>\n",
              "      <td>0.682967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.078500</td>\n",
              "      <td>1.720455</td>\n",
              "      <td>0.749039</td>\n",
              "      <td>0.736857</td>\n",
              "      <td>0.666783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.100800</td>\n",
              "      <td>1.668230</td>\n",
              "      <td>0.753981</td>\n",
              "      <td>0.746259</td>\n",
              "      <td>0.677392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.075600</td>\n",
              "      <td>1.649342</td>\n",
              "      <td>0.756727</td>\n",
              "      <td>0.752528</td>\n",
              "      <td>0.687980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.077000</td>\n",
              "      <td>1.689045</td>\n",
              "      <td>0.756727</td>\n",
              "      <td>0.747890</td>\n",
              "      <td>0.681117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.056300</td>\n",
              "      <td>1.779681</td>\n",
              "      <td>0.751785</td>\n",
              "      <td>0.740365</td>\n",
              "      <td>0.669575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.052400</td>\n",
              "      <td>1.762538</td>\n",
              "      <td>0.752334</td>\n",
              "      <td>0.745375</td>\n",
              "      <td>0.678573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.072300</td>\n",
              "      <td>1.799238</td>\n",
              "      <td>0.746293</td>\n",
              "      <td>0.736124</td>\n",
              "      <td>0.667102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.058600</td>\n",
              "      <td>1.797124</td>\n",
              "      <td>0.747941</td>\n",
              "      <td>0.740141</td>\n",
              "      <td>0.672505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10500\n",
            "Configuration saved in results/checkpoint-10500/config.json\n",
            "Model weights saved in results/checkpoint-10500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-11000\n",
            "Configuration saved in results/checkpoint-11000/config.json\n",
            "Model weights saved in results/checkpoint-11000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-11500\n",
            "Configuration saved in results/checkpoint-11500/config.json\n",
            "Model weights saved in results/checkpoint-11500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-12000\n",
            "Configuration saved in results/checkpoint-12000/config.json\n",
            "Model weights saved in results/checkpoint-12000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-12500\n",
            "Configuration saved in results/checkpoint-12500/config.json\n",
            "Model weights saved in results/checkpoint-12500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-13000\n",
            "Configuration saved in results/checkpoint-13000/config.json\n",
            "Model weights saved in results/checkpoint-13000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-13500\n",
            "Configuration saved in results/checkpoint-13500/config.json\n",
            "Model weights saved in results/checkpoint-13500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-2000 (score: 0.8607475161552429).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='684' max='228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [228/228 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running training *****\n",
            "  Num examples = 54304\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 13576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 4 Complete---------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13576' max='13576' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13576/13576 21:52, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.039600</td>\n",
              "      <td>1.886578</td>\n",
              "      <td>0.747941</td>\n",
              "      <td>0.748635</td>\n",
              "      <td>0.681478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.059100</td>\n",
              "      <td>2.106729</td>\n",
              "      <td>0.749039</td>\n",
              "      <td>0.733189</td>\n",
              "      <td>0.656463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.103900</td>\n",
              "      <td>1.833354</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.753284</td>\n",
              "      <td>0.689305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.196300</td>\n",
              "      <td>1.482510</td>\n",
              "      <td>0.743548</td>\n",
              "      <td>0.749776</td>\n",
              "      <td>0.690779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.434800</td>\n",
              "      <td>1.028764</td>\n",
              "      <td>0.751785</td>\n",
              "      <td>0.736282</td>\n",
              "      <td>0.663080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.370900</td>\n",
              "      <td>1.043404</td>\n",
              "      <td>0.756727</td>\n",
              "      <td>0.746115</td>\n",
              "      <td>0.679115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.321900</td>\n",
              "      <td>1.241820</td>\n",
              "      <td>0.739154</td>\n",
              "      <td>0.746149</td>\n",
              "      <td>0.686199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>1.154687</td>\n",
              "      <td>0.758924</td>\n",
              "      <td>0.755150</td>\n",
              "      <td>0.691757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.310000</td>\n",
              "      <td>1.222130</td>\n",
              "      <td>0.750686</td>\n",
              "      <td>0.748012</td>\n",
              "      <td>0.684362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.261600</td>\n",
              "      <td>1.300305</td>\n",
              "      <td>0.751785</td>\n",
              "      <td>0.742565</td>\n",
              "      <td>0.676386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.252800</td>\n",
              "      <td>1.317740</td>\n",
              "      <td>0.745744</td>\n",
              "      <td>0.739239</td>\n",
              "      <td>0.671299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.215100</td>\n",
              "      <td>1.382331</td>\n",
              "      <td>0.744646</td>\n",
              "      <td>0.740088</td>\n",
              "      <td>0.672968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.205900</td>\n",
              "      <td>1.351018</td>\n",
              "      <td>0.751785</td>\n",
              "      <td>0.747487</td>\n",
              "      <td>0.680654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.148800</td>\n",
              "      <td>1.648599</td>\n",
              "      <td>0.746842</td>\n",
              "      <td>0.734637</td>\n",
              "      <td>0.662181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.090600</td>\n",
              "      <td>1.655815</td>\n",
              "      <td>0.751236</td>\n",
              "      <td>0.742281</td>\n",
              "      <td>0.673498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.098900</td>\n",
              "      <td>1.721037</td>\n",
              "      <td>0.748490</td>\n",
              "      <td>0.732855</td>\n",
              "      <td>0.660526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.070400</td>\n",
              "      <td>1.830171</td>\n",
              "      <td>0.751236</td>\n",
              "      <td>0.741683</td>\n",
              "      <td>0.671706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.102000</td>\n",
              "      <td>1.596576</td>\n",
              "      <td>0.759473</td>\n",
              "      <td>0.758803</td>\n",
              "      <td>0.695677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.081200</td>\n",
              "      <td>1.614736</td>\n",
              "      <td>0.756178</td>\n",
              "      <td>0.751968</td>\n",
              "      <td>0.686404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.063800</td>\n",
              "      <td>1.762444</td>\n",
              "      <td>0.750686</td>\n",
              "      <td>0.743602</td>\n",
              "      <td>0.675447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.069700</td>\n",
              "      <td>1.838520</td>\n",
              "      <td>0.752883</td>\n",
              "      <td>0.745425</td>\n",
              "      <td>0.677576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.071100</td>\n",
              "      <td>1.788570</td>\n",
              "      <td>0.747392</td>\n",
              "      <td>0.743137</td>\n",
              "      <td>0.675937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.059600</td>\n",
              "      <td>1.790626</td>\n",
              "      <td>0.753432</td>\n",
              "      <td>0.746920</td>\n",
              "      <td>0.679083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.052300</td>\n",
              "      <td>1.899400</td>\n",
              "      <td>0.751785</td>\n",
              "      <td>0.739964</td>\n",
              "      <td>0.670661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.056400</td>\n",
              "      <td>1.892178</td>\n",
              "      <td>0.750686</td>\n",
              "      <td>0.743747</td>\n",
              "      <td>0.677722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>1.869602</td>\n",
              "      <td>0.752334</td>\n",
              "      <td>0.743906</td>\n",
              "      <td>0.676908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.053000</td>\n",
              "      <td>1.882205</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>0.741586</td>\n",
              "      <td>0.674050</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-500\n",
            "Configuration saved in results/checkpoint-500/config.json\n",
            "Model weights saved in results/checkpoint-500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1000\n",
            "Configuration saved in results/checkpoint-1000/config.json\n",
            "Model weights saved in results/checkpoint-1000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1500\n",
            "Configuration saved in results/checkpoint-1500/config.json\n",
            "Model weights saved in results/checkpoint-1500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2000\n",
            "Configuration saved in results/checkpoint-2000/config.json\n",
            "Model weights saved in results/checkpoint-2000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-2500\n",
            "Configuration saved in results/checkpoint-2500/config.json\n",
            "Model weights saved in results/checkpoint-2500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3000\n",
            "Configuration saved in results/checkpoint-3000/config.json\n",
            "Model weights saved in results/checkpoint-3000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3500\n",
            "Configuration saved in results/checkpoint-3500/config.json\n",
            "Model weights saved in results/checkpoint-3500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4000\n",
            "Configuration saved in results/checkpoint-4000/config.json\n",
            "Model weights saved in results/checkpoint-4000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4500\n",
            "Configuration saved in results/checkpoint-4500/config.json\n",
            "Model weights saved in results/checkpoint-4500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5000\n",
            "Configuration saved in results/checkpoint-5000/config.json\n",
            "Model weights saved in results/checkpoint-5000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-5500\n",
            "Configuration saved in results/checkpoint-5500/config.json\n",
            "Model weights saved in results/checkpoint-5500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6000\n",
            "Configuration saved in results/checkpoint-6000/config.json\n",
            "Model weights saved in results/checkpoint-6000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6500\n",
            "Configuration saved in results/checkpoint-6500/config.json\n",
            "Model weights saved in results/checkpoint-6500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7000\n",
            "Configuration saved in results/checkpoint-7000/config.json\n",
            "Model weights saved in results/checkpoint-7000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-7500\n",
            "Configuration saved in results/checkpoint-7500/config.json\n",
            "Model weights saved in results/checkpoint-7500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8000\n",
            "Configuration saved in results/checkpoint-8000/config.json\n",
            "Model weights saved in results/checkpoint-8000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-8500\n",
            "Configuration saved in results/checkpoint-8500/config.json\n",
            "Model weights saved in results/checkpoint-8500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9000\n",
            "Configuration saved in results/checkpoint-9000/config.json\n",
            "Model weights saved in results/checkpoint-9000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-9500\n",
            "Configuration saved in results/checkpoint-9500/config.json\n",
            "Model weights saved in results/checkpoint-9500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10000\n",
            "Configuration saved in results/checkpoint-10000/config.json\n",
            "Model weights saved in results/checkpoint-10000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-10500\n",
            "Configuration saved in results/checkpoint-10500/config.json\n",
            "Model weights saved in results/checkpoint-10500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-11000\n",
            "Configuration saved in results/checkpoint-11000/config.json\n",
            "Model weights saved in results/checkpoint-11000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-11500\n",
            "Configuration saved in results/checkpoint-11500/config.json\n",
            "Model weights saved in results/checkpoint-11500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-12000\n",
            "Configuration saved in results/checkpoint-12000/config.json\n",
            "Model weights saved in results/checkpoint-12000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-12500\n",
            "Configuration saved in results/checkpoint-12500/config.json\n",
            "Model weights saved in results/checkpoint-12500/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-13000\n",
            "Configuration saved in results/checkpoint-13000/config.json\n",
            "Model weights saved in results/checkpoint-13000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-13500\n",
            "Configuration saved in results/checkpoint-13500/config.json\n",
            "Model weights saved in results/checkpoint-13500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-2500 (score: 1.0287635326385498).\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='684' max='228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [228/228 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n",
            "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: response_text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1821\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------Iteration 5 Complete---------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1UzIi5vYVrQ",
        "outputId": "fa6e5dc9-e664-4080-f28c-88a74f3b0537"
      },
      "source": [
        "import statistics\n",
        "\n",
        "print(\"%15s %s (%s)\" % (\"\",\"Mean\", \"StDev\"))\n",
        "\n",
        "print(\"-\"*29)\n",
        "print(\"Macro Scores\")\n",
        "print(\"-\"*29)\n",
        "\n",
        "print(f\"%15s %s (%s)\" %(\"Accuracy\",\n",
        "    round(statistics.mean(accuracy_list),3),\n",
        "    round(statistics.stdev(accuracy_list),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Macro F1\",\n",
        "    round(statistics.mean(macro_f1_score_list),3),\n",
        "    round(statistics.stdev(macro_f1_score_list),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Weighted F1\",\n",
        "    round(statistics.mean(weighted_f1_score_list),3),\n",
        "    round(statistics.stdev(weighted_f1_score_list),3)))\n",
        "\n",
        "print(\"-\"*29)\n",
        "print(\"Class Scores\")\n",
        "print(\"-\"*29)\n",
        "\n",
        "print(f\"%15s %s (%s)\" %(\"Positive\",\n",
        "    round(statistics.mean(positive_f1_score),3),\n",
        "    round(statistics.stdev(positive_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Neutral\",\n",
        "    round(statistics.mean(neutral_f1_score),3),\n",
        "    round(statistics.stdev(neutral_f1_score),3)))\n",
        "print(f\"%15s %5s (%s)\" %(\"Negative\",\n",
        "    round(statistics.mean(negative_f1_score),3),\n",
        "    round(statistics.stdev(negative_f1_score),3)))\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Mean (StDev)\n",
            "-----------------------------\n",
            "Macro Scores\n",
            "-----------------------------\n",
            "       Accuracy 0.756 (0.006)\n",
            "       Macro F1 0.689 (0.015)\n",
            "    Weighted F1 0.754 (0.011)\n",
            "-----------------------------\n",
            "Class Scores\n",
            "-----------------------------\n",
            "       Positive 0.862 (0.002)\n",
            "        Neutral 0.555 (0.056)\n",
            "       Negative 0.651 (0.016)\n"
          ]
        }
      ]
    }
  ]
}